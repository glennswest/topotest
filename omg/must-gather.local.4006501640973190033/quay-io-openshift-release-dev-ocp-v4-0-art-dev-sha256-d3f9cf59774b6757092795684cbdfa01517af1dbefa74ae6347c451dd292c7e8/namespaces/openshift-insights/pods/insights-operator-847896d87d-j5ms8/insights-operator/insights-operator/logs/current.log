2023-05-04T16:32:44.085683843Z I0504 16:32:44.085164       1 cmd.go:209] Using service-serving-cert provided certificates
2023-05-04T16:32:44.085683843Z I0504 16:32:44.085247       1 observer_polling.go:74] Adding reactor for file "/var/run/secrets/serving-cert/tls.crt"
2023-05-04T16:32:44.085683843Z I0504 16:32:44.085285       1 observer_polling.go:74] Adding reactor for file "/var/run/secrets/serving-cert/tls.key"
2023-05-04T16:32:44.085683843Z I0504 16:32:44.085313       1 observer_polling.go:52] Starting from specified content for file "/etc/insights-operator/server.yaml"
2023-05-04T16:32:44.085683843Z I0504 16:32:44.085321       1 observer_polling.go:52] Starting from specified content for file "/var/run/configmaps/service-ca-bundle/service-ca.crt"
2023-05-04T16:32:44.086953595Z I0504 16:32:44.086100       1 observer_polling.go:159] Starting file observer
2023-05-04T16:32:44.086953595Z I0504 16:32:44.086431       1 observer_polling.go:135] File observer successfully synced
2023-05-04T16:32:44.134908764Z W0504 16:32:44.134864       1 builder.go:230] unable to get owner reference (falling back to namespace): replicasets.apps "insights-operator-847896d87d" is forbidden: User "system:serviceaccount:openshift-insights:operator" cannot get resource "replicasets" in API group "apps" in the namespace "openshift-insights"
2023-05-04T16:32:44.135471961Z I0504 16:32:44.135451       1 dynamic_serving_content.go:113] "Loaded a new cert/key pair" name="serving-cert::/var/run/secrets/serving-cert/tls.crt::/var/run/secrets/serving-cert/tls.key"
2023-05-04T16:32:44.484846678Z I0504 16:32:44.484782       1 requestheader_controller.go:244] Loaded a new request header values for RequestHeaderAuthRequestController
2023-05-04T16:32:44.485884636Z I0504 16:32:44.485539       1 maxinflight.go:140] "Initialized nonMutatingChan" len=400
2023-05-04T16:32:44.485926815Z I0504 16:32:44.485918       1 maxinflight.go:146] "Initialized mutatingChan" len=200
2023-05-04T16:32:44.486041821Z I0504 16:32:44.485953       1 timing_ratio_histogram.go:202] "TimingRatioHistogramVec.NewForLabelValuesSafe hit the inefficient case" fqName="apiserver_flowcontrol_read_vs_write_current_requests" labelValues=[executing readOnly]
2023-05-04T16:32:44.486081004Z I0504 16:32:44.486072       1 timing_ratio_histogram.go:202] "TimingRatioHistogramVec.NewForLabelValuesSafe hit the inefficient case" fqName="apiserver_flowcontrol_read_vs_write_current_requests" labelValues=[executing mutating]
2023-05-04T16:32:44.486103998Z I0504 16:32:44.486097       1 maxinflight.go:117] "Set denominator for readonly requests" limit=400
2023-05-04T16:32:44.486121901Z I0504 16:32:44.486116       1 maxinflight.go:121] "Set denominator for mutating requests" limit=200
2023-05-04T16:32:44.486158219Z I0504 16:32:44.486151       1 config.go:731] Not requested to run hook priority-and-fairness-config-consumer
2023-05-04T16:32:44.489056157Z I0504 16:32:44.488981       1 operator.go:51] Starting insights-operator v0.0.0-master+$Format:%H$
2023-05-04T16:32:44.490495678Z I0504 16:32:44.490449       1 genericapiserver.go:480] MuxAndDiscoveryComplete has all endpoints registered and discovery information is complete
2023-05-04T16:32:44.490495678Z W0504 16:32:44.490473       1 secure_serving.go:69] Use of insecure cipher 'TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256' detected.
2023-05-04T16:32:44.490495678Z W0504 16:32:44.490478       1 secure_serving.go:69] Use of insecure cipher 'TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256' detected.
2023-05-04T16:32:44.490583222Z I0504 16:32:44.490418       1 config.go:315] Current config: {"report":false,"storagePath":"/var/lib/insights-operator","interval":"2h","endpoint":"https://console.redhat.com/api/ingress/v1/upload","conditionalGathererEndpoint":"https://console.redhat.com/api/gathering/gathering_rules","pull_report":{"endpoint":"https://console.redhat.com/api/insights-results-aggregator/v2/cluster/%s/reports","delay":"60s","timeout":"3000s","min_retry":"30s"},"impersonate":"system:serviceaccount:openshift-insights:gather","enableGlobalObfuscation":false,"OCM":{"scaEndpoint":"","scaInterval":"","scaDisabled":false,"clusterTransferEndpoint":"","clusterTransferInterval":""},"disableInsightsAlerts":false}
2023-05-04T16:32:44.553065619Z I0504 16:32:44.553026       1 secretconfigobserver.go:215] Configuration set: enabled=false endpoint=https://console.redhat.com/api/ingress/v1/upload conditional_gatherer_endpoint=https://console.redhat.com/api/gathering/gathering_rules interval=2h0m0s username=false token=false reportEndpoint=https://console.redhat.com/api/insights-results-aggregator/v2/cluster/%s/reports initialPollingDelay=1m0s minRetryTime=30s pollingTimeout=50m0s
2023-05-04T16:32:44.553065619Z I0504 16:32:44.553045       1 secretconfigobserver.go:136] Refreshing configuration from cluster pull secret
2023-05-04T16:32:44.553360131Z I0504 16:32:44.553327       1 tlsconfig.go:200] "Loaded serving cert" certName="serving-cert::/var/run/secrets/serving-cert/tls.crt::/var/run/secrets/serving-cert/tls.key" certDetail="\"metrics.openshift-insights.svc\" [serving] validServingFor=[metrics.openshift-insights.svc,metrics.openshift-insights.svc.cluster.local] issuer=\"openshift-service-serving-signer@1683030520\" (2023-05-02 12:37:30 +0000 UTC to 2025-05-01 12:37:31 +0000 UTC (now=2023-05-04 16:32:44.553297434 +0000 UTC))"
2023-05-04T16:32:44.553428279Z I0504 16:32:44.553417       1 named_certificates.go:53] "Loaded SNI cert" index=0 certName="self-signed loopback" certDetail="\"apiserver-loopback-client@1683217964\" [serving] validServingFor=[apiserver-loopback-client] issuer=\"apiserver-loopback-client-ca@1683217964\" (2023-05-04 15:32:44 +0000 UTC to 2024-05-03 15:32:44 +0000 UTC (now=2023-05-04 16:32:44.55340194 +0000 UTC))"
2023-05-04T16:32:44.553448006Z I0504 16:32:44.553439       1 secure_serving.go:210] Serving securely on [::]:8443
2023-05-04T16:32:44.553462654Z I0504 16:32:44.553454       1 genericapiserver.go:585] [graceful-termination] waiting for shutdown to be initiated
2023-05-04T16:32:44.553484304Z I0504 16:32:44.553477       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
2023-05-04T16:32:44.553490025Z I0504 16:32:44.553483       1 shared_informer.go:255] Waiting for caches to sync for RequestHeaderAuthRequestController
2023-05-04T16:32:44.553792613Z I0504 16:32:44.553775       1 dynamic_serving_content.go:132] "Starting controller" name="serving-cert::/var/run/secrets/serving-cert/tls.crt::/var/run/secrets/serving-cert/tls.key"
2023-05-04T16:32:44.555556242Z I0504 16:32:44.555527       1 tlsconfig.go:240] "Starting DynamicServingCertificateController"
2023-05-04T16:32:44.555608320Z I0504 16:32:44.555597       1 configmap_cafile_content.go:202] "Starting controller" name="client-ca::kube-system::extension-apiserver-authentication::client-ca-file"
2023-05-04T16:32:44.555615213Z I0504 16:32:44.555606       1 shared_informer.go:255] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
2023-05-04T16:32:44.555744225Z I0504 16:32:44.555728       1 reflector.go:221] Starting reflector *v1.ConfigMap (12h0m0s) from k8s.io/apiserver/pkg/server/dynamiccertificates/configmap_cafile_content.go:206
2023-05-04T16:32:44.555744225Z I0504 16:32:44.555737       1 reflector.go:257] Listing and watching *v1.ConfigMap from k8s.io/apiserver/pkg/server/dynamiccertificates/configmap_cafile_content.go:206
2023-05-04T16:32:44.555850093Z I0504 16:32:44.555839       1 configmap_cafile_content.go:202] "Starting controller" name="client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file"
2023-05-04T16:32:44.555870662Z I0504 16:32:44.555864       1 shared_informer.go:255] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file
2023-05-04T16:32:44.555998442Z I0504 16:32:44.555987       1 reflector.go:221] Starting reflector *v1.ConfigMap (12h0m0s) from k8s.io/apiserver/pkg/server/dynamiccertificates/configmap_cafile_content.go:206
2023-05-04T16:32:44.556021465Z I0504 16:32:44.556015       1 reflector.go:257] Listing and watching *v1.ConfigMap from k8s.io/apiserver/pkg/server/dynamiccertificates/configmap_cafile_content.go:206
2023-05-04T16:32:44.556067912Z I0504 16:32:44.556055       1 reflector.go:221] Starting reflector *v1.ConfigMap (12h0m0s) from k8s.io/apiserver/pkg/authentication/request/headerrequest/requestheader_controller.go:172
2023-05-04T16:32:44.556067912Z I0504 16:32:44.556062       1 reflector.go:257] Listing and watching *v1.ConfigMap from k8s.io/apiserver/pkg/authentication/request/headerrequest/requestheader_controller.go:172
2023-05-04T16:32:44.566094044Z I0504 16:32:44.566057       1 secretconfigobserver.go:248] Found cloud.openshift.com token
2023-05-04T16:32:44.566094044Z I0504 16:32:44.566081       1 secretconfigobserver.go:203] Configuration updated: enabled=true endpoint=https://console.redhat.com/api/ingress/v1/upload conditional_gatherer_endpoint=https://console.redhat.com/api/gathering/gathering_rules interval=2h0m0s username=false token=true reportEndpoint=https://console.redhat.com/api/insights-results-aggregator/v2/cluster/%s/reports initialPollingDelay=1m0s minRetryTime=30s pollingTimeout=50m0s
2023-05-04T16:32:44.566094044Z I0504 16:32:44.566085       1 secretconfigobserver.go:162] Refreshing configuration from cluster secret
2023-05-04T16:32:44.626523699Z I0504 16:32:44.626456       1 secretconfigobserver.go:119] support secret does not exist
2023-05-04T16:32:44.627003760Z I0504 16:32:44.626980       1 secretconfigobserver.go:136] Refreshing configuration from cluster pull secret
2023-05-04T16:32:44.632829000Z I0504 16:32:44.631229       1 secretconfigobserver.go:248] Found cloud.openshift.com token
2023-05-04T16:32:44.632829000Z I0504 16:32:44.631257       1 secretconfigobserver.go:162] Refreshing configuration from cluster secret
2023-05-04T16:32:44.632829000Z I0504 16:32:44.632065       1 recorder.go:155] Pruning old reports every 5h49m35s, max age is 288h0m0s
2023-05-04T16:32:44.634952885Z I0504 16:32:44.634906       1 secretconfigobserver.go:119] support secret does not exist
2023-05-04T16:32:44.635496575Z I0504 16:32:44.635484       1 operator.go:207] The last pod state is unhealthy
2023-05-04T16:32:44.655793048Z I0504 16:32:44.655746       1 shared_informer.go:285] caches populated
2023-05-04T16:32:44.655793048Z I0504 16:32:44.655766       1 shared_informer.go:262] Caches are synced for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
2023-05-04T16:32:44.656056662Z I0504 16:32:44.656044       1 shared_informer.go:285] caches populated
2023-05-04T16:32:44.656087841Z I0504 16:32:44.656080       1 shared_informer.go:262] Caches are synced for RequestHeaderAuthRequestController
2023-05-04T16:32:44.656178962Z I0504 16:32:44.656164       1 tlsconfig.go:178] "Loaded client CA" index=0 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"admin-kubeconfig-signer\" [] issuer=\"<self>\" (2023-05-02 12:12:54 +0000 UTC to 2033-04-29 12:12:54 +0000 UTC (now=2023-05-04 16:32:44.656142994 +0000 UTC))"
2023-05-04T16:32:44.656195162Z I0504 16:32:44.656186       1 tlsconfig.go:178] "Loaded client CA" index=1 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kube-control-plane-signer\" [] issuer=\"<self>\" (2023-05-02 12:12:57 +0000 UTC to 2024-05-01 12:12:57 +0000 UTC (now=2023-05-04 16:32:44.656174463 +0000 UTC))"
2023-05-04T16:32:44.656232302Z I0504 16:32:44.656223       1 shared_informer.go:285] caches populated
2023-05-04T16:32:44.656251778Z I0504 16:32:44.656245       1 shared_informer.go:262] Caches are synced for client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file
2023-05-04T16:32:44.656351025Z I0504 16:32:44.656338       1 tlsconfig.go:178] "Loaded client CA" index=2 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kube-apiserver-to-kubelet-signer\" [] issuer=\"<self>\" (2023-05-02 12:12:57 +0000 UTC to 2024-05-01 12:12:57 +0000 UTC (now=2023-05-04 16:32:44.656193068 +0000 UTC))"
2023-05-04T16:32:44.656366313Z I0504 16:32:44.656358       1 tlsconfig.go:178] "Loaded client CA" index=3 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kubelet-bootstrap-kubeconfig-signer\" [] issuer=\"<self>\" (2023-05-02 12:12:55 +0000 UTC to 2033-04-29 12:12:55 +0000 UTC (now=2023-05-04 16:32:44.656347839 +0000 UTC))"
2023-05-04T16:32:44.656384137Z I0504 16:32:44.656375       1 tlsconfig.go:178] "Loaded client CA" index=4 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"openshift-kube-apiserver-operator_node-system-admin-signer@1683031055\" [] issuer=\"<self>\" (2023-05-02 12:37:35 +0000 UTC to 2024-05-01 12:37:36 +0000 UTC (now=2023-05-04 16:32:44.656364199 +0000 UTC))"
2023-05-04T16:32:44.656412891Z I0504 16:32:44.656404       1 tlsconfig.go:178] "Loaded client CA" index=5 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"openshift-kube-controller-manager-operator_csr-signer-signer@1683098709\" [] issuer=\"<self>\" (2023-05-03 07:25:09 +0000 UTC to 2023-07-02 07:25:10 +0000 UTC (now=2023-05-04 16:32:44.656382824 +0000 UTC))"
2023-05-04T16:32:44.656440422Z I0504 16:32:44.656423       1 tlsconfig.go:178] "Loaded client CA" index=6 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kube-csr-signer_@1683098906\" [] issuer=\"openshift-kube-controller-manager-operator_csr-signer-signer@1683098709\" (2023-05-03 07:28:25 +0000 UTC to 2023-06-02 07:28:26 +0000 UTC (now=2023-05-04 16:32:44.656411799 +0000 UTC))"
2023-05-04T16:32:44.656579824Z I0504 16:32:44.656561       1 tlsconfig.go:200] "Loaded serving cert" certName="serving-cert::/var/run/secrets/serving-cert/tls.crt::/var/run/secrets/serving-cert/tls.key" certDetail="\"metrics.openshift-insights.svc\" [serving] validServingFor=[metrics.openshift-insights.svc,metrics.openshift-insights.svc.cluster.local] issuer=\"openshift-service-serving-signer@1683030520\" (2023-05-02 12:37:30 +0000 UTC to 2025-05-01 12:37:31 +0000 UTC (now=2023-05-04 16:32:44.656533146 +0000 UTC))"
2023-05-04T16:32:44.656658331Z I0504 16:32:44.656647       1 named_certificates.go:53] "Loaded SNI cert" index=0 certName="self-signed loopback" certDetail="\"apiserver-loopback-client@1683217964\" [serving] validServingFor=[apiserver-loopback-client] issuer=\"apiserver-loopback-client-ca@1683217964\" (2023-05-04 15:32:44 +0000 UTC to 2024-05-03 15:32:44 +0000 UTC (now=2023-05-04 16:32:44.656634697 +0000 UTC))"
2023-05-04T16:32:44.656775942Z I0504 16:32:44.656765       1 tlsconfig.go:178] "Loaded client CA" index=0 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"admin-kubeconfig-signer\" [] issuer=\"<self>\" (2023-05-02 12:12:54 +0000 UTC to 2033-04-29 12:12:54 +0000 UTC (now=2023-05-04 16:32:44.656753961 +0000 UTC))"
2023-05-04T16:32:44.656800328Z I0504 16:32:44.656792       1 tlsconfig.go:178] "Loaded client CA" index=1 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kube-control-plane-signer\" [] issuer=\"<self>\" (2023-05-02 12:12:57 +0000 UTC to 2024-05-01 12:12:57 +0000 UTC (now=2023-05-04 16:32:44.656773798 +0000 UTC))"
2023-05-04T16:32:44.656867033Z I0504 16:32:44.656809       1 tlsconfig.go:178] "Loaded client CA" index=2 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kube-apiserver-to-kubelet-signer\" [] issuer=\"<self>\" (2023-05-02 12:12:57 +0000 UTC to 2024-05-01 12:12:57 +0000 UTC (now=2023-05-04 16:32:44.656798625 +0000 UTC))"
2023-05-04T16:32:44.656867033Z I0504 16:32:44.656831       1 tlsconfig.go:178] "Loaded client CA" index=3 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kubelet-bootstrap-kubeconfig-signer\" [] issuer=\"<self>\" (2023-05-02 12:12:55 +0000 UTC to 2033-04-29 12:12:55 +0000 UTC (now=2023-05-04 16:32:44.656815336 +0000 UTC))"
2023-05-04T16:32:44.656867033Z I0504 16:32:44.656847       1 tlsconfig.go:178] "Loaded client CA" index=4 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"openshift-kube-apiserver-operator_node-system-admin-signer@1683031055\" [] issuer=\"<self>\" (2023-05-02 12:37:35 +0000 UTC to 2024-05-01 12:37:36 +0000 UTC (now=2023-05-04 16:32:44.656836415 +0000 UTC))"
2023-05-04T16:32:44.656876571Z I0504 16:32:44.656871       1 tlsconfig.go:178] "Loaded client CA" index=5 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"openshift-kube-controller-manager-operator_csr-signer-signer@1683098709\" [] issuer=\"<self>\" (2023-05-03 07:25:09 +0000 UTC to 2023-07-02 07:25:10 +0000 UTC (now=2023-05-04 16:32:44.65686037 +0000 UTC))"
2023-05-04T16:32:44.656910064Z I0504 16:32:44.656900       1 tlsconfig.go:178] "Loaded client CA" index=6 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kube-csr-signer_@1683098906\" [] issuer=\"openshift-kube-controller-manager-operator_csr-signer-signer@1683098709\" (2023-05-03 07:28:25 +0000 UTC to 2023-06-02 07:28:26 +0000 UTC (now=2023-05-04 16:32:44.656877382 +0000 UTC))"
2023-05-04T16:32:44.656925673Z I0504 16:32:44.656918       1 tlsconfig.go:178] "Loaded client CA" index=7 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"openshift-kube-apiserver-operator_aggregator-client-signer@1683098704\" [] issuer=\"<self>\" (2023-05-03 07:25:03 +0000 UTC to 2023-06-02 07:25:04 +0000 UTC (now=2023-05-04 16:32:44.656907739 +0000 UTC))"
2023-05-04T16:32:44.657142139Z I0504 16:32:44.657020       1 tlsconfig.go:200] "Loaded serving cert" certName="serving-cert::/var/run/secrets/serving-cert/tls.crt::/var/run/secrets/serving-cert/tls.key" certDetail="\"metrics.openshift-insights.svc\" [serving] validServingFor=[metrics.openshift-insights.svc,metrics.openshift-insights.svc.cluster.local] issuer=\"openshift-service-serving-signer@1683030520\" (2023-05-02 12:37:30 +0000 UTC to 2025-05-01 12:37:31 +0000 UTC (now=2023-05-04 16:32:44.657007376 +0000 UTC))"
2023-05-04T16:32:44.657142139Z I0504 16:32:44.657099       1 named_certificates.go:53] "Loaded SNI cert" index=0 certName="self-signed loopback" certDetail="\"apiserver-loopback-client@1683217964\" [serving] validServingFor=[apiserver-loopback-client] issuer=\"apiserver-loopback-client-ca@1683217964\" (2023-05-04 15:32:44 +0000 UTC to 2024-05-03 15:32:44 +0000 UTC (now=2023-05-04 16:32:44.657088058 +0000 UTC))"
2023-05-04T16:33:04.682931313Z I0504 16:33:04.680094       1 periodic.go:150] Running clusterconfig gatherer
2023-05-04T16:33:04.682931313Z I0504 16:33:04.680147       1 tasks_processing.go:45] number of workers: 16
2023-05-04T16:33:04.682931313Z I0504 16:33:04.680164       1 tasks_processing.go:69] worker 15 listening for tasks.
2023-05-04T16:33:04.682931313Z I0504 16:33:04.680168       1 tasks_processing.go:71] worker 15 working on openshift_apiserver_operator_logs task.
2023-05-04T16:33:04.682931313Z I0504 16:33:04.680251       1 tasks_processing.go:69] worker 7 listening for tasks.
2023-05-04T16:33:04.682931313Z I0504 16:33:04.680264       1 tasks_processing.go:69] worker 0 listening for tasks.
2023-05-04T16:33:04.682931313Z I0504 16:33:04.680279       1 tasks_processing.go:69] worker 1 listening for tasks.
2023-05-04T16:33:04.682931313Z I0504 16:33:04.680285       1 tasks_processing.go:69] worker 2 listening for tasks.
2023-05-04T16:33:04.682931313Z I0504 16:33:04.680293       1 tasks_processing.go:69] worker 3 listening for tasks.
2023-05-04T16:33:04.682931313Z I0504 16:33:04.680299       1 tasks_processing.go:69] worker 4 listening for tasks.
2023-05-04T16:33:04.682931313Z I0504 16:33:04.680305       1 tasks_processing.go:69] worker 5 listening for tasks.
2023-05-04T16:33:04.682931313Z I0504 16:33:04.680310       1 tasks_processing.go:69] worker 6 listening for tasks.
2023-05-04T16:33:04.682931313Z I0504 16:33:04.680317       1 tasks_processing.go:69] worker 11 listening for tasks.
2023-05-04T16:33:04.682931313Z I0504 16:33:04.680323       1 tasks_processing.go:69] worker 8 listening for tasks.
2023-05-04T16:33:04.682931313Z I0504 16:33:04.680330       1 tasks_processing.go:69] worker 9 listening for tasks.
2023-05-04T16:33:04.682931313Z I0504 16:33:04.680336       1 tasks_processing.go:69] worker 10 listening for tasks.
2023-05-04T16:33:04.682931313Z I0504 16:33:04.680342       1 tasks_processing.go:69] worker 13 listening for tasks.
2023-05-04T16:33:04.682931313Z I0504 16:33:04.680348       1 tasks_processing.go:69] worker 12 listening for tasks.
2023-05-04T16:33:04.682931313Z I0504 16:33:04.680354       1 tasks_processing.go:69] worker 14 listening for tasks.
2023-05-04T16:33:04.682931313Z I0504 16:33:04.680360       1 tasks_processing.go:71] worker 14 working on machine_autoscalers task.
2023-05-04T16:33:04.682931313Z I0504 16:33:04.680536       1 tasks_processing.go:71] worker 7 working on kube_controller_manager_logs task.
2023-05-04T16:33:04.682931313Z I0504 16:33:04.680618       1 tasks_processing.go:71] worker 6 working on cost_management_metrics_configs task.
2023-05-04T16:33:04.682931313Z I0504 16:33:04.680724       1 tasks_processing.go:71] worker 0 working on schedulers task.
2023-05-04T16:33:04.682931313Z I0504 16:33:04.680777       1 tasks_processing.go:71] worker 3 working on version task.
2023-05-04T16:33:04.778096714Z I0504 16:33:04.778031       1 tasks_processing.go:71] worker 1 working on machine_healthchecks task.
2023-05-04T16:33:04.781286198Z I0504 16:33:04.778335       1 tasks_processing.go:71] worker 2 working on jaegers task.
2023-05-04T16:33:04.781286198Z I0504 16:33:04.778691       1 tasks_processing.go:71] worker 9 working on nodes task.
2023-05-04T16:33:04.781286198Z I0504 16:33:04.779275       1 tasks_processing.go:71] worker 11 working on sap_datahubs task.
2023-05-04T16:33:04.781286198Z I0504 16:33:04.779579       1 tasks_processing.go:71] worker 8 working on pdbs task.
2023-05-04T16:33:04.781414098Z I0504 16:33:04.781398       1 tasks_processing.go:71] worker 13 working on sap_license_management_logs task.
2023-05-04T16:33:04.782111086Z I0504 16:33:04.782084       1 tasks_processing.go:71] worker 10 working on validating_webhook_configurations task.
2023-05-04T16:33:04.782578072Z I0504 16:33:04.782550       1 tasks_processing.go:71] worker 5 working on netnamespaces task.
2023-05-04T16:33:04.782941424Z I0504 16:33:04.782928       1 tasks_processing.go:71] worker 4 working on image task.
2023-05-04T16:33:04.783331245Z I0504 16:33:04.783317       1 tasks_processing.go:71] worker 12 working on olm_operators task.
2023-05-04T16:33:04.786906734Z I0504 16:33:04.786875       1 controller.go:116] Initializing last reported time to 2023-05-04T16:13:56Z
2023-05-04T16:33:04.786950186Z I0504 16:33:04.786942       1 controller.go:311] The initial operator extension status is healthy
2023-05-04T16:33:04.786989039Z I0504 16:33:04.786980       1 controller.go:200] Source periodic-workloads *controllerstatus.Simple is not ready
2023-05-04T16:33:04.787010779Z I0504 16:33:04.787003       1 controller.go:200] Source insightsuploader *insightsuploader.Controller is not ready
2023-05-04T16:33:04.787028032Z I0504 16:33:04.787022       1 controller.go:200] Source periodic-clusterconfig *controllerstatus.Simple is not ready
2023-05-04T16:33:04.787044783Z I0504 16:33:04.787038       1 controller.go:200] Source periodic-conditional *controllerstatus.Simple is not ready
2023-05-04T16:33:04.787076623Z I0504 16:33:04.787069       1 controller.go:419] The operator is still being initialized
2023-05-04T16:33:04.787093354Z I0504 16:33:04.787088       1 controller.go:447] The operator is healthy
2023-05-04T16:33:04.787144590Z I0504 16:33:04.787137       1 controller.go:325] No status update necessary, objects are identical
2023-05-04T16:33:04.787179676Z W0504 16:33:04.787173       1 operator.go:179] started
2023-05-04T16:33:04.787282489Z I0504 16:33:04.787262       1 cluster_transfer.go:78] checking the availability of cluster transfer. Next check is in 24h0m0s
2023-05-04T16:33:04.789920769Z I0504 16:33:04.789896       1 tasks_processing.go:71] worker 14 working on operators task.
2023-05-04T16:33:04.790040334Z I0504 16:33:04.790029       1 sap_vsystem_iptables_logs.go:51] SAP resources weren't found
2023-05-04T16:33:04.790304620Z I0504 16:33:04.790285       1 gather.go:180] gatherer "clusterconfig" function "machine_autoscalers" took 109.528249ms to process 0 records
2023-05-04T16:33:04.790304620Z I0504 16:33:04.790298       1 gather.go:180] gatherer "clusterconfig" function "sap_datahubs" took 10.719554ms to process 0 records
2023-05-04T16:33:04.790316522Z I0504 16:33:04.790307       1 gather.go:180] gatherer "clusterconfig" function "sap_license_management_logs" took 8.628119ms to process 0 records
2023-05-04T16:33:04.790321511Z I0504 16:33:04.790315       1 gather.go:180] gatherer "clusterconfig" function "netnamespaces" took 7.478813ms to process 0 records
2023-05-04T16:33:04.790321511Z I0504 16:33:04.790319       1 gather.go:180] gatherer "clusterconfig" function "jaegers" took 11.923873ms to process 0 records
2023-05-04T16:33:04.790339675Z I0504 16:33:04.790325       1 tasks_processing.go:71] worker 2 working on image_pruners task.
2023-05-04T16:33:04.790354874Z I0504 16:33:04.790346       1 tasks_processing.go:71] worker 11 working on container_images task.
2023-05-04T16:33:04.790389739Z I0504 16:33:04.790379       1 tasks_processing.go:71] worker 5 working on install_plans task.
2023-05-04T16:33:04.790432039Z I0504 16:33:04.790414       1 tasks_processing.go:71] worker 13 working on config_maps task.
2023-05-04T16:33:04.813692723Z I0504 16:33:04.813118       1 tasks_processing.go:71] worker 6 working on openshift_sdn_logs task.
2023-05-04T16:33:04.813692723Z I0504 16:33:04.813272       1 controllerstatus.go:70] name=insightsuploader healthy=true reason= message=
2023-05-04T16:33:04.813692723Z I0504 16:33:04.813304       1 controllerstatus.go:70] name=insightsreport healthy=true reason= message=
2023-05-04T16:33:04.813692723Z I0504 16:33:04.813309       1 insightsreport.go:245] Starting report retriever
2023-05-04T16:33:04.813692723Z I0504 16:33:04.813327       1 sca.go:99] Pulling SCA certificates from https://api.openshift.com/api/accounts_mgmt/v1/certificates. Next check is in 8h0m0s
2023-05-04T16:33:04.813692723Z I0504 16:33:04.813468       1 insightsuploader.go:87] Reporting status periodically to https://console.redhat.com/api/ingress/v1/upload every 2h0m0s, starting in -3h11m42s
2023-05-04T16:33:04.813692723Z I0504 16:33:04.813508       1 insightsuploader.go:122] Nothing to report since 2023-05-04T16:13:56Z
2023-05-04T16:33:04.813692723Z I0504 16:33:04.813516       1 insightsreport.go:246] Initial config: &{true /var/lib/insights-operator 2h0m0s https://console.redhat.com/api/ingress/v1/upload https://console.redhat.com/api/gathering/gathering_rules https://console.redhat.com/api/insights-results-aggregator/v2/cluster/%s/reports 1m0s 30s 50m0s system:serviceaccount:openshift-insights:gather false   b3BlbnNoaWZ0LXJlbGVhc2UtZGV2K2d3ZXN0cmVkaGF0Y29tMW10NDc1aXN5Z3RtcTRrb2xnaDF1aHNiNDZjOlVUQzNZNDdGRjhSTk1JMzk2R1RPQTIxWTFZVUFNQlQyTzFMUlVKSUI3WUlMVFNYTzBVM1kxODdRUlZPWVg0UFM= {  } {8h0m0s https://api.openshift.com/api/accounts_mgmt/v1/certificates false https://api.openshift.com/api/accounts_mgmt/v1/cluster_transfers 24h0m0s} false}
2023-05-04T16:33:04.814204613Z I0504 16:33:04.814085       1 gather.go:180] gatherer "clusterconfig" function "cost_management_metrics_configs" took 132.482459ms to process 0 records
2023-05-04T16:33:04.875928096Z I0504 16:33:04.874985       1 gather_logs.go:132] no pods in openshift-sdn namespace were found
2023-05-04T16:33:04.875995302Z I0504 16:33:04.875732       1 tasks_processing.go:71] worker 10 working on crds task.
2023-05-04T16:33:04.876340580Z I0504 16:33:04.876327       1 controller.go:200] Source periodic-clusterconfig *controllerstatus.Simple is not ready
2023-05-04T16:33:04.876364375Z I0504 16:33:04.876357       1 controller.go:200] Source periodic-conditional *controllerstatus.Simple is not ready
2023-05-04T16:33:04.876381597Z I0504 16:33:04.876375       1 controller.go:200] Source periodic-workloads *controllerstatus.Simple is not ready
2023-05-04T16:33:04.876399942Z I0504 16:33:04.876394       1 controller.go:200] Source scaController *sca.Controller is not ready
2023-05-04T16:33:04.876416683Z I0504 16:33:04.876410       1 controller.go:200] Source clusterTransferController *clustertransfer.Controller is not ready
2023-05-04T16:33:04.876443273Z I0504 16:33:04.876436       1 controller.go:419] The operator is still being initialized
2023-05-04T16:33:04.876459864Z I0504 16:33:04.876454       1 controller.go:447] The operator is healthy
2023-05-04T16:33:04.876500530Z I0504 16:33:04.876493       1 controller.go:325] No status update necessary, objects are identical
2023-05-04T16:33:04.876836941Z I0504 16:33:04.876820       1 recorder.go:70] Recording config/validatingwebhookconfigurations/alertmanagerconfigs.openshift.io with fingerprint=fcf00b34b07141e143ba5b5fb1b59572f62343463c4d71416c3057e811be28d5
2023-05-04T16:33:04.876871827Z I0504 16:33:04.876863       1 recorder.go:70] Recording config/validatingwebhookconfigurations/autoscaling.openshift.io with fingerprint=ce0c1da823eed5c0ec415879d4789e218f08ff6db536e7f7ea5ef4f0010d5dae
2023-05-04T16:33:04.876902224Z I0504 16:33:04.876892       1 recorder.go:70] Recording config/validatingwebhookconfigurations/cluster-baremetal-validating-webhook-configuration with fingerprint=ce423529a9780f564c48c4de6c74f76cc65f86c5c44a4af5ca92781327ff98e8
2023-05-04T16:33:04.876924696Z I0504 16:33:04.876916       1 recorder.go:70] Recording config/validatingwebhookconfigurations/controlplanemachineset.machine.openshift.io with fingerprint=c2f3a625f87c750536bb29317e48541c4a696dbbeecf0a3102c4ffe958c2f905
2023-05-04T16:33:04.876945365Z I0504 16:33:04.876937       1 recorder.go:70] Recording config/validatingwebhookconfigurations/multus.openshift.io with fingerprint=4bb2304c54026dab033e1a2a651b2ca8a8dfbeb14023a1e430dc992b1f0cdb17
2023-05-04T16:33:04.876978617Z I0504 16:33:04.876958       1 recorder.go:70] Recording config/validatingwebhookconfigurations/performance-addon-operator with fingerprint=90ced388dfb6ff2029b0bf830afa6f769a41c64d5c6ac8b40225af7c68214381
2023-05-04T16:33:04.876999867Z I0504 16:33:04.876992       1 recorder.go:70] Recording config/validatingwebhookconfigurations/prometheusrules.openshift.io with fingerprint=b31c2bdf0f899481779a4149e2902ba299fe6873a663296253861d90be26b2ef
2023-05-04T16:33:04.877022409Z I0504 16:33:04.877014       1 recorder.go:70] Recording config/validatingwebhookconfigurations/snapshot.storage.k8s.io with fingerprint=84f30fd3c07eb1e7694fa2fe112539311495a9ae22612b849e5bc4afdae5b432
2023-05-04T16:33:04.877042557Z I0504 16:33:04.877034       1 recorder.go:70] Recording config/validatingwebhookconfigurations/vlvmcluster.kb.io-bwbz9 with fingerprint=b2ca9c2c4c8590efcd9e18e3a4b4e0499e8822edff27caa50c8193f3fc3ee13c
2023-05-04T16:33:04.877061894Z I0504 16:33:04.877051       1 gather.go:180] gatherer "clusterconfig" function "validating_webhook_configurations" took 93.578743ms to process 9 records
2023-05-04T16:33:04.877068055Z I0504 16:33:04.877060       1 gather.go:180] gatherer "clusterconfig" function "openshift_sdn_logs" took 62.844386ms to process 0 records
2023-05-04T16:33:04.877118810Z I0504 16:33:04.877108       1 recorder.go:70] Recording config/schedulers/cluster with fingerprint=24909f0181771d02e9d889c59ad4037a27c08c3752b621530cfebebf2e665887
2023-05-04T16:33:04.877132566Z I0504 16:33:04.877124       1 gather.go:180] gatherer "clusterconfig" function "schedulers" took 195.371569ms to process 1 records
2023-05-04T16:33:04.877348501Z I0504 16:33:04.877335       1 recorder.go:70] Recording config/clusteroperator/imageregistry.operator.openshift.io/imagepruner/cluster with fingerprint=db32db6f703fae36c0a256cef5351fd88c275597fbc57b2840c23a8145809329
2023-05-04T16:33:04.877348501Z I0504 16:33:04.877343       1 gather.go:180] gatherer "clusterconfig" function "image_pruners" took 86.005834ms to process 1 records
2023-05-04T16:33:04.877412972Z I0504 16:33:04.877402       1 recorder.go:70] Recording config/image with fingerprint=40406a2d3048d25fb0167bcc2918af08fd6c87b76ee15bfdea90334a80de86f0
2023-05-04T16:33:04.877412972Z I0504 16:33:04.877408       1 gather.go:180] gatherer "clusterconfig" function "image" took 93.487061ms to process 1 records
2023-05-04T16:33:04.877637053Z I0504 16:33:04.877622       1 recorder.go:70] Recording config/node/node with fingerprint=a4a6e37d786588df64a9a724b7ed0ecf86c212597b86420f005ab730d5d91cd5
2023-05-04T16:33:04.877637053Z I0504 16:33:04.877629       1 gather.go:180] gatherer "clusterconfig" function "nodes" took 97.847313ms to process 1 records
2023-05-04T16:33:04.877653965Z I0504 16:33:04.877635       1 tasks_processing.go:71] worker 9 working on image_registries task.
2023-05-04T16:33:04.877747911Z I0504 16:33:04.877737       1 recorder.go:70] Recording config/machinehealthchecks/openshift-machine-api/machine-api-termination-handler with fingerprint=fa9d2812bc01b43f8bac647c12a6a4ef945698219c71eee0836ad01b2fb92aa6
2023-05-04T16:33:04.877773549Z I0504 16:33:04.877766       1 gather.go:180] gatherer "clusterconfig" function "machine_healthchecks" took 99.651297ms to process 1 records
2023-05-04T16:33:04.877942847Z I0504 16:33:04.877931       1 tasks_processing.go:71] worker 4 working on machine_config_pools task.
2023-05-04T16:33:04.878168139Z I0504 16:33:04.878153       1 tasks_processing.go:71] worker 1 working on dvo_metrics task.
2023-05-04T16:33:04.878363586Z I0504 16:33:04.878350       1 tasks_processing.go:71] worker 6 working on operators_pods_and_events task.
2023-05-04T16:33:04.878556508Z I0504 16:33:04.878544       1 tasks_processing.go:71] worker 0 working on node_logs task.
2023-05-04T16:33:04.878729493Z I0504 16:33:04.878717       1 tasks_processing.go:71] worker 2 working on openshift_authentication_logs task.
2023-05-04T16:33:04.879253115Z I0504 16:33:04.879239       1 tasks_processing.go:71] worker 8 working on overlapping_namespace_uids task.
2023-05-04T16:33:04.879489278Z I0504 16:33:04.879476       1 recorder.go:70] Recording config/pdbs/openshift-console/console with fingerprint=6d80d3160849b9a1af763d944042ceed3b0a795d9e298e70af95ab68b0d8b662
2023-05-04T16:33:04.879498525Z I0504 16:33:04.879494       1 recorder.go:70] Recording config/pdbs/openshift-console/downloads with fingerprint=e5b2126f5ad97a584cd91d89a8bd3b10b22ad3ada4cbddde5262ca822cbea509
2023-05-04T16:33:04.879526778Z I0504 16:33:04.879517       1 recorder.go:70] Recording config/pdbs/openshift-operator-lifecycle-manager/packageserver-pdb with fingerprint=1f50962101bab1bdc7ac6f4d97a0f536a8656a6ec548201d7917248746707ada
2023-05-04T16:33:04.879526778Z I0504 16:33:04.879523       1 gather.go:180] gatherer "clusterconfig" function "pdbs" took 99.653191ms to process 3 records
2023-05-04T16:33:04.925609284Z I0504 16:33:04.925581       1 tasks_processing.go:71] worker 9 working on tsdb_status task.
2023-05-04T16:33:04.926292847Z I0504 16:33:04.926278       1 recorder.go:70] Recording config/clusteroperator/imageregistry.operator.openshift.io/config/cluster with fingerprint=1024b4dbe2157bbc8c571d79fdd5c987f0db6d702997b32a007e80be5c34e96f
2023-05-04T16:33:04.926323664Z I0504 16:33:04.926315       1 gather.go:180] gatherer "clusterconfig" function "image_registries" took 47.936524ms to process 1 records
2023-05-04T16:33:04.928705804Z W0504 16:33:04.928677       1 dvo_metrics.go:95] No DVO metrics gathered
2023-05-04T16:33:04.928742062Z I0504 16:33:04.928701       1 tasks_processing.go:71] worker 12 working on openshift_machine_api_events task.
2023-05-04T16:33:04.929271756Z I0504 16:33:04.929255       1 version.go:101] Found 1 unhealthy pods in openshift-cluster-version
2023-05-04T16:33:04.933372390Z I0504 16:33:04.932988       1 operators_pods_and_events.go:98] Found 0 pods with 0 containers
2023-05-04T16:33:04.945190815Z I0504 16:33:04.945155       1 recorder.go:70] Recording config/olm_operators with fingerprint=ca82ebf1da0994b592679c234a51181c446a42664129c26a6e52ce0a0068da03
2023-05-04T16:33:04.945190815Z I0504 16:33:04.945172       1 gather.go:180] gatherer "clusterconfig" function "olm_operators" took 145.330897ms to process 1 records
2023-05-04T16:33:04.945190815Z I0504 16:33:04.945180       1 gather.go:180] gatherer "clusterconfig" function "dvo_metrics" took 50.576918ms to process 0 records
2023-05-04T16:33:04.945275294Z I0504 16:33:04.945264       1 recorder.go:70] Recording config/machineconfigpools/master with fingerprint=52fbaf0bc3c102c47b04aed7fb81bed1682dfdb716f6871a08cc48da179c0439
2023-05-04T16:33:04.945341738Z I0504 16:33:04.945333       1 recorder.go:70] Recording config/machineconfigpools/worker with fingerprint=9a0d6452846784a245788e8f86b5889853af50693428a6ad7192280f0563d6b6
2023-05-04T16:33:04.945341738Z I0504 16:33:04.945339       1 gather.go:180] gatherer "clusterconfig" function "machine_config_pools" took 51.21188ms to process 2 records
2023-05-04T16:33:04.945348220Z I0504 16:33:04.945343       1 gather.go:180] gatherer "clusterconfig" function "openshift_apiserver_operator_logs" took 249.148672ms to process 0 records
2023-05-04T16:33:04.945361375Z I0504 16:33:04.945353       1 recorder.go:70] Recording config/namespaces_with_overlapping_uids with fingerprint=4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945
2023-05-04T16:33:04.945361375Z I0504 16:33:04.945359       1 gather.go:180] gatherer "clusterconfig" function "overlapping_namespace_uids" took 50.304267ms to process 1 records
2023-05-04T16:33:04.945367497Z I0504 16:33:04.945363       1 gather.go:180] gatherer "clusterconfig" function "operators_pods_and_events" took 55.04956ms to process 0 records
2023-05-04T16:33:04.945372316Z I0504 16:33:04.945368       1 tasks_processing.go:71] worker 6 working on host_subnets task.
2023-05-04T16:33:04.945638816Z I0504 16:33:04.945627       1 tasks_processing.go:71] worker 8 working on sap_config task.
2023-05-04T16:33:04.947715993Z I0504 16:33:04.945953       1 tasks_processing.go:71] worker 1 working on authentication task.
2023-05-04T16:33:04.948981578Z I0504 16:33:04.948199       1 tasks_processing.go:71] worker 6 working on machine_configs task.
2023-05-04T16:33:04.952028555Z I0504 16:33:04.951916       1 gather.go:180] gatherer "clusterconfig" function "host_subnets" took 2.777682ms to process 0 records
2023-05-04T16:33:04.952082045Z I0504 16:33:04.952073       1 gather.go:180] gatherer "clusterconfig" function "sap_config" took 6.173874ms to process 0 records
2023-05-04T16:33:04.952103035Z I0504 16:33:04.952096       1 tasks_processing.go:71] worker 8 working on openshift_logging task.
2023-05-04T16:33:04.954806828Z I0504 16:33:04.952935       1 tasks_processing.go:71] worker 10 working on silenced_alerts task.
2023-05-04T16:33:04.956949157Z I0504 16:33:04.956593       1 recorder.go:70] Recording config/crd/volumesnapshots.snapshot.storage.k8s.io with fingerprint=06d23a6335a38edbc58c1974e35b9692361fd2cc7b6c26c9642895fa2b662db9
2023-05-04T16:33:04.957434748Z I0504 16:33:04.957423       1 recorder.go:70] Recording config/crd/volumesnapshotcontents.snapshot.storage.k8s.io with fingerprint=c14ae6f5b67ba3c88d768061277086a49870420126f1219955ba2635c8fd8251
2023-05-04T16:33:04.957461849Z I0504 16:33:04.957453       1 gather.go:180] gatherer "clusterconfig" function "crds" took 76.923332ms to process 2 records
2023-05-04T16:33:04.957643330Z I0504 16:33:04.957633       1 recorder.go:70] Recording config/authentication with fingerprint=1345cd1911d860bbed605f3d6c2205288d79a10cc93e892beed48c40a61fc59d
2023-05-04T16:33:04.957666804Z I0504 16:33:04.957659       1 gather.go:180] gatherer "clusterconfig" function "authentication" took 8.088246ms to process 1 records
2023-05-04T16:33:04.962265352Z I0504 16:33:04.962116       1 tasks_processing.go:71] worker 4 working on mutating_webhook_configurations task.
2023-05-04T16:33:04.962666074Z I0504 16:33:04.962647       1 tasks_processing.go:71] worker 15 working on proxies task.
2023-05-04T16:33:04.965755511Z I0504 16:33:04.964992       1 recorder.go:70] Recording config/version with fingerprint=61e13e57576e6bbd0ef4eb750791459fe7b32a12cef9039e776ceed4612f5a33
2023-05-04T16:33:04.965755511Z I0504 16:33:04.965011       1 recorder.go:70] Recording config/id with fingerprint=ce9fe64408ec18c0573ef9be03fd4a143bc29898e33d0347cf715e07a6155496
2023-05-04T16:33:04.966127749Z I0504 16:33:04.966106       1 tasks_processing.go:71] worker 3 working on container_runtime_configs task.
2023-05-04T16:33:04.966823425Z I0504 16:33:04.966379       1 tasks_processing.go:71] worker 1 working on metrics task.
2023-05-04T16:33:04.970477801Z I0504 16:33:04.970116       1 recorder.go:70] Recording config/pod/openshift-cluster-version/cluster-version-operator-7544974f8f-tjk7v with fingerprint=db72b1d08fea3e6e9bc3c01dd698d013d1b5a5e815b6d6746a398f07beb0fe6a
2023-05-04T16:33:04.970598067Z I0504 16:33:04.970588       1 recorder.go:70] Recording events/openshift-cluster-version with fingerprint=33bd4acab32d6a0f35423a5df764e36426366ca5fbe7ff498c18a58c4ea9c59a
2023-05-04T16:33:04.970623956Z I0504 16:33:04.970616       1 gather.go:180] gatherer "clusterconfig" function "version" took 283.388537ms to process 4 records
2023-05-04T16:33:04.970643743Z I0504 16:33:04.970637       1 gather.go:180] gatherer "clusterconfig" function "openshift_logging" took 12.378165ms to process 0 records
2023-05-04T16:33:04.970665504Z E0504 16:33:04.970658       1 gather.go:143] gatherer "clusterconfig" function "config_maps" failed with the error: configmaps "cluster-monitoring-config" not found
2023-05-04T16:33:04.970692665Z I0504 16:33:04.970686       1 recorder.go:70] Recording config/configmaps/openshift-config/admin-kubeconfig-client-ca/ca-bundle.crt with fingerprint=34cdf5d36d45a9e3ee7c2be31546e3d937ae4ebf144ac07b0210c06a1610a94d
2023-05-04T16:33:04.970714385Z I0504 16:33:04.970708       1 recorder.go:70] Recording config/configmaps/openshift-config/etcd-ca-bundle/ca-bundle.crt with fingerprint=34cdf5d36d45a9e3ee7c2be31546e3d937ae4ebf144ac07b0210c06a1610a94d
2023-05-04T16:33:04.970739452Z W0504 16:33:04.970729       1 gather.go:158] issue recording gatherer "clusterconfig" function "config_maps" result "config/configmaps/openshift-config/etcd-ca-bundle/ca-bundle.crt" because of the warning: warning: the record with the same fingerprint "34cdf5d36d45a9e3ee7c2be31546e3d937ae4ebf144ac07b0210c06a1610a94d" was already recorded at path "config/configmaps/openshift-config/admin-kubeconfig-client-ca/ca-bundle.crt", recording another one with a different path "config/configmaps/openshift-config/etcd-ca-bundle/ca-bundle.crt"
2023-05-04T16:33:04.970761193Z I0504 16:33:04.970755       1 recorder.go:70] Recording config/configmaps/openshift-config/etcd-metric-serving-ca/ca-bundle.crt with fingerprint=34cdf5d36d45a9e3ee7c2be31546e3d937ae4ebf144ac07b0210c06a1610a94d
2023-05-04T16:33:04.970782633Z W0504 16:33:04.970775       1 gather.go:158] issue recording gatherer "clusterconfig" function "config_maps" result "config/configmaps/openshift-config/etcd-metric-serving-ca/ca-bundle.crt" because of the warning: warning: the record with the same fingerprint "34cdf5d36d45a9e3ee7c2be31546e3d937ae4ebf144ac07b0210c06a1610a94d" was already recorded at path "config/configmaps/openshift-config/etcd-ca-bundle/ca-bundle.crt", recording another one with a different path "config/configmaps/openshift-config/etcd-metric-serving-ca/ca-bundle.crt"
2023-05-04T16:33:04.970805075Z I0504 16:33:04.970798       1 recorder.go:70] Recording config/configmaps/openshift-config/etcd-serving-ca/ca-bundle.crt with fingerprint=34cdf5d36d45a9e3ee7c2be31546e3d937ae4ebf144ac07b0210c06a1610a94d
2023-05-04T16:33:04.970825283Z W0504 16:33:04.970818       1 gather.go:158] issue recording gatherer "clusterconfig" function "config_maps" result "config/configmaps/openshift-config/etcd-serving-ca/ca-bundle.crt" because of the warning: warning: the record with the same fingerprint "34cdf5d36d45a9e3ee7c2be31546e3d937ae4ebf144ac07b0210c06a1610a94d" was already recorded at path "config/configmaps/openshift-config/etcd-metric-serving-ca/ca-bundle.crt", recording another one with a different path "config/configmaps/openshift-config/etcd-serving-ca/ca-bundle.crt"
2023-05-04T16:33:04.970868965Z I0504 16:33:04.970861       1 recorder.go:70] Recording config/configmaps/openshift-config/initial-kube-apiserver-server-ca/ca-bundle.crt with fingerprint=b115cabb75d3a5abd871b8626a1e9e91f4b87698e6f540c0d58abddc29c34240
2023-05-04T16:33:04.970908069Z I0504 16:33:04.970901       1 recorder.go:70] Recording config/configmaps/openshift-config/kube-root-ca.crt/ca.crt with fingerprint=8f83ef1ecfe5c8bf1cdc6211109047b8218a3e3824396ed4c00cdb684c75b209
2023-05-04T16:33:04.970925602Z I0504 16:33:04.970919       1 recorder.go:70] Recording config/configmaps/openshift-config/openshift-install-manifests/invoker with fingerprint=04f8996da763b7a969b1028ee3007569eaf3a635486ddab211d512c85b9df8fb
2023-05-04T16:33:04.970942153Z I0504 16:33:04.970936       1 recorder.go:70] Recording config/configmaps/openshift-config/openshift-install-manifests/version with fingerprint=678bc2ab673ae8f811ba4e95eb34d4a0d62dcd07a2f4ed0b69b94af3193ce00d
2023-05-04T16:33:04.971008116Z I0504 16:33:04.970999       1 recorder.go:70] Recording config/configmaps/openshift-config/openshift-service-ca.crt/service-ca.crt with fingerprint=34cdf5d36d45a9e3ee7c2be31546e3d937ae4ebf144ac07b0210c06a1610a94d
2023-05-04T16:33:04.971043984Z W0504 16:33:04.971026       1 gather.go:158] issue recording gatherer "clusterconfig" function "config_maps" result "config/configmaps/openshift-config/openshift-service-ca.crt/service-ca.crt" because of the warning: warning: the record with the same fingerprint "34cdf5d36d45a9e3ee7c2be31546e3d937ae4ebf144ac07b0210c06a1610a94d" was already recorded at path "config/configmaps/openshift-config/etcd-serving-ca/ca-bundle.crt", recording another one with a different path "config/configmaps/openshift-config/openshift-service-ca.crt/service-ca.crt"
2023-05-04T16:33:04.971107603Z I0504 16:33:04.971099       1 recorder.go:70] Recording config/configmaps/kube-system/cluster-config-v1 with fingerprint=083de95c5f401dfd87a0f16d6fb12ae369eccd8a54654fb98afe933578a6e6b3
2023-05-04T16:33:04.971129204Z I0504 16:33:04.971122       1 gather.go:180] gatherer "clusterconfig" function "config_maps" took 179.174338ms to process 10 records
2023-05-04T16:33:04.971149191Z I0504 16:33:04.971142       1 gather.go:180] gatherer "clusterconfig" function "openshift_machine_api_events" took 40.885223ms to process 0 records
2023-05-04T16:33:04.971167636Z I0504 16:33:04.971161       1 tasks_processing.go:71] worker 12 working on infrastructures task.
2023-05-04T16:33:04.971276270Z I0504 16:33:04.971266       1 tasks_processing.go:71] worker 13 working on machine_sets task.
2023-05-04T16:33:04.971369084Z I0504 16:33:04.971359       1 tasks_processing.go:71] worker 8 working on pod_network_connectivity_checks task.
2023-05-04T16:33:04.981591714Z E0504 16:33:04.980435       1 tsdb_status.go:34] Unable to tsdb status: Get "https://prometheus-k8s.openshift-monitoring.svc:9091/api/v1/status/tsdb": dial tcp 172.30.65.195:9091: connect: connection refused
2023-05-04T16:33:04.981591714Z I0504 16:33:04.980457       1 tasks_processing.go:71] worker 9 working on support_secret task.
2023-05-04T16:33:04.981591714Z E0504 16:33:04.980505       1 recent_metrics.go:76] Unable to retrieve most recent metrics: Get "https://prometheus-k8s.openshift-monitoring.svc:9091/federate?match%5B%5D=etcd_object_counts&match%5B%5D=cluster_installer&match%5B%5D=namespace%3Acontainer_cpu_usage_seconds_total%3Asum_rate&match%5B%5D=namespace%3Acontainer_memory_usage_bytes%3Asum&match%5B%5D=vsphere_node_hw_version_total&match%5B%5D=virt_platform&match%5B%5D=console_helm_installs_total&match%5B%5D=console_helm_upgrades_total&match%5B%5D=console_helm_uninstalls_total": dial tcp 172.30.65.195:9091: connect: connection refused
2023-05-04T16:33:04.981591714Z E0504 16:33:04.980699       1 gather.go:143] gatherer "clusterconfig" function "tsdb_status" failed with the error: Get "https://prometheus-k8s.openshift-monitoring.svc:9091/api/v1/status/tsdb": dial tcp 172.30.65.195:9091: connect: connection refused
2023-05-04T16:33:04.981591714Z I0504 16:33:04.980923       1 gather.go:180] gatherer "clusterconfig" function "tsdb_status" took 54.822875ms to process 0 records
2023-05-04T16:33:04.981591714Z I0504 16:33:04.980934       1 gather.go:180] gatherer "clusterconfig" function "support_secret" took 891ns to process 0 records
2023-05-04T16:33:04.981591714Z E0504 16:33:04.980944       1 gather.go:143] gatherer "clusterconfig" function "metrics" failed with the error: Get "https://prometheus-k8s.openshift-monitoring.svc:9091/federate?match%5B%5D=etcd_object_counts&match%5B%5D=cluster_installer&match%5B%5D=namespace%3Acontainer_cpu_usage_seconds_total%3Asum_rate&match%5B%5D=namespace%3Acontainer_memory_usage_bytes%3Asum&match%5B%5D=vsphere_node_hw_version_total&match%5B%5D=virt_platform&match%5B%5D=console_helm_installs_total&match%5B%5D=console_helm_upgrades_total&match%5B%5D=console_helm_uninstalls_total": dial tcp 172.30.65.195:9091: connect: connection refused
2023-05-04T16:33:04.981591714Z I0504 16:33:04.981000       1 gather.go:180] gatherer "clusterconfig" function "metrics" took 14.131686ms to process 0 records
2023-05-04T16:33:04.981591714Z I0504 16:33:04.981017       1 tasks_processing.go:71] worker 1 working on openshift_sdn_controller_logs task.
2023-05-04T16:33:04.982344547Z I0504 16:33:04.982242       1 tasks_processing.go:71] worker 9 working on ingress task.
2023-05-04T16:33:05.043366644Z W0504 16:33:05.043316       1 operators.go:101] Can't read operator resource versions: %vunable to retrieve the complete list of server APIs: apps.openshift.io/v1: the server is currently unable to handle the request, authorization.openshift.io/v1: the server is currently unable to handle the request, build.openshift.io/v1: the server is currently unable to handle the request, image.openshift.io/v1: the server is currently unable to handle the request, metrics.k8s.io/v1beta1: the server is currently unable to handle the request, oauth.openshift.io/v1: the server is currently unable to handle the request, packages.operators.coreos.com/v1: the server is currently unable to handle the request, project.openshift.io/v1: the server is currently unable to handle the request, quota.openshift.io/v1: the server is currently unable to handle the request, route.openshift.io/v1: the server is currently unable to handle the request, security.openshift.io/v1: the server is currently unable to handle the request, template.openshift.io/v1: the server is currently unable to handle the request, user.openshift.io/v1: the server is currently unable to handle the request
2023-05-04T16:33:05.043422288Z I0504 16:33:05.043414       1 tasks_processing.go:71] worker 14 working on ceph_cluster task.
2023-05-04T16:33:05.043726349Z I0504 16:33:05.043714       1 recorder.go:70] Recording config/clusteroperator/authentication with fingerprint=1efd3f21ee71b660a4ae53585f28e78ce7f8f2091d6db18979e30642cbf538c7
2023-05-04T16:33:05.043773898Z I0504 16:33:05.043766       1 recorder.go:70] Recording config/clusteroperator/baremetal with fingerprint=4bf59119c135fb1cdcdf2749d25518ad973dab155f25cbc9817b63927e401f3c
2023-05-04T16:33:05.043818882Z I0504 16:33:05.043811       1 recorder.go:70] Recording config/clusteroperator/cloud-controller-manager with fingerprint=0e8e6b710c1961eb8dd6e6acb614f23d31325bff863dd583b5562240674169a9
2023-05-04T16:33:05.043892691Z I0504 16:33:05.043885       1 recorder.go:70] Recording config/clusteroperator/cloud-credential with fingerprint=20b979683e2a805f92c744c887f1e9438f6843d0eff24039d727076fc0cc4e17
2023-05-04T16:33:05.043938347Z I0504 16:33:05.043931       1 recorder.go:70] Recording config/clusteroperator/cluster-autoscaler with fingerprint=e9b9d816a2c9b9340b12183cc1b6106f3c73d639880cc7805b065f0b6568ec1b
2023-05-04T16:33:05.043988491Z I0504 16:33:05.043980       1 recorder.go:70] Recording config/clusteroperator/config-operator with fingerprint=e19ab07be91edcff155450ff113ac630be3649e9991ab76407ad5e3ece794180
2023-05-04T16:33:05.044032834Z I0504 16:33:05.044025       1 recorder.go:70] Recording config/clusteroperator/console with fingerprint=9644a9e7590df8301a39384f81c15ad9b0399742f4fafb04f4710d31f4e4c946
2023-05-04T16:33:05.044092065Z I0504 16:33:05.044084       1 recorder.go:70] Recording config/clusteroperator/control-plane-machine-set with fingerprint=d4ea52e71465f005b4535efe64ff28f0cec1826997f78004f6cf0affb61b2059
2023-05-04T16:33:05.044135296Z I0504 16:33:05.044128       1 recorder.go:70] Recording config/clusteroperator/csi-snapshot-controller with fingerprint=33d3ab32d5328de8530c5dde172d4708288791be7552f75c5c212c94b74273c7
2023-05-04T16:33:05.044175632Z I0504 16:33:05.044168       1 recorder.go:70] Recording config/clusteroperator/dns with fingerprint=b1fd2fcc5989be8689cec34fd094b4d293c8b82320fc23c7e480421f331ac43e
2023-05-04T16:33:05.044214865Z I0504 16:33:05.044208       1 recorder.go:70] Recording config/clusteroperator/etcd with fingerprint=a83c76d10208792d7d4dd39ada60f9d7487ffb6cf1604ebebcc61591310f068d
2023-05-04T16:33:05.044275379Z I0504 16:33:05.044246       1 recorder.go:70] Recording config/clusteroperator/image-registry with fingerprint=43df41c72168dab50474066f8fa510b902f6e20c821ef40b6d9adecbc2eb4aa2
2023-05-04T16:33:05.044321796Z I0504 16:33:05.044314       1 recorder.go:70] Recording config/clusteroperator/ingress with fingerprint=daa4bbf899bf3fb87078dbb22ad598b8efd4e04244fdf3570341a9205fa62dd2
2023-05-04T16:33:05.044369736Z I0504 16:33:05.044362       1 recorder.go:70] Recording config/clusteroperator/insights with fingerprint=4cfdaf7c1ba005b69ae1335d193ac51f3bd7031b6ab70801a2a9e6e03533f0c6
2023-05-04T16:33:05.044414961Z I0504 16:33:05.044408       1 recorder.go:70] Recording config/clusteroperator/kube-apiserver with fingerprint=debdaf9e5fc75b12eaa2c76b3f5b77267af9ced2d4b6253af5b9f5e965647ba3
2023-05-04T16:33:05.044508907Z I0504 16:33:05.044500       1 recorder.go:70] Recording config/clusteroperator/kube-controller-manager with fingerprint=e6cff0ee0723f5ffb842637f741ef8a56242ab0317840e3a29d7852e438fc601
2023-05-04T16:33:05.044559873Z I0504 16:33:05.044552       1 recorder.go:70] Recording config/clusteroperator/kube-scheduler with fingerprint=83db24d90f13ef1356adb0fb5ebdcdbd7675c21893b3d4b89ee27f69eaaef63d
2023-05-04T16:33:05.044599868Z I0504 16:33:05.044592       1 recorder.go:70] Recording config/clusteroperator/kube-storage-version-migrator with fingerprint=ccfc84876c229c3c6045ca9f1b222124b85c2dac1cc752fb3176035277a7255c
2023-05-04T16:33:05.044692291Z I0504 16:33:05.044637       1 recorder.go:70] Recording config/clusteroperator/machine-api with fingerprint=a8bee862f72e44e2668646fec5444489731624daf8a91570871ed01e37b8f2e6
2023-05-04T16:33:05.044735693Z I0504 16:33:05.044727       1 recorder.go:70] Recording config/clusteroperator/machine-approver with fingerprint=eebf2b65b9d350fa13d6687832f6025c629ac4e3f1253855ed23f79697b71a29
2023-05-04T16:33:05.044782340Z I0504 16:33:05.044775       1 recorder.go:70] Recording config/clusteroperator/machine-config with fingerprint=915af78d83cf1d1e5c458af02c481ade1b4afd11e6339d81a7ed17be09d05f21
2023-05-04T16:33:05.044828276Z I0504 16:33:05.044816       1 recorder.go:70] Recording config/clusteroperator/marketplace with fingerprint=4a0f21077f08643866287c5f8c816517c108220f6f54314f04273c393ac1c19d
2023-05-04T16:33:05.044875294Z I0504 16:33:05.044868       1 recorder.go:70] Recording config/clusteroperator/monitoring with fingerprint=3e0db66ece6258b200f1353748a8d3530a988c84f90eab8f8d8995a95e127f53
2023-05-04T16:33:05.045019455Z I0504 16:33:05.044987       1 recorder.go:70] Recording config/clusteroperator/network with fingerprint=e8ed6ea6ec0ee0ed10718f4072d9c6b3099df82d0718596a56dcf0a4762a4d28
2023-05-04T16:33:05.045062626Z I0504 16:33:05.045055       1 recorder.go:70] Recording config/clusteroperator/node-tuning with fingerprint=fc13144fb589caa4d387013d21cbf2df49f956db3e6c26d9faef9c139cde8667
2023-05-04T16:33:05.045111317Z I0504 16:33:05.045104       1 recorder.go:70] Recording config/clusteroperator/openshift-apiserver with fingerprint=ba48d0afa4c3f70f93533747087859413a8a8e29a8dd95eb8936a9c120c66b3f
2023-05-04T16:33:05.045149539Z I0504 16:33:05.045143       1 recorder.go:70] Recording config/clusteroperator/openshift-controller-manager with fingerprint=89f3e2de4ed2d1c0132e5258ddf0fa7f346f7cac170a5db88adaeba1787c3d8e
2023-05-04T16:33:05.045182541Z I0504 16:33:05.045176       1 recorder.go:70] Recording config/clusteroperator/openshift-samples with fingerprint=6ef24af6838a62f114529e7a2b8e34385c8dc60c92e688cdc008561915c2d060
2023-05-04T16:33:05.045256239Z I0504 16:33:05.045248       1 recorder.go:70] Recording config/clusteroperator/operator-lifecycle-manager with fingerprint=462ad5bd6d9c13cc1b47ce253dae1d588fec32ed5a53d4d99f0a10deea23d0b5
2023-05-04T16:33:05.045296735Z I0504 16:33:05.045289       1 recorder.go:70] Recording config/clusteroperator/operator-lifecycle-manager-catalog with fingerprint=ebc9040ec802a9b1125d8f1f1904595278c0daaf5e332aeff907eebeea2a8939
2023-05-04T16:33:05.045333153Z I0504 16:33:05.045326       1 recorder.go:70] Recording config/clusteroperator/operator-lifecycle-manager-packageserver with fingerprint=1dcd5d8ea13840e60fd3d468a502003eaaa51af534516125dcfff214f1a27f46
2023-05-04T16:33:05.045369291Z I0504 16:33:05.045362       1 recorder.go:70] Recording config/clusteroperator/service-ca with fingerprint=e5b59a726b16c18a272f1680cacb6d6963ddc0009f183de59bf2467f19592d0a
2023-05-04T16:33:05.045412963Z I0504 16:33:05.045402       1 recorder.go:70] Recording config/clusteroperator/storage with fingerprint=9200f635b1cce268441cb1956f5af47e67b138fd39eb4108d24901435425b85f
2023-05-04T16:33:05.045434434Z I0504 16:33:05.045427       1 gather.go:180] gatherer "clusterconfig" function "operators" took 253.468367ms to process 33 records
2023-05-04T16:33:05.045545632Z I0504 16:33:05.045535       1 tasks_processing.go:71] worker 14 working on active_alerts task.
2023-05-04T16:33:05.045880901Z I0504 16:33:05.045868       1 gather.go:180] gatherer "clusterconfig" function "ceph_cluster" took 2.100491ms to process 0 records
2023-05-04T16:33:05.050112411Z I0504 16:33:05.050085       1 tasks_processing.go:71] worker 6 working on scheduler_logs task.
2023-05-04T16:33:05.050343996Z I0504 16:33:05.050333       1 recorder.go:70] Recording config/machineconfigs/00-master with fingerprint=acabf1fda5cc6909ce4f35367196635f3fae4fcd36b0ae1756c2623531914a5d
2023-05-04T16:33:05.051556080Z I0504 16:33:05.050584       1 recorder.go:70] Recording config/machineconfigs/00-worker with fingerprint=fb109d938c194334c7b432abe0fb7aad3e5e99ee7bcf45eb222daf28c288c91e
2023-05-04T16:33:05.051656388Z I0504 16:33:05.051644       1 recorder.go:70] Recording config/machineconfigs/01-master-container-runtime with fingerprint=80dd4bc6d57e9dc37f6fc9dcc79607ca3b34e6564a35aa5843fe56f49871ac97
2023-05-04T16:33:05.051729976Z I0504 16:33:05.051722       1 recorder.go:70] Recording config/machineconfigs/01-master-kubelet with fingerprint=927d5399cd7a3b8b15246e5c9d151d6e7ef0782f1998f66b0f7e92c7b7c2d789
2023-05-04T16:33:05.051779779Z I0504 16:33:05.051772       1 recorder.go:70] Recording config/machineconfigs/01-worker-container-runtime with fingerprint=3196a78f9ec1060681045e7f570ead88bbae0d1b135d6e48e7438713cb07148c
2023-05-04T16:33:05.051855251Z I0504 16:33:05.051847       1 recorder.go:70] Recording config/machineconfigs/01-worker-kubelet with fingerprint=99688bbcb30624daef4c88311c1b39273db871dd22392a551d3e4b4e03da0a83
2023-05-04T16:33:05.053051716Z I0504 16:33:05.052175       1 recorder.go:70] Recording config/machineconfigs/99-master-generated-registries with fingerprint=a24dcc4dc28d25513e10398975d7fca40c6f3e754e6857aa8a1741b30db75cf9
2023-05-04T16:33:05.053113612Z I0504 16:33:05.053104       1 recorder.go:70] Recording config/machineconfigs/99-master-ssh with fingerprint=247ee91099b8c8149129568c17bc87bf9b3058154cd58c4b3f2683b61db93799
2023-05-04T16:33:05.053161492Z I0504 16:33:05.053154       1 recorder.go:70] Recording config/machineconfigs/99-worker-generated-registries with fingerprint=f18e8d08689a82855560665aa586466ea29eb4f8aa8b0210613df54be7214ed5
2023-05-04T16:33:05.053341610Z I0504 16:33:05.053331       1 recorder.go:70] Recording config/machineconfigs/99-worker-ssh with fingerprint=4c1c3a062d5b75efd7fd5da072666dc939b284abb1bb6a384418a2563cce774e
2023-05-04T16:33:05.054038778Z I0504 16:33:05.054027       1 recorder.go:70] Recording config/machineconfigs/rendered-master-fa45321130bb3e39d5868f5cd1a6f593 with fingerprint=30cad36815f12749651ca1acec67fa254e18b6ef2098073ef5b8f8187ad9c021
2023-05-04T16:33:05.054226981Z I0504 16:33:05.054218       1 recorder.go:70] Recording config/machineconfigs/rendered-worker-2535121dc3ab02d4fb8debe0352afadb with fingerprint=33a2d56260cac23cefed38aceb0409f8cc7735d7a98596c676f23a1e02b399e6
2023-05-04T16:33:05.054252018Z I0504 16:33:05.054243       1 gather.go:180] gatherer "clusterconfig" function "machine_configs" took 98.556764ms to process 12 records
2023-05-04T16:33:05.062903932Z I0504 16:33:05.062874       1 tasks_processing.go:71] worker 14 working on service_accounts task.
2023-05-04T16:33:05.062994582Z I0504 16:33:05.062948       1 recorder.go:70] Recording config/alerts with fingerprint=4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945
2023-05-04T16:33:05.063014890Z W0504 16:33:05.063000       1 gather.go:158] issue recording gatherer "clusterconfig" function "active_alerts" result "config/alerts.json" because of the warning: warning: the record with the same fingerprint "4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945" was already recorded at path "config/namespaces_with_overlapping_uids.json", recording another one with a different path "config/alerts.json"
2023-05-04T16:33:05.063014890Z I0504 16:33:05.063009       1 gather.go:180] gatherer "clusterconfig" function "active_alerts" took 17.308417ms to process 1 records
2023-05-04T16:33:05.063626127Z I0504 16:33:05.063600       1 tasks_processing.go:71] worker 10 working on storage_cluster task.
2023-05-04T16:33:05.063678716Z I0504 16:33:05.063666       1 recorder.go:70] Recording config/silenced_alerts.json with fingerprint=37517e5f3dc66819f61f5a7bb8ace1921282415f10551d2defa5c3eb0985b570
2023-05-04T16:33:05.063686570Z I0504 16:33:05.063677       1 gather.go:180] gatherer "clusterconfig" function "silenced_alerts" took 106.984457ms to process 1 records
2023-05-04T16:33:05.064940523Z I0504 16:33:05.064913       1 tasks_processing.go:71] worker 10 working on sap_pods task.
2023-05-04T16:33:05.065232331Z I0504 16:33:05.065216       1 gather.go:180] gatherer "clusterconfig" function "storage_cluster" took 1.295942ms to process 0 records
2023-05-04T16:33:05.065855871Z I0504 16:33:05.065844       1 tasks_processing.go:71] worker 10 working on feature_gates task.
2023-05-04T16:33:05.065930631Z I0504 16:33:05.065871       1 gather.go:180] gatherer "clusterconfig" function "sap_pods" took 917.672s to process 0 records
2023-05-04T16:33:05.160260784Z I0504 16:33:05.160217       1 tasks_processing.go:71] worker 3 working on networks task.
2023-05-04T16:33:05.160390337Z I0504 16:33:05.160360       1 gather.go:180] gatherer "clusterconfig" function "container_runtime_configs" took 194.092148ms to process 0 records
2023-05-04T16:33:05.166388422Z I0504 16:33:05.162438       1 tasks_processing.go:71] worker 4 working on certificate_signing_requests task.
2023-05-04T16:33:05.166388422Z I0504 16:33:05.162765       1 gather.go:180] gatherer "clusterconfig" function "mutating_webhook_configurations" took 200.298644ms to process 0 records
2023-05-04T16:33:05.167774673Z I0504 16:33:05.167140       1 tasks_processing.go:71] worker 4 working on oauths task.
2023-05-04T16:33:05.167774673Z I0504 16:33:05.167444       1 gather.go:180] gatherer "clusterconfig" function "certificate_signing_requests" took 4.676645ms to process 0 records
2023-05-04T16:33:05.167774673Z I0504 16:33:05.167504       1 recorder.go:70] Recording config/proxy with fingerprint=1d43dfe530a46e7e4a398048c020301f58d72ef0d0e0f7a1ade4951756d2876a
2023-05-04T16:33:05.167774673Z I0504 16:33:05.167511       1 gather.go:180] gatherer "clusterconfig" function "proxies" took 204.621385ms to process 1 records
2023-05-04T16:33:05.167774673Z I0504 16:33:05.167566       1 recorder.go:70] Recording config/featuregate with fingerprint=e270958e75df290e33fd14e3a1f26ab3af7f7e06c8c4662c03d569da78e0de3a
2023-05-04T16:33:05.167774673Z I0504 16:33:05.167572       1 gather.go:180] gatherer "clusterconfig" function "feature_gates" took 101.444772ms to process 1 records
2023-05-04T16:33:05.167774673Z I0504 16:33:05.167579       1 tasks_processing.go:74] worker 10 stopped.
2023-05-04T16:33:05.167774673Z I0504 16:33:05.167583       1 tasks_processing.go:74] worker 15 stopped.
2023-05-04T16:33:05.169394882Z I0504 16:33:05.168922       1 tasks_processing.go:74] worker 9 stopped.
2023-05-04T16:33:05.169394882Z I0504 16:33:05.169112       1 recorder.go:70] Recording config/ingress with fingerprint=781a0b8ee5796efd6fc80b9fff891a01af47b36baf9ea4f75188a913d17e7ac5
2023-05-04T16:33:05.169394882Z I0504 16:33:05.169124       1 gather.go:180] gatherer "clusterconfig" function "ingress" took 186.656186ms to process 1 records
2023-05-04T16:33:05.169506041Z I0504 16:33:05.169496       1 tasks_processing.go:74] worker 12 stopped.
2023-05-04T16:33:05.169866277Z I0504 16:33:05.169515       1 recorder.go:70] Recording config/infrastructure with fingerprint=2d9683e273fbbc5188e978b3d62ea82188cb5acdef1d98809b1424c27b0ec63d
2023-05-04T16:33:05.169949884Z I0504 16:33:05.169935       1 gather.go:180] gatherer "clusterconfig" function "infrastructures" took 197.881328ms to process 1 records
2023-05-04T16:33:05.173287496Z I0504 16:33:05.173248       1 recorder.go:70] Recording config/network with fingerprint=af2cda9e5ed3e939a5ffd44d5a75116a02a299b30e84fb30087ab60b6075519e
2023-05-04T16:33:05.173287496Z I0504 16:33:05.173273       1 gather.go:180] gatherer "clusterconfig" function "networks" took 9.4761ms to process 1 records
2023-05-04T16:33:05.173287496Z I0504 16:33:05.173281       1 gather.go:180] gatherer "clusterconfig" function "machine_sets" took 198.440868ms to process 0 records
2023-05-04T16:33:05.173334535Z I0504 16:33:05.173325       1 tasks_processing.go:74] worker 13 stopped.
2023-05-04T16:33:05.173483534Z I0504 16:33:05.173462       1 tasks_processing.go:74] worker 3 stopped.
2023-05-04T16:33:05.173483534Z I0504 16:33:05.169750       1 gather_logs.go:132] no pods in openshift-sdn namespace were found
2023-05-04T16:33:05.173483534Z I0504 16:33:05.173473       1 tasks_processing.go:74] worker 1 stopped.
2023-05-04T16:33:05.173483534Z I0504 16:33:05.173477       1 gather.go:180] gatherer "clusterconfig" function "openshift_sdn_controller_logs" took 192.452812ms to process 0 records
2023-05-04T16:33:05.174005203Z I0504 16:33:05.173938       1 tasks_processing.go:74] worker 4 stopped.
2023-05-04T16:33:05.174495763Z I0504 16:33:05.174481       1 recorder.go:70] Recording config/oauth with fingerprint=9d910ae7f0dcb338bb7cc4e0ed40b9df5d0c7c8c794cdd32a78dbbfb150f2c47
2023-05-04T16:33:05.174525629Z I0504 16:33:05.174516       1 gather.go:180] gatherer "clusterconfig" function "oauths" took 6.783327ms to process 1 records
2023-05-04T16:33:05.176857385Z I0504 16:33:05.176830       1 tasks_processing.go:74] worker 11 stopped.
2023-05-04T16:33:05.177120739Z I0504 16:33:05.177085       1 recorder.go:70] Recording config/pod/openshift-apiserver/apiserver-65d8786fff-b42ll with fingerprint=2775eccac090dd98d7f3a35b7bddbaace10865f267ac637820e0c3e526eec49b
2023-05-04T16:33:05.177234081Z I0504 16:33:05.177224       1 recorder.go:70] Recording config/pod/openshift-authentication-operator/authentication-operator-68df59f464-mdvwv with fingerprint=cd4ce977561f011071a864d1bd68f615c905b5c6f392627d4cd586aa991ecd47
2023-05-04T16:33:05.177330372Z I0504 16:33:05.177322       1 recorder.go:70] Recording config/pod/openshift-cloud-credential-operator/cloud-credential-operator-fd47f96b9-8ks4f with fingerprint=0d97a135708aaf8c3a151be57aa2d9ffb65b79615f7efa38dc9cde293537d7f6
2023-05-04T16:33:05.177424950Z I0504 16:33:05.177415       1 recorder.go:70] Recording config/pod/openshift-cluster-machine-approver/machine-approver-879c4799-h65jk with fingerprint=c0e63feea6fdf5f9d9941f46d70b802481e8e0ef5054d7276fbe4418d303928b
2023-05-04T16:33:05.177531650Z I0504 16:33:05.177523       1 recorder.go:70] Recording config/pod/openshift-cluster-storage-operator/cluster-storage-operator-578bfd8476-tj45n with fingerprint=91ba3fa5a6512d334659e8be212ea7a70a176a99501edc1d34e88208df37ac34
2023-05-04T16:33:05.177620346Z I0504 16:33:05.177603       1 recorder.go:70] Recording config/pod/openshift-cluster-storage-operator/csi-snapshot-controller-6587df558d-kcwr4 with fingerprint=d0747b85ea15be1c1c4e4e2c10ecddfbbca4a6c0493092d363213922c1275cf5
2023-05-04T16:33:05.177701999Z I0504 16:33:05.177694       1 recorder.go:70] Recording config/pod/openshift-cluster-version/cluster-version-operator-7544974f8f-tjk7v with fingerprint=db72b1d08fea3e6e9bc3c01dd698d013d1b5a5e815b6d6746a398f07beb0fe6a
2023-05-04T16:33:05.177732306Z E0504 16:33:05.177723       1 gather.go:164] error recording gatherer "clusterconfig" function "container_images" result "config/pod/openshift-cluster-version/cluster-version-operator-7544974f8f-tjk7v.json" because of the error: the record with the same name "config/pod/openshift-cluster-version/cluster-version-operator-7544974f8f-tjk7v.json" was already recorded and had the fingerprint "db72b1d08fea3e6e9bc3c01dd698d013d1b5a5e815b6d6746a398f07beb0fe6a", overwriting with the record having fingerprint "db72b1d08fea3e6e9bc3c01dd698d013d1b5a5e815b6d6746a398f07beb0fe6a"
2023-05-04T16:33:05.177761621Z W0504 16:33:05.177750       1 gather.go:158] issue recording gatherer "clusterconfig" function "container_images" result "config/pod/openshift-cluster-version/cluster-version-operator-7544974f8f-tjk7v.json" because of the warning: warning: the record with the same fingerprint "db72b1d08fea3e6e9bc3c01dd698d013d1b5a5e815b6d6746a398f07beb0fe6a" was already recorded at path "config/pod/openshift-cluster-version/cluster-version-operator-7544974f8f-tjk7v.json", recording another one with a different path "config/pod/openshift-cluster-version/cluster-version-operator-7544974f8f-tjk7v.json"
2023-05-04T16:33:05.177908407Z I0504 16:33:05.177859       1 recorder.go:70] Recording config/pod/openshift-console/downloads-797d94d7f9-tb6j4 with fingerprint=d84eecc57250be970ef319f35dee8fb851b9569fd242a19eb79995b61a43b5a5
2023-05-04T16:33:05.178010809Z I0504 16:33:05.178001       1 recorder.go:70] Recording config/pod/openshift-controller-manager-operator/openshift-controller-manager-operator-967d9d7c4-xvgmx with fingerprint=ae484ad8181471352274a6624a5d86692e0c729c1d6312487c20e26bda478c64
2023-05-04T16:33:05.178143808Z I0504 16:33:05.178130       1 recorder.go:70] Recording config/pod/openshift-ingress/router-default-757b9d4d79-snzvp with fingerprint=709c8d012b9299ff92d6f7ad699bf3b33b5d8767d8728fafd2502f138c3608a0
2023-05-04T16:33:05.178217126Z I0504 16:33:05.178209       1 recorder.go:70] Recording config/pod/openshift-kube-storage-version-migrator/migrator-5c54d8d69d-k9vfh with fingerprint=e2c915af2b99b68a49420e2be1b7d49de9e89f69afda972576dea5690c8130d9
2023-05-04T16:33:05.178932728Z I0504 16:33:05.178913       1 recorder.go:70] Recording config/pod/openshift-machine-api/control-plane-machine-set-operator-749d766b67-qq96k with fingerprint=e7d208372da47358bf436042c0d4597dfcecff7b6d0022a54b1d736b4ff8cc66
2023-05-04T16:33:05.179034209Z I0504 16:33:05.179024       1 recorder.go:70] Recording config/pod/openshift-machine-api/machine-api-operator-df4db9c9b-4fbsv with fingerprint=6e195068e413cb7b8798a26bc4b7e5edf83083c16f1b61f23a1ce29508e516a6
2023-05-04T16:33:05.179099762Z I0504 16:33:05.179091       1 recorder.go:70] Recording config/pod/openshift-marketplace/certified-operators-5jwdq with fingerprint=c84caa800f041bde4882ba2f3d2f9a0ffb94f9adcaee7c24a05cefafc743bcc2
2023-05-04T16:33:05.179161969Z I0504 16:33:05.179153       1 recorder.go:70] Recording config/pod/openshift-marketplace/community-operators-kn87b with fingerprint=7cca8996ba52f9c6111c35ead15699980365a6ab8942de16f7420f6e48cf862a
2023-05-04T16:33:05.179218445Z I0504 16:33:05.179210       1 recorder.go:70] Recording config/pod/openshift-marketplace/community-operators-t8dwk with fingerprint=e8d48567a26105db56310caf2c05409a9ee8aa20348f567532a2bc222a93b015
2023-05-04T16:33:05.179277175Z I0504 16:33:05.179269       1 recorder.go:70] Recording config/pod/openshift-marketplace/redhat-marketplace-4hgh8 with fingerprint=d5175240be3874da5dc5e4a71057388b57d2fc5a15618cc6783b79aca484394a
2023-05-04T16:33:05.179333851Z I0504 16:33:05.179325       1 recorder.go:70] Recording config/pod/openshift-marketplace/redhat-operators-x54c6 with fingerprint=d0e466f275bc051bc2962f61bcbd51327c0ae4b65cc7659401708799376ff7ca
2023-05-04T16:33:05.179417228Z I0504 16:33:05.179409       1 recorder.go:70] Recording config/pod/openshift-monitoring/openshift-state-metrics-5ff95d844f-8nmnp with fingerprint=446a9d571d7870c60bb695195eb32970142ff3dd5c36ecc659bdc714e1b817f7
2023-05-04T16:33:05.179502608Z I0504 16:33:05.179491       1 recorder.go:70] Recording config/pod/openshift-monitoring/prometheus-adapter-868b97668c-fzkrw with fingerprint=83ff16a9e5de3e3d3716019da879a4b9935c3fa5e9fbee6d21d44e38af7cd330
2023-05-04T16:33:05.179702353Z I0504 16:33:05.179690       1 recorder.go:70] Recording config/pod/openshift-monitoring/prometheus-k8s-0 with fingerprint=817161fe2441023cc26a5f69ed284751bed5daaffd111012d5dd43284858bc13
2023-05-04T16:33:05.180060395Z I0504 16:33:05.180046       1 recorder.go:70] Recording config/pod/openshift-monitoring/thanos-querier-575965dcf-gnqvv with fingerprint=55788570e744856bd1702f5a0fab7b739d0f9ca3d96a110500eed6752823589f
2023-05-04T16:33:05.180170451Z I0504 16:33:05.180160       1 recorder.go:70] Recording config/pod/openshift-oauth-apiserver/apiserver-c486dbd69-dxjxl with fingerprint=aef6ee746c285cb4f71feab9de530650f8f0e3c7e03fb5bf622c375f42644733
2023-05-04T16:33:05.180232878Z I0504 16:33:05.180224       1 recorder.go:70] Recording config/pod/openshift-operator-lifecycle-manager/catalog-operator-76c4c9dd94-4n8wx with fingerprint=06633eccf458e250b70cb0b5bbca7ac1e6efa704fe412b88392776dfe425a0e2
2023-05-04T16:33:05.180293101Z I0504 16:33:05.180284       1 recorder.go:70] Recording config/pod/openshift-operator-lifecycle-manager/olm-operator-79f8b8bdc4-542cn with fingerprint=0e8ed9f591e9a24c1ab071a415d2a0a7c8214f3094883a9d10d3133590170d7d
2023-05-04T16:33:05.180353915Z I0504 16:33:05.180345       1 recorder.go:70] Recording config/pod/openshift-operator-lifecycle-manager/package-server-manager-55cc8b7f-6w2qg with fingerprint=bb636a765d0d65379e213d95232cde588637849ac6bdae80229485c686754f97
2023-05-04T16:33:05.180412615Z I0504 16:33:05.180404       1 recorder.go:70] Recording config/pod/openshift-operator-lifecycle-manager/packageserver-587b4f455-7gj2b with fingerprint=044e07975d4f0237338de9230d992e4a5512cdcebef332702d912f0123c9e38d
2023-05-04T16:33:05.180522712Z I0504 16:33:05.180514       1 recorder.go:70] Recording config/pod/openshift-storage/lvms-operator-65cb4bdf95-8qw5z with fingerprint=02f8e3cdb9acef2cd881be3766c46339012be183290f47c75e9f051ff9463821
2023-05-04T16:33:05.180627629Z I0504 16:33:05.180619       1 recorder.go:70] Recording config/pod/openshift-storage/topolvm-controller-5496f5d4f4-ll8f6 with fingerprint=0dca5b0475717ed0e3ee01466cbb44ba369bb623243ff8cc915a465dde9a9683
2023-05-04T16:33:05.180737365Z I0504 16:33:05.180720       1 recorder.go:70] Recording config/pod/openshift-storage/topolvm-node-7fjkf with fingerprint=57918463fe60428f4877a4e2278f808ed8a327a9e9ca20c113b65b3342b5feab
2023-05-04T16:33:05.180792258Z I0504 16:33:05.180780       1 recorder.go:70] Recording config/pod/openshift-storage/vg-manager-dq9h6 with fingerprint=734f5007d5426f480d3ee2f79473a48153459dce9645bbec89acb13bb101ba78
2023-05-04T16:33:05.180882587Z I0504 16:33:05.180871       1 recorder.go:70] Recording config/running_containers with fingerprint=2080daa329709c161583892ea1ceab57b24cd4d4bee0c1a540792ebdd6de7261
2023-05-04T16:33:05.180892225Z I0504 16:33:05.180879       1 gather.go:180] gatherer "clusterconfig" function "container_images" took 386.473436ms to process 32 records
2023-05-04T16:33:05.180917262Z I0504 16:33:05.180906       1 recorder.go:70] Recording config/podnetworkconnectivitychecks with fingerprint=44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a
2023-05-04T16:33:05.180917262Z I0504 16:33:05.180911       1 gather.go:180] gatherer "clusterconfig" function "pod_network_connectivity_checks" took 205.826586ms to process 1 records
2023-05-04T16:33:05.180924466Z I0504 16:33:05.180915       1 gather.go:180] gatherer "clusterconfig" function "openshift_authentication_logs" took 300.288075ms to process 0 records
2023-05-04T16:33:05.180924466Z I0504 16:33:05.180921       1 tasks_processing.go:74] worker 2 stopped.
2023-05-04T16:33:05.180929645Z I0504 16:33:05.180926       1 tasks_processing.go:74] worker 8 stopped.
2023-05-04T16:33:05.206167500Z I0504 16:33:05.205395       1 tasks_processing.go:74] worker 7 stopped.
2023-05-04T16:33:05.206201724Z I0504 16:33:05.205866       1 recorder.go:70] Recording config/pod/openshift-kube-controller-manager/logs/kube-controller-manager-node/errors.log with fingerprint=27e9b56e823c238f649092b3c63728724c8eed85744e9cb81ba02f9017b3f939
2023-05-04T16:33:05.206229105Z I0504 16:33:05.206219       1 gather.go:180] gatherer "clusterconfig" function "kube_controller_manager_logs" took 524.846368ms to process 1 records
2023-05-04T16:33:05.225921865Z I0504 16:33:05.225892       1 tasks_processing.go:74] worker 6 stopped.
2023-05-04T16:33:05.226002667Z I0504 16:33:05.225983       1 recorder.go:70] Recording config/pod/openshift-kube-scheduler/logs/openshift-kube-scheduler-node/messages.log with fingerprint=821f85f1aadec2bc7df1f04c88b4a1037a73e3057cccb27a7e28c66015436c12
2023-05-04T16:33:05.226035468Z I0504 16:33:05.226026       1 gather.go:180] gatherer "clusterconfig" function "scheduler_logs" took 175.787393ms to process 1 records
2023-05-04T16:33:05.264041710Z I0504 16:33:05.264011       1 request.go:533] Waited for 52.759334ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-cloud-controller-manager-operator/serviceaccounts?limit=1000
2023-05-04T16:33:05.312440742Z I0504 16:33:05.312405       1 request.go:533] Waited for 102.939627ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operators.coreos.com/v1alpha1/namespaces/openshift-cluster-node-tuning-operator/installplans?limit=500
2023-05-04T16:33:05.465115037Z I0504 16:33:05.464164       1 request.go:533] Waited for 169.855822ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-cloud-credential-operator/serviceaccounts?limit=1000
2023-05-04T16:33:05.512517028Z I0504 16:33:05.512382       1 request.go:533] Waited for 197.589931ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operators.coreos.com/v1alpha1/namespaces/openshift-cluster-samples-operator/installplans?limit=500
2023-05-04T16:33:06.047486510Z I0504 16:33:06.047448       1 controllerstatus.go:79] name=scaController healthy=false reason=NotFound message=Failed to pull SCA certs from https://api.openshift.com/api/accounts_mgmt/v1/certificates: OCM API https://api.openshift.com/api/accounts_mgmt/v1/certificates returned HTTP 404: {"code":"ACCT-MGMT-7","href":"/api/accounts_mgmt/v1/errors/7","id":"7","kind":"Error","operation_id":"f82ad084-743d-4543-b1ab-0efd330d202f","reason":"The organization (id= 1Mt47AoBiztIJKs0V9zRyQSeUGh) does not have any certificate of type sca. Enable SCA at https://access.redhat.com/management."}
2023-05-04T16:33:06.063521687Z I0504 16:33:06.063267       1 request.go:533] Waited for 93.820567ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-cluster-machine-approver/serviceaccounts?limit=1000
2023-05-04T16:33:06.113471819Z I0504 16:33:06.111955       1 request.go:533] Waited for 142.357418ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operators.coreos.com/v1alpha1/namespaces/openshift-config/installplans?limit=500
2023-05-04T16:33:06.146235654Z I0504 16:33:06.146203       1 cluster_transfer.go:97] no available accepted cluster transfer
2023-05-04T16:33:06.146285598Z I0504 16:33:06.146276       1 controllerstatus.go:70] name=clusterTransferController healthy=true reason=NoClusterTransfer message=no available cluster transfer
2023-05-04T16:33:06.464119194Z I0504 16:33:06.464085       1 request.go:533] Waited for 177.790421ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-cluster-samples-operator/serviceaccounts?limit=1000
2023-05-04T16:33:06.511940783Z I0504 16:33:06.511902       1 request.go:533] Waited for 126.955769ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operators.coreos.com/v1alpha1/namespaces/openshift-config-operator/installplans?limit=500
2023-05-04T16:33:06.663598320Z I0504 16:33:06.663564       1 request.go:533] Waited for 196.226262ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-cluster-storage-operator/serviceaccounts?limit=1000
2023-05-04T16:33:06.712729756Z I0504 16:33:06.712701       1 request.go:533] Waited for 55.159166ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operators.coreos.com/v1alpha1/namespaces/openshift-console/installplans?limit=500
2023-05-04T16:33:06.913786081Z I0504 16:33:06.913266       1 request.go:533] Waited for 73.246063ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operators.coreos.com/v1alpha1/namespaces/openshift-console-operator/installplans?limit=500
2023-05-04T16:33:07.064117510Z I0504 16:33:07.064083       1 request.go:533] Waited for 192.748026ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config/serviceaccounts?limit=1000
2023-05-04T16:33:07.112124777Z I0504 16:33:07.112090       1 request.go:533] Waited for 196.765515ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operators.coreos.com/v1alpha1/namespaces/openshift-console-user-settings/installplans?limit=500
2023-05-04T16:33:07.264044998Z I0504 16:33:07.264010       1 request.go:533] Waited for 197.989321ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/serviceaccounts?limit=1000
2023-05-04T16:33:07.312198789Z I0504 16:33:07.312158       1 request.go:533] Waited for 152.226455ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operators.coreos.com/v1alpha1/namespaces/openshift-controller-manager/installplans?limit=500
2023-05-04T16:33:07.464191185Z I0504 16:33:07.464162       1 request.go:533] Waited for 105.097316ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-operator/serviceaccounts?limit=1000
2023-05-04T16:33:07.512501039Z I0504 16:33:07.512471       1 request.go:533] Waited for 155.093414ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operators.coreos.com/v1alpha1/namespaces/openshift-controller-manager-operator/installplans?limit=500
2023-05-04T16:33:07.712967157Z I0504 16:33:07.712925       1 request.go:533] Waited for 62.991612ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operators.coreos.com/v1alpha1/namespaces/openshift-dns/installplans?limit=500
2023-05-04T16:33:07.864096173Z I0504 16:33:07.864056       1 request.go:533] Waited for 161.184042ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-console-operator/serviceaccounts?limit=1000
2023-05-04T16:33:07.913170842Z I0504 16:33:07.913036       1 request.go:533] Waited for 198.258545ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operators.coreos.com/v1alpha1/namespaces/openshift-dns-operator/installplans?limit=500
2023-05-04T16:33:08.064106586Z I0504 16:33:08.064067       1 request.go:533] Waited for 179.834586ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-console-user-settings/serviceaccounts?limit=1000
2023-05-04T16:33:08.112259626Z I0504 16:33:08.112226       1 request.go:533] Waited for 136.909565ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operators.coreos.com/v1alpha1/namespaces/openshift-etcd/installplans?limit=500
2023-05-04T16:33:08.264259937Z I0504 16:33:08.264226       1 request.go:533] Waited for 198.076735ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-controller-manager/serviceaccounts?limit=1000
2023-05-04T16:33:08.312605097Z I0504 16:33:08.312566       1 request.go:533] Waited for 198.55359ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operators.coreos.com/v1alpha1/namespaces/openshift-etcd-operator/installplans?limit=500
2023-05-04T16:33:08.463442205Z I0504 16:33:08.463403       1 request.go:533] Waited for 196.898403ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-controller-manager-operator/serviceaccounts?limit=1000
2023-05-04T16:33:08.512688918Z I0504 16:33:08.512650       1 request.go:533] Waited for 174.380944ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operators.coreos.com/v1alpha1/namespaces/openshift-host-network/installplans?limit=500
2023-05-04T16:33:08.664118627Z I0504 16:33:08.664091       1 request.go:533] Waited for 197.740534ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-dns/serviceaccounts?limit=1000
2023-05-04T16:33:08.712187179Z I0504 16:33:08.712148       1 request.go:533] Waited for 193.434976ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operators.coreos.com/v1alpha1/namespaces/openshift-image-registry/installplans?limit=500
2023-05-04T16:33:08.864219760Z I0504 16:33:08.864186       1 request.go:533] Waited for 198.121648ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-dns-operator/serviceaccounts?limit=1000
2023-05-04T16:33:08.912422083Z I0504 16:33:08.912387       1 request.go:533] Waited for 77.872704ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operators.coreos.com/v1alpha1/namespaces/openshift-infra/installplans?limit=500
2023-05-04T16:33:09.113429527Z I0504 16:33:09.112068       1 request.go:533] Waited for 52.330889ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operators.coreos.com/v1alpha1/namespaces/openshift-ingress/installplans?limit=500
2023-05-04T16:33:09.263294741Z I0504 16:33:09.263258       1 request.go:533] Waited for 177.285323ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/serviceaccounts?limit=1000
2023-05-04T16:33:09.312643014Z I0504 16:33:09.312609       1 request.go:533] Waited for 198.631405ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operators.coreos.com/v1alpha1/namespaces/openshift-ingress-canary/installplans?limit=500
2023-05-04T16:33:09.464951473Z I0504 16:33:09.464109       1 request.go:533] Waited for 195.677833ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-host-network/serviceaccounts?limit=1000
2023-05-04T16:33:09.513152112Z I0504 16:33:09.511974       1 request.go:533] Waited for 197.364878ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operators.coreos.com/v1alpha1/namespaces/openshift-ingress-operator/installplans?limit=500
2023-05-04T16:33:09.664172484Z I0504 16:33:09.664097       1 request.go:533] Waited for 194.827918ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-image-registry/serviceaccounts?limit=1000
2023-05-04T16:33:09.712207002Z I0504 16:33:09.712159       1 request.go:533] Waited for 143.577927ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operators.coreos.com/v1alpha1/namespaces/openshift-insights/installplans?limit=500
2023-05-04T16:33:09.864671824Z I0504 16:33:09.863633       1 request.go:533] Waited for 197.45079ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts?limit=1000
2023-05-04T16:33:10.066312616Z I0504 16:33:10.064116       1 request.go:533] Waited for 98.886612ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-ingress/serviceaccounts?limit=1000
2023-05-04T16:33:10.117102714Z I0504 16:33:10.113870       1 request.go:533] Waited for 65.254138ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operators.coreos.com/v1alpha1/namespaces/openshift-kube-apiserver/installplans?limit=500
2023-05-04T16:33:10.264270487Z I0504 16:33:10.264234       1 request.go:533] Waited for 177.517399ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-ingress-canary/serviceaccounts?limit=1000
2023-05-04T16:33:10.312581735Z I0504 16:33:10.312546       1 request.go:533] Waited for 180.765353ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operators.coreos.com/v1alpha1/namespaces/openshift-kube-apiserver-operator/installplans?limit=500
2023-05-04T16:33:10.867525845Z I0504 16:33:10.867431       1 request.go:533] Waited for 155.588293ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kni-infra/serviceaccounts?limit=1000
2023-05-04T16:33:10.916309919Z I0504 16:33:10.913014       1 request.go:533] Waited for 150.845874ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operators.coreos.com/v1alpha1/namespaces/openshift-kube-scheduler/installplans?limit=500
2023-05-04T16:33:11.009061801Z I0504 16:33:11.009021       1 tasks_processing.go:74] worker 0 stopped.
2023-05-04T16:33:11.009243572Z I0504 16:33:11.009220       1 recorder.go:70] Recording config/node/logs/node.log with fingerprint=5b6b4a68f3308f693dd166a625311880d54518e82ac12d6e6010230f5f825deb
2023-05-04T16:33:11.009270863Z I0504 16:33:11.009261       1 gather.go:180] gatherer "clusterconfig" function "node_logs" took 6.130458346s to process 1 records
2023-05-04T16:33:11.065189314Z I0504 16:33:11.063888       1 request.go:533] Waited for 136.415208ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts?limit=1000
2023-05-04T16:33:11.113211709Z I0504 16:33:11.112995       1 request.go:533] Waited for 185.570869ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operators.coreos.com/v1alpha1/namespaces/openshift-kube-scheduler-operator/installplans?limit=500
2023-05-04T16:33:12.664256449Z I0504 16:33:12.664221       1 request.go:533] Waited for 113.247579ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-machine-api/serviceaccounts?limit=1000
2023-05-04T16:33:12.712482496Z I0504 16:33:12.712451       1 request.go:533] Waited for 128.135884ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operators.coreos.com/v1alpha1/namespaces/openshift-network-diagnostics/installplans?limit=500
2023-05-04T16:33:12.865605076Z I0504 16:33:12.865574       1 request.go:533] Waited for 193.305005ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-machine-config-operator/serviceaccounts?limit=1000
2023-05-04T16:33:13.066688285Z I0504 16:33:13.066656       1 request.go:533] Waited for 168.335055ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-marketplace/serviceaccounts?limit=1000
2023-05-04T16:33:13.112928199Z I0504 16:33:13.112899       1 request.go:533] Waited for 190.480665ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operators.coreos.com/v1alpha1/namespaces/openshift-node/installplans?limit=500
2023-05-04T16:33:13.264384286Z I0504 16:33:13.264352       1 request.go:533] Waited for 170.976526ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-monitoring/serviceaccounts?limit=1000
2023-05-04T16:33:13.312765744Z I0504 16:33:13.312735       1 request.go:533] Waited for 50.85247ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operators.coreos.com/v1alpha1/namespaces/openshift-nutanix-infra/installplans?limit=500
2023-05-04T16:33:13.464119759Z I0504 16:33:13.464090       1 request.go:533] Waited for 52.721574ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-multus/serviceaccounts?limit=1000
2023-05-04T16:33:13.512730367Z I0504 16:33:13.512699       1 request.go:533] Waited for 80.747677ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operators.coreos.com/v1alpha1/namespaces/openshift-oauth-apiserver/installplans?limit=500
2023-05-04T16:33:13.665224088Z I0504 16:33:13.663788       1 request.go:533] Waited for 197.610561ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-network-diagnostics/serviceaccounts?limit=1000
2023-05-04T16:33:13.712800437Z I0504 16:33:13.712760       1 request.go:533] Waited for 92.433131ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operators.coreos.com/v1alpha1/namespaces/openshift-openstack-infra/installplans?limit=500
2023-05-04T16:33:14.069023608Z I0504 16:33:14.068753       1 request.go:533] Waited for 169.276108ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-node/serviceaccounts?limit=1000
2023-05-04T16:33:14.113692708Z I0504 16:33:14.113192       1 request.go:533] Waited for 198.366247ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operators.coreos.com/v1alpha1/namespaces/openshift-operators/installplans?limit=500
2023-05-04T16:33:14.267690449Z I0504 16:33:14.264464       1 request.go:533] Waited for 180.488717ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-nutanix-infra/serviceaccounts?limit=1000
2023-05-04T16:33:14.313077705Z I0504 16:33:14.312004       1 request.go:533] Waited for 109.76561ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operators.coreos.com/v1alpha1/namespaces/openshift-ovirt-infra/installplans?limit=500
2023-05-04T16:33:14.468029754Z I0504 16:33:14.466335       1 request.go:533] Waited for 158.908836ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-oauth-apiserver/serviceaccounts?limit=1000
2023-05-04T16:33:14.515011619Z I0504 16:33:14.513092       1 request.go:533] Waited for 127.040971ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operators.coreos.com/v1alpha1/namespaces/openshift-ovn-kubernetes/installplans?limit=500
2023-05-04T16:33:14.670984031Z I0504 16:33:14.670014       1 request.go:533] Waited for 132.854619ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-openstack-infra/serviceaccounts?limit=1000
2023-05-04T16:33:14.712502154Z I0504 16:33:14.712462       1 request.go:533] Waited for 175.209661ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operators.coreos.com/v1alpha1/namespaces/openshift-route-controller-manager/installplans?limit=500
2023-05-04T16:33:14.864232324Z I0504 16:33:14.864202       1 request.go:533] Waited for 155.12793ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-operator-lifecycle-manager/serviceaccounts?limit=1000
2023-05-04T16:33:14.912045157Z I0504 16:33:14.912007       1 request.go:533] Waited for 197.142422ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operators.coreos.com/v1alpha1/namespaces/openshift-service-ca/installplans?limit=500
2023-05-04T16:33:15.064392844Z I0504 16:33:15.064357       1 request.go:533] Waited for 176.995539ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-operators/serviceaccounts?limit=1000
2023-05-04T16:33:15.113928466Z I0504 16:33:15.113341       1 request.go:533] Waited for 185.009801ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operators.coreos.com/v1alpha1/namespaces/openshift-service-ca-operator/installplans?limit=500
2023-05-04T16:33:15.264290582Z I0504 16:33:15.264258       1 request.go:533] Waited for 189.54411ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-ovirt-infra/serviceaccounts?limit=1000
2023-05-04T16:33:15.313549675Z I0504 16:33:15.313509       1 request.go:533] Waited for 193.904893ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operators.coreos.com/v1alpha1/namespaces/openshift-storage/installplans?limit=500
2023-05-04T16:33:15.464025364Z I0504 16:33:15.463988       1 request.go:533] Waited for 101.665346ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-ovn-kubernetes/serviceaccounts?limit=1000
2023-05-04T16:33:15.514554558Z I0504 16:33:15.514511       1 request.go:533] Waited for 134.288948ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operators.coreos.com/v1alpha1/namespaces/openshift-user-workload-monitoring/installplans?limit=500
2023-05-04T16:33:15.665724898Z I0504 16:33:15.663836       1 request.go:533] Waited for 129.206741ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-route-controller-manager/serviceaccounts?limit=1000
2023-05-04T16:33:15.718303664Z I0504 16:33:15.718255       1 request.go:533] Waited for 183.683274ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operators.coreos.com/v1alpha1/namespaces/openshift-vsphere-infra/installplans?limit=500
2023-05-04T16:33:15.796268485Z I0504 16:33:15.796175       1 tasks_processing.go:74] worker 5 stopped.
2023-05-04T16:33:15.796268485Z I0504 16:33:15.796217       1 recorder.go:70] Recording config/installplans with fingerprint=407ce712345f2115a7c38f87c7485486737709175477b7849e2f832ffdb015f8
2023-05-04T16:33:15.796268485Z I0504 16:33:15.796227       1 gather.go:180] gatherer "clusterconfig" function "install_plans" took 11.005778468s to process 1 records
2023-05-04T16:33:15.864050599Z I0504 16:33:15.864008       1 request.go:533] Waited for 172.430101ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-service-ca/serviceaccounts?limit=1000
2023-05-04T16:33:16.064285649Z I0504 16:33:16.064135       1 request.go:533] Waited for 192.81485ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-service-ca-operator/serviceaccounts?limit=1000
2023-05-04T16:33:16.266713750Z I0504 16:33:16.263534       1 request.go:533] Waited for 116.327139ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-storage/serviceaccounts?limit=1000
2023-05-04T16:33:16.664098806Z I0504 16:33:16.664056       1 request.go:533] Waited for 179.900494ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-vsphere-infra/serviceaccounts?limit=1000
2023-05-04T16:33:16.779397047Z I0504 16:33:16.779262       1 tasks_processing.go:74] worker 14 stopped.
2023-05-04T16:33:16.780861582Z I0504 16:33:16.779530       1 recorder.go:70] Recording config/serviceaccounts with fingerprint=89f7c8ae1ed7c4c37ef10949d33e8e1a6f75092ed2426ef7617ac28d05b4fe8e
2023-05-04T16:33:16.780861582Z I0504 16:33:16.779541       1 gather.go:180] gatherer "clusterconfig" function "service_accounts" took 11.716306615s to process 1 records
2023-05-04T16:33:16.780861582Z E0504 16:33:16.779591       1 periodic.go:167] clusterconfig failed after 12.099s with: function "config_maps" failed with an error, function "metrics" failed with an error, function "tsdb_status" failed with an error, unable to record function "container_images" record "config/pod/openshift-cluster-version/cluster-version-operator-7544974f8f-tjk7v.json"
2023-05-04T16:33:16.780861582Z I0504 16:33:16.779599       1 controllerstatus.go:79] name=periodic-clusterconfig healthy=false reason=PeriodicGatherFailed message=Source clusterconfig could not be retrieved: function "config_maps" failed with an error, function "metrics" failed with an error, function "tsdb_status" failed with an error, unable to record function "container_images" record "config/pod/openshift-cluster-version/cluster-version-operator-7544974f8f-tjk7v.json"
2023-05-04T16:33:16.780861582Z I0504 16:33:16.779643       1 periodic.go:150] Running workloads gatherer
2023-05-04T16:33:16.780861582Z I0504 16:33:16.779663       1 tasks_processing.go:45] number of workers: 1
2023-05-04T16:33:16.780861582Z I0504 16:33:16.779670       1 tasks_processing.go:69] worker 0 listening for tasks.
2023-05-04T16:33:16.780861582Z I0504 16:33:16.779673       1 tasks_processing.go:71] worker 0 working on workload_info task.
2023-05-04T16:33:16.885595901Z I0504 16:33:16.882704       1 workloads_info.go:238] Loaded pods in 0s, will wait 37s for image data
2023-05-04T16:33:16.886121446Z E0504 16:33:16.885613       1 workloads_info.go:354] Unable to retrieve image sha256:631012b7d9f911558fa49e34402be56a1587a09e58ad645ce2de37aaa20eb468
2023-05-04T16:33:16.889007756Z E0504 16:33:16.886570       1 workloads_info.go:354] Unable to retrieve image sha256:dfdf833d03dac36b747951107a25ab6424eb387bb140f344d4be8d8c7f4e895f
2023-05-04T16:33:16.889050997Z E0504 16:33:16.889015       1 workloads_info.go:354] Unable to retrieve image sha256:238c03849ea26995bfde9657c7628ae0e31fe35f4be068d7326b65acb1f55d01
2023-05-04T16:33:16.893137888Z E0504 16:33:16.891547       1 workloads_info.go:354] Unable to retrieve image sha256:3a09b3bee316f15d4adac8d392f514c1491bdf37760b36f3a8714e563833ca7c
2023-05-04T16:33:16.893489597Z E0504 16:33:16.893440       1 workloads_info.go:354] Unable to retrieve image sha256:56e8f74cab8fdae7f7bbf1c9a307a5fb98eac750a306ec8073478f0899259609
2023-05-04T16:33:16.913209401Z E0504 16:33:16.913172       1 workloads_info.go:354] Unable to retrieve image sha256:2d1371d52c5233f6daf04aa0b0c12f29799155c15b49031bd9581d78529742b2
2023-05-04T16:33:16.917460419Z E0504 16:33:16.916608       1 workloads_info.go:354] Unable to retrieve image sha256:f1d71ba084c63e2d6b3140b9cbada2b50bb6589a39a526dedb466945d284c73e
2023-05-04T16:33:16.918284123Z E0504 16:33:16.918257       1 workloads_info.go:354] Unable to retrieve image sha256:06285dddb5ba9bce5a5ddd07f685f1bc766abed1e0c3890621df281ddc19ab1c
2023-05-04T16:33:16.920559869Z I0504 16:33:16.920522       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.858518ms" userAgent="Prometheus/2.39.1" audit-ID="5893e98f-fa84-4ff6-adf5-3b89cab3808c" srcIP="10.128.0.90:54562" resp=200
2023-05-04T16:33:16.923588025Z E0504 16:33:16.921015       1 workloads_info.go:354] Unable to retrieve image sha256:a5e07e3a1c8bfa3f66ddbdf1bb6b12f48587434f8a37f075d6a02435dfa18dc2
2023-05-04T16:33:16.924223636Z E0504 16:33:16.924205       1 workloads_info.go:354] Unable to retrieve image sha256:81ecc8fb6073babcfb5c08b43206fbbe49e5c0c0694dc3fb6433aebfa9e0bd0f
2023-05-04T16:33:16.987496708Z I0504 16:33:16.986089       1 request.go:533] Waited for 61.824316ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/image.openshift.io/v1/images/sha256:af36c8fe819208e55cc0346c504d641e31a0a1575420a21a6d108a67cbb978df
2023-05-04T16:33:16.987496708Z E0504 16:33:16.987190       1 workloads_info.go:354] Unable to retrieve image sha256:af36c8fe819208e55cc0346c504d641e31a0a1575420a21a6d108a67cbb978df
2023-05-04T16:33:17.083765269Z I0504 16:33:17.083719       1 request.go:533] Waited for 96.476169ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/image.openshift.io/v1/images/sha256:31c7741fc7bb73ff752ba43f5acf014b8fadd69196fc522241302de918066cb1
2023-05-04T16:33:17.084985456Z E0504 16:33:17.084820       1 workloads_info.go:354] Unable to retrieve image sha256:31c7741fc7bb73ff752ba43f5acf014b8fadd69196fc522241302de918066cb1
2023-05-04T16:33:17.183140141Z I0504 16:33:17.183106       1 request.go:533] Waited for 98.217754ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/image.openshift.io/v1/images/sha256:782acf9917df2dff59e1318fc08487830240019e5cc241e02e39a06651900bc2
2023-05-04T16:33:17.184841641Z E0504 16:33:17.184824       1 workloads_info.go:354] Unable to retrieve image sha256:782acf9917df2dff59e1318fc08487830240019e5cc241e02e39a06651900bc2
2023-05-04T16:33:17.283329461Z I0504 16:33:17.283301       1 request.go:533] Waited for 98.381311ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/image.openshift.io/v1/images/sha256:f87f071c3aa8b3932f33cd2dec201abbf7a116e70eeb0df53f93cccc0c3f4041
2023-05-04T16:33:17.285161104Z E0504 16:33:17.284656       1 workloads_info.go:354] Unable to retrieve image sha256:f87f071c3aa8b3932f33cd2dec201abbf7a116e70eeb0df53f93cccc0c3f4041
2023-05-04T16:33:17.387619316Z I0504 16:33:17.387580       1 request.go:533] Waited for 102.869082ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/image.openshift.io/v1/images/sha256:41709e49c29b2764beb118cc25216916be6f8db716ed51886b8191ea695d94e0
2023-05-04T16:33:17.405237841Z E0504 16:33:17.403776       1 workloads_info.go:354] Unable to retrieve image sha256:41709e49c29b2764beb118cc25216916be6f8db716ed51886b8191ea695d94e0
2023-05-04T16:33:17.484037066Z I0504 16:33:17.483387       1 request.go:533] Waited for 79.5484ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/image.openshift.io/v1/images/sha256:9f0cdc00b1b1a3c17411e50653253b9f6bb5329ea4fb82ad983790a6dbf2d9ad
2023-05-04T16:33:17.504205250Z E0504 16:33:17.502659       1 workloads_info.go:354] Unable to retrieve image sha256:9f0cdc00b1b1a3c17411e50653253b9f6bb5329ea4fb82ad983790a6dbf2d9ad
2023-05-04T16:33:17.586337463Z I0504 16:33:17.583952       1 request.go:533] Waited for 81.102663ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/image.openshift.io/v1/images/sha256:e2981cdba6d1e6787c1b5b048bba246cc307650a53ef680dc44593e6227333f1
2023-05-04T16:33:17.588416690Z E0504 16:33:17.588380       1 workloads_info.go:354] Unable to retrieve image sha256:e2981cdba6d1e6787c1b5b048bba246cc307650a53ef680dc44593e6227333f1
2023-05-04T16:33:17.685081634Z I0504 16:33:17.685038       1 request.go:533] Waited for 96.525432ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/image.openshift.io/v1/images/sha256:8b396d60a7de757d04a86a334d1b86faa3121df769903d76d8c98a25c3621705
2023-05-04T16:33:17.687163185Z E0504 16:33:17.687137       1 workloads_info.go:354] Unable to retrieve image sha256:8b396d60a7de757d04a86a334d1b86faa3121df769903d76d8c98a25c3621705
2023-05-04T16:33:17.783376321Z I0504 16:33:17.783198       1 request.go:533] Waited for 95.938721ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/image.openshift.io/v1/images/sha256:87666cc451e16c135276f6405cd7d0c2ce76fd5f19f02a9654c23bb9651c54b3
2023-05-04T16:33:17.791289835Z E0504 16:33:17.789301       1 workloads_info.go:354] Unable to retrieve image sha256:87666cc451e16c135276f6405cd7d0c2ce76fd5f19f02a9654c23bb9651c54b3
2023-05-04T16:33:17.887290824Z I0504 16:33:17.887154       1 request.go:533] Waited for 97.763162ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/image.openshift.io/v1/images/sha256:00d1be95201020c5cb1d3fae3435ee9e7dc22d8360481ec8609fa368c6ad306e
2023-05-04T16:33:17.889096969Z E0504 16:33:17.888313       1 workloads_info.go:354] Unable to retrieve image sha256:00d1be95201020c5cb1d3fae3435ee9e7dc22d8360481ec8609fa368c6ad306e
2023-05-04T16:33:17.984263183Z I0504 16:33:17.983233       1 request.go:533] Waited for 94.849359ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/image.openshift.io/v1/images/sha256:fb7a1e5f6616311d94b625dd3b452348bf75577b824f58a92883139f8f233681
2023-05-04T16:33:17.985834849Z E0504 16:33:17.984315       1 workloads_info.go:354] Unable to retrieve image sha256:fb7a1e5f6616311d94b625dd3b452348bf75577b824f58a92883139f8f233681
2023-05-04T16:33:18.090428274Z I0504 16:33:18.090396       1 request.go:533] Waited for 106.010782ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/image.openshift.io/v1/images/sha256:f1955371a5f88d8984af4445f43864dad8cc315e714f40984ebdf973185ade92
2023-05-04T16:33:18.094609982Z E0504 16:33:18.091618       1 workloads_info.go:354] Unable to retrieve image sha256:f1955371a5f88d8984af4445f43864dad8cc315e714f40984ebdf973185ade92
2023-05-04T16:33:18.194672233Z I0504 16:33:18.185464       1 request.go:533] Waited for 93.785766ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/image.openshift.io/v1/images/sha256:6275a171f6d5a523627963860415ed0e43f1728f2dd897c49412600bf64bc9c3
2023-05-04T16:33:18.194672233Z E0504 16:33:18.189218       1 workloads_info.go:354] Unable to retrieve image sha256:6275a171f6d5a523627963860415ed0e43f1728f2dd897c49412600bf64bc9c3
2023-05-04T16:33:18.286083489Z I0504 16:33:18.283217       1 request.go:533] Waited for 93.94238ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/image.openshift.io/v1/images/sha256:961706a0d75013fcef5f3bbf59754ed23549316fba391249b22529d6a97f1cb2
2023-05-04T16:33:18.286083489Z E0504 16:33:18.284311       1 workloads_info.go:354] Unable to retrieve image sha256:961706a0d75013fcef5f3bbf59754ed23549316fba391249b22529d6a97f1cb2
2023-05-04T16:33:18.386462033Z I0504 16:33:18.383044       1 request.go:533] Waited for 98.659271ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/image.openshift.io/v1/images/sha256:7e5cf6294e213c4dfbd16d7f5e0bd3071703a0fde2342eb09b3957eb6a2b6b3d
2023-05-04T16:33:18.386462033Z E0504 16:33:18.384171       1 workloads_info.go:354] Unable to retrieve image sha256:7e5cf6294e213c4dfbd16d7f5e0bd3071703a0fde2342eb09b3957eb6a2b6b3d
2023-05-04T16:33:18.485377044Z I0504 16:33:18.483440       1 request.go:533] Waited for 99.212378ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/image.openshift.io/v1/images/sha256:303fe68053354fb40b73196c2c950e5305cf4cd7b9109824b6aa33d3aeedb988
2023-05-04T16:33:18.485377044Z E0504 16:33:18.484612       1 workloads_info.go:354] Unable to retrieve image sha256:303fe68053354fb40b73196c2c950e5305cf4cd7b9109824b6aa33d3aeedb988
2023-05-04T16:33:18.586364860Z I0504 16:33:18.585092       1 request.go:533] Waited for 99.257002ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/image.openshift.io/v1/images/sha256:1d74f4833b6bb911b57cc08a170a7242733bb5d09ac9480399395a1970e21365
2023-05-04T16:33:18.586364860Z E0504 16:33:18.586326       1 workloads_info.go:354] Unable to retrieve image sha256:1d74f4833b6bb911b57cc08a170a7242733bb5d09ac9480399395a1970e21365
2023-05-04T16:33:18.684999926Z I0504 16:33:18.683220       1 request.go:533] Waited for 96.825444ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/image.openshift.io/v1/images/sha256:7ecf76246d81adfe3f52fdb54a7bddf6b892ea6900521d71553d16f2918a2cac
2023-05-04T16:33:18.699227184Z E0504 16:33:18.699175       1 workloads_info.go:354] Unable to retrieve image sha256:7ecf76246d81adfe3f52fdb54a7bddf6b892ea6900521d71553d16f2918a2cac
2023-05-04T16:33:18.786013290Z I0504 16:33:18.783007       1 request.go:533] Waited for 83.745286ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/image.openshift.io/v1/images/sha256:9ed61d19216d71cc5692c22402961b0f865ed8629f5d64f1687aa47af601c018
2023-05-04T16:33:18.786013290Z E0504 16:33:18.784743       1 workloads_info.go:354] Unable to retrieve image sha256:9ed61d19216d71cc5692c22402961b0f865ed8629f5d64f1687aa47af601c018
2023-05-04T16:33:18.883299057Z I0504 16:33:18.883115       1 request.go:533] Waited for 98.314525ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/image.openshift.io/v1/images/sha256:30784b4b00568946c30c1830da739d61193a622cc3a17286fe91885f0c93af9f
2023-05-04T16:33:18.884386165Z E0504 16:33:18.884170       1 workloads_info.go:354] Unable to retrieve image sha256:30784b4b00568946c30c1830da739d61193a622cc3a17286fe91885f0c93af9f
2023-05-04T16:33:18.984949004Z I0504 16:33:18.984908       1 request.go:533] Waited for 100.655774ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/image.openshift.io/v1/images/sha256:773fe01f949872eaae7daee9bac53f06ca4d375e3f8d6207a9a3eccaa4ab9f98
2023-05-04T16:33:18.989042467Z E0504 16:33:18.987045       1 workloads_info.go:354] Unable to retrieve image sha256:773fe01f949872eaae7daee9bac53f06ca4d375e3f8d6207a9a3eccaa4ab9f98
2023-05-04T16:33:19.083676363Z I0504 16:33:19.083410       1 request.go:533] Waited for 96.292696ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/image.openshift.io/v1/images/sha256:4fafaae3445cd29a8ba685901a338b8539877d15f149466cc7b4e42fdca60c40
2023-05-04T16:33:19.084539010Z E0504 16:33:19.084509       1 workloads_info.go:354] Unable to retrieve image sha256:4fafaae3445cd29a8ba685901a338b8539877d15f149466cc7b4e42fdca60c40
2023-05-04T16:33:19.183419647Z I0504 16:33:19.183373       1 request.go:533] Waited for 98.805165ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/image.openshift.io/v1/images/sha256:9c407846948c8ff2cd441089c6a57822cfe1a07a537dff1f9d7ebf2db2d1cdee
2023-05-04T16:33:19.186123064Z E0504 16:33:19.186089       1 workloads_info.go:354] Unable to retrieve image sha256:9c407846948c8ff2cd441089c6a57822cfe1a07a537dff1f9d7ebf2db2d1cdee
2023-05-04T16:33:19.283819441Z I0504 16:33:19.283718       1 request.go:533] Waited for 97.565261ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/image.openshift.io/v1/images/sha256:c8d009a8c5ea6b7739d18d167647f2bd1733af8560b6d7b013a6d0c35e266323
2023-05-04T16:33:19.291157005Z E0504 16:33:19.290762       1 workloads_info.go:354] Unable to retrieve image sha256:c8d009a8c5ea6b7739d18d167647f2bd1733af8560b6d7b013a6d0c35e266323
2023-05-04T16:33:19.385449190Z I0504 16:33:19.385039       1 request.go:533] Waited for 94.212416ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/image.openshift.io/v1/images/sha256:851bbd751f0896f040e55e8fbf0c621e96f3ea2536cb1dfbdcc9a890bcbf2a32
2023-05-04T16:33:19.389287264Z E0504 16:33:19.387885       1 workloads_info.go:354] Unable to retrieve image sha256:851bbd751f0896f040e55e8fbf0c621e96f3ea2536cb1dfbdcc9a890bcbf2a32
2023-05-04T16:33:19.484283720Z I0504 16:33:19.483816       1 request.go:533] Waited for 95.851459ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/image.openshift.io/v1/images/sha256:dfca545c1b42ae20c6465e61cf16a44f9411d9ed30af1f9017ed6da0d7ebd216
2023-05-04T16:33:19.485167577Z E0504 16:33:19.485060       1 workloads_info.go:354] Unable to retrieve image sha256:dfca545c1b42ae20c6465e61cf16a44f9411d9ed30af1f9017ed6da0d7ebd216
2023-05-04T16:33:19.583945401Z I0504 16:33:19.583910       1 request.go:533] Waited for 98.784777ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/image.openshift.io/v1/images/sha256:13c6c13414ca1ad1b47ed6b7e785e92f1e435dff1d70709fb807c23a98803a32
2023-05-04T16:33:19.584798019Z E0504 16:33:19.584785       1 workloads_info.go:354] Unable to retrieve image sha256:13c6c13414ca1ad1b47ed6b7e785e92f1e435dff1d70709fb807c23a98803a32
2023-05-04T16:33:19.683978297Z I0504 16:33:19.683071       1 request.go:533] Waited for 98.230698ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/image.openshift.io/v1/images/sha256:53c526dc7766f65b2de93215a5f609fdc2f790717c07d15ffcbf5d4ac79d002e
2023-05-04T16:33:19.687952627Z E0504 16:33:19.685206       1 workloads_info.go:354] Unable to retrieve image sha256:53c526dc7766f65b2de93215a5f609fdc2f790717c07d15ffcbf5d4ac79d002e
2023-05-04T16:33:19.784038204Z I0504 16:33:19.783372       1 request.go:533] Waited for 98.104953ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/image.openshift.io/v1/images/sha256:eeed76c41bf3d2262a4d177241a315bc476421b8471cbba1555991aac8ef83b0
2023-05-04T16:33:19.786872957Z E0504 16:33:19.786646       1 workloads_info.go:354] Unable to retrieve image sha256:eeed76c41bf3d2262a4d177241a315bc476421b8471cbba1555991aac8ef83b0
2023-05-04T16:33:19.816277034Z I0504 16:33:19.814500       1 insightsuploader.go:122] Nothing to report since 2023-05-04T16:13:56Z
2023-05-04T16:33:19.886014162Z I0504 16:33:19.885205       1 request.go:533] Waited for 98.496707ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/image.openshift.io/v1/images/sha256:7d756df4dce6ace35ff2aecf459affb7cc1bef2aa08004d62575ec09f6c76c86
2023-05-04T16:33:19.890997964Z E0504 16:33:19.890222       1 workloads_info.go:354] Unable to retrieve image sha256:7d756df4dce6ace35ff2aecf459affb7cc1bef2aa08004d62575ec09f6c76c86
2023-05-04T16:33:19.988030817Z I0504 16:33:19.987924       1 request.go:533] Waited for 97.638748ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/image.openshift.io/v1/images/sha256:917b84445c725430f74f2041baa697d86d2a0bc971f6b9101591524daf8053f6
2023-05-04T16:33:19.989361341Z E0504 16:33:19.989158       1 workloads_info.go:354] Unable to retrieve image sha256:917b84445c725430f74f2041baa697d86d2a0bc971f6b9101591524daf8053f6
2023-05-04T16:33:20.092860965Z I0504 16:33:20.083343       1 request.go:533] Waited for 94.015908ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/image.openshift.io/v1/images/sha256:0fabfe66dbbe204c284860937d453712fe199940fb1088823268fe611a44b793
2023-05-04T16:33:20.092860965Z E0504 16:33:20.086789       1 workloads_info.go:354] Unable to retrieve image sha256:0fabfe66dbbe204c284860937d453712fe199940fb1088823268fe611a44b793
2023-05-04T16:33:20.192741596Z I0504 16:33:20.184008       1 request.go:533] Waited for 97.152638ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/image.openshift.io/v1/images/sha256:81a043e61c07b8e93c6b082aa920d61ffa69762bcc2ef1018360026d62c11b18
2023-05-04T16:33:20.193927309Z E0504 16:33:20.193899       1 workloads_info.go:354] Unable to retrieve image sha256:81a043e61c07b8e93c6b082aa920d61ffa69762bcc2ef1018360026d62c11b18
2023-05-04T16:33:20.283189355Z I0504 16:33:20.283150       1 request.go:533] Waited for 89.12476ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/image.openshift.io/v1/images/sha256:3a1252ab4a94ef96c90c19a926c6c10b1c73186377f408414c8a3aa1949a0a75
2023-05-04T16:33:20.284428689Z E0504 16:33:20.284408       1 workloads_info.go:354] Unable to retrieve image sha256:3a1252ab4a94ef96c90c19a926c6c10b1c73186377f408414c8a3aa1949a0a75
2023-05-04T16:33:20.383726136Z I0504 16:33:20.383690       1 request.go:533] Waited for 99.172634ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/image.openshift.io/v1/images/sha256:aec165a1c80946b96c6ba401ff249e31554a3cce8ab2f996b9f6618dbe9bc84a
2023-05-04T16:33:20.384808014Z E0504 16:33:20.384782       1 workloads_info.go:354] Unable to retrieve image sha256:aec165a1c80946b96c6ba401ff249e31554a3cce8ab2f996b9f6618dbe9bc84a
2023-05-04T16:33:20.483512059Z I0504 16:33:20.483474       1 request.go:533] Waited for 98.593838ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/image.openshift.io/v1/images/sha256:d1705c63614eeb3feebc11b29e6a977c28bac2401092efae1d42b655259e2629
2023-05-04T16:33:20.484700056Z E0504 16:33:20.484667       1 workloads_info.go:354] Unable to retrieve image sha256:d1705c63614eeb3feebc11b29e6a977c28bac2401092efae1d42b655259e2629
2023-05-04T16:33:20.584242894Z I0504 16:33:20.584026       1 request.go:533] Waited for 99.241463ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/image.openshift.io/v1/images/sha256:13397fef9671257021455712bf8242685325c97dbc6700c988bd6ab5e68ff57e
2023-05-04T16:33:20.585455246Z E0504 16:33:20.585347       1 workloads_info.go:354] Unable to retrieve image sha256:13397fef9671257021455712bf8242685325c97dbc6700c988bd6ab5e68ff57e
2023-05-04T16:33:20.685107569Z I0504 16:33:20.685066       1 request.go:533] Waited for 99.655599ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/image.openshift.io/v1/images/sha256:8090f9dd771f4f292e508b5ffca3aca3b4e6226aed25e131e49a9b6596b0b451
2023-05-04T16:33:20.687101868Z E0504 16:33:20.687068       1 workloads_info.go:354] Unable to retrieve image sha256:8090f9dd771f4f292e508b5ffca3aca3b4e6226aed25e131e49a9b6596b0b451
2023-05-04T16:33:20.783433977Z I0504 16:33:20.782921       1 request.go:533] Waited for 95.789332ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/image.openshift.io/v1/images/sha256:f968922564c3eea1c69d6bbe529d8970784d6cae8935afaf674d9fa7c0f72ea3
2023-05-04T16:33:20.784816989Z E0504 16:33:20.784793       1 workloads_info.go:354] Unable to retrieve image sha256:f968922564c3eea1c69d6bbe529d8970784d6cae8935afaf674d9fa7c0f72ea3
2023-05-04T16:33:20.883077614Z I0504 16:33:20.883021       1 request.go:533] Waited for 98.157501ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/image.openshift.io/v1/images/sha256:e2eeaa28dd8f578270448360ada5a2c2f74e353d658a9abfbe2d9bb930c5f229
2023-05-04T16:33:20.884830118Z E0504 16:33:20.884801       1 workloads_info.go:354] Unable to retrieve image sha256:e2eeaa28dd8f578270448360ada5a2c2f74e353d658a9abfbe2d9bb930c5f229
2023-05-04T16:33:20.983176714Z I0504 16:33:20.982874       1 request.go:533] Waited for 98.00764ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/image.openshift.io/v1/images/sha256:c4e5f13cd4d2a9556b980a8a6790c237685b007f7ea7723191bf1633d8d88e27
2023-05-04T16:33:20.985528232Z E0504 16:33:20.984259       1 workloads_info.go:354] Unable to retrieve image sha256:c4e5f13cd4d2a9556b980a8a6790c237685b007f7ea7723191bf1633d8d88e27
2023-05-04T16:33:21.084297309Z I0504 16:33:21.084091       1 request.go:533] Waited for 99.770784ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/image.openshift.io/v1/images/sha256:5097e405f3dc5e0bd7e6072d3d93cbfcd45d3d74771003c48e689b2f8c4d3850
2023-05-04T16:33:21.086465673Z E0504 16:33:21.085234       1 workloads_info.go:354] Unable to retrieve image sha256:5097e405f3dc5e0bd7e6072d3d93cbfcd45d3d74771003c48e689b2f8c4d3850
2023-05-04T16:33:21.183805933Z I0504 16:33:21.183545       1 request.go:533] Waited for 98.236068ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/image.openshift.io/v1/images/sha256:f2f70f1bd12128213b7b131782a4e76df20cbc224b13c69fff7ec71787b5499e
2023-05-04T16:33:21.186265172Z E0504 16:33:21.184506       1 workloads_info.go:354] Unable to retrieve image sha256:f2f70f1bd12128213b7b131782a4e76df20cbc224b13c69fff7ec71787b5499e
2023-05-04T16:33:21.284736952Z I0504 16:33:21.283282       1 request.go:533] Waited for 98.708744ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/image.openshift.io/v1/images/sha256:fbeeb31a94b29354971d11e3db852e7a6ec8d2b70b8ec323a01b124281e49261
2023-05-04T16:33:21.285856881Z E0504 16:33:21.285827       1 workloads_info.go:354] Unable to retrieve image sha256:fbeeb31a94b29354971d11e3db852e7a6ec8d2b70b8ec323a01b124281e49261
2023-05-04T16:33:21.387108632Z I0504 16:33:21.383123       1 request.go:533] Waited for 97.204825ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/image.openshift.io/v1/images/sha256:b1f2103c4ddf702b2a135e68420af3e434c8b135735dbd33bf66afada0036976
2023-05-04T16:33:21.397130468Z E0504 16:33:21.394836       1 workloads_info.go:354] Unable to retrieve image sha256:b1f2103c4ddf702b2a135e68420af3e434c8b135735dbd33bf66afada0036976
2023-05-04T16:33:21.485485855Z I0504 16:33:21.484350       1 request.go:533] Waited for 89.442285ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/image.openshift.io/v1/images/sha256:d03a73b14daa7fe32294f62fd5ef20edf193204d6a39df05dd4342e721e7746d
2023-05-04T16:33:21.496011615Z E0504 16:33:21.491446       1 workloads_info.go:354] Unable to retrieve image sha256:d03a73b14daa7fe32294f62fd5ef20edf193204d6a39df05dd4342e721e7746d
2023-05-04T16:33:21.586826152Z I0504 16:33:21.585344       1 request.go:533] Waited for 93.827635ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/image.openshift.io/v1/images/sha256:f6ba6ec29ae317b65ccae96aae4338eed31430f09c536e09ac1e36d9f11b208e
2023-05-04T16:33:21.594792014Z E0504 16:33:21.591180       1 workloads_info.go:354] Unable to retrieve image sha256:f6ba6ec29ae317b65ccae96aae4338eed31430f09c536e09ac1e36d9f11b208e
2023-05-04T16:33:21.683116263Z I0504 16:33:21.683073       1 request.go:533] Waited for 91.821845ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/image.openshift.io/v1/images/sha256:09c8eb0283a9eda5b282f04357875966a549651e120e527904a917ec862eb642
2023-05-04T16:33:21.686999822Z E0504 16:33:21.686952       1 workloads_info.go:354] Unable to retrieve image sha256:09c8eb0283a9eda5b282f04357875966a549651e120e527904a917ec862eb642
2023-05-04T16:33:21.785501118Z I0504 16:33:21.785307       1 request.go:533] Waited for 98.20477ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/image.openshift.io/v1/images/sha256:422e4fbe1ed81c79084f43a826dc0674510a7ff578e62b4ddda119ed3266d0b6
2023-05-04T16:33:21.789130260Z E0504 16:33:21.786424       1 workloads_info.go:354] Unable to retrieve image sha256:422e4fbe1ed81c79084f43a826dc0674510a7ff578e62b4ddda119ed3266d0b6
2023-05-04T16:33:21.887181502Z I0504 16:33:21.886097       1 request.go:533] Waited for 99.612899ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/image.openshift.io/v1/images/sha256:fa1ff52055ededc0386ee6b334ffe0cd9252f5878fcccf1396aee30adf6de046
2023-05-04T16:33:21.888660033Z E0504 16:33:21.888632       1 workloads_info.go:354] Unable to retrieve image sha256:fa1ff52055ededc0386ee6b334ffe0cd9252f5878fcccf1396aee30adf6de046
2023-05-04T16:33:21.984232188Z I0504 16:33:21.983931       1 request.go:533] Waited for 95.164922ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/image.openshift.io/v1/images/sha256:7c23b71619bd88c1bfa093cfa1a72db148937e8f1637c99ff164bf566eaf78b8
2023-05-04T16:33:21.993563018Z E0504 16:33:21.993519       1 workloads_info.go:354] Unable to retrieve image sha256:7c23b71619bd88c1bfa093cfa1a72db148937e8f1637c99ff164bf566eaf78b8
2023-05-04T16:33:22.083136369Z I0504 16:33:22.083100       1 request.go:533] Waited for 89.449879ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/image.openshift.io/v1/images/sha256:80342a9216008b642e15bf8d79532c440b5e6e6e56b2576d8c24b473b0a81e6f
2023-05-04T16:33:22.087884659Z E0504 16:33:22.084219       1 workloads_info.go:354] Unable to retrieve image sha256:80342a9216008b642e15bf8d79532c440b5e6e6e56b2576d8c24b473b0a81e6f
2023-05-04T16:33:22.185849249Z I0504 16:33:22.183812       1 request.go:533] Waited for 99.537969ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/image.openshift.io/v1/images/sha256:e045fad043f28570b754619999ffb356bedee81ff842c56a32b1b13588fc1651
2023-05-04T16:33:22.191004702Z E0504 16:33:22.186587       1 workloads_info.go:354] Unable to retrieve image sha256:e045fad043f28570b754619999ffb356bedee81ff842c56a32b1b13588fc1651
2023-05-04T16:33:22.286172209Z I0504 16:33:22.284243       1 request.go:533] Waited for 97.57588ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/image.openshift.io/v1/images/sha256:503846d640ded8b0deedc7c69647320065055d3d2a423993259692362c5d5b86
2023-05-04T16:33:22.287699501Z E0504 16:33:22.287669       1 workloads_info.go:354] Unable to retrieve image sha256:503846d640ded8b0deedc7c69647320065055d3d2a423993259692362c5d5b86
2023-05-04T16:33:22.383848307Z I0504 16:33:22.383806       1 request.go:533] Waited for 96.074026ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/image.openshift.io/v1/images/sha256:78078017998532005d730896ed4ca6f212ca9ac5713d65ca724eb9468fd8f7fb
2023-05-04T16:33:22.386811321Z E0504 16:33:22.386775       1 workloads_info.go:354] Unable to retrieve image sha256:78078017998532005d730896ed4ca6f212ca9ac5713d65ca724eb9468fd8f7fb
2023-05-04T16:33:22.483362261Z I0504 16:33:22.483330       1 request.go:533] Waited for 96.493812ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/image.openshift.io/v1/images/sha256:51c76ce72315ae658d91de6620d8dd4f798e6ea0c493e5d2899dd2c52fbcd931
2023-05-04T16:33:22.484499102Z E0504 16:33:22.484482       1 workloads_info.go:354] Unable to retrieve image sha256:51c76ce72315ae658d91de6620d8dd4f798e6ea0c493e5d2899dd2c52fbcd931
2023-05-04T16:33:22.583482400Z I0504 16:33:22.583433       1 request.go:533] Waited for 98.839409ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/image.openshift.io/v1/images/sha256:33617f49d30c6752e078e76bebcbf3f4384fb03286f2ef4d6ca9d2e6464ada43
2023-05-04T16:33:22.584504697Z E0504 16:33:22.584480       1 workloads_info.go:354] Unable to retrieve image sha256:33617f49d30c6752e078e76bebcbf3f4384fb03286f2ef4d6ca9d2e6464ada43
2023-05-04T16:33:22.683586820Z I0504 16:33:22.683556       1 request.go:533] Waited for 98.870457ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/image.openshift.io/v1/images/sha256:47bc752254f826905ac36cc2eb1819373a3045603e5dfa03c7f9e6d73c3fd9f9
2023-05-04T16:33:22.684719093Z E0504 16:33:22.684699       1 workloads_info.go:354] Unable to retrieve image sha256:47bc752254f826905ac36cc2eb1819373a3045603e5dfa03c7f9e6d73c3fd9f9
2023-05-04T16:33:22.784644167Z I0504 16:33:22.784082       1 request.go:533] Waited for 99.269174ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/image.openshift.io/v1/images/sha256:ae783ee6a05beafca04f0766933ee1573b70231a6cd8c449a2177afdaf4802a0
2023-05-04T16:33:22.786165679Z E0504 16:33:22.785431       1 workloads_info.go:354] Unable to retrieve image sha256:ae783ee6a05beafca04f0766933ee1573b70231a6cd8c449a2177afdaf4802a0
2023-05-04T16:33:22.883718787Z I0504 16:33:22.883681       1 request.go:533] Waited for 98.192296ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/image.openshift.io/v1/images/sha256:c28f27a3a10df13e5e8c074e8734683a6603ebaccd9d67e2095070fb6859b1d6
2023-05-04T16:33:22.884755500Z E0504 16:33:22.884730       1 workloads_info.go:354] Unable to retrieve image sha256:c28f27a3a10df13e5e8c074e8734683a6603ebaccd9d67e2095070fb6859b1d6
2023-05-04T16:33:22.983126361Z I0504 16:33:22.983082       1 request.go:533] Waited for 98.2908ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/image.openshift.io/v1/images/sha256:e36c1c4e383fd252168aa2cb465236aa642062446aa3a026f06ea4a4afb52d7f
2023-05-04T16:33:22.984203701Z E0504 16:33:22.984171       1 workloads_info.go:354] Unable to retrieve image sha256:e36c1c4e383fd252168aa2cb465236aa642062446aa3a026f06ea4a4afb52d7f
2023-05-04T16:33:23.083619099Z I0504 16:33:23.083584       1 request.go:533] Waited for 99.355076ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/image.openshift.io/v1/images/sha256:a1a9ffe4c3d12fd672271f098a10a111ab5b3d145b7e2da447ef1aaab5189c12
2023-05-04T16:33:23.084627540Z E0504 16:33:23.084603       1 workloads_info.go:354] Unable to retrieve image sha256:a1a9ffe4c3d12fd672271f098a10a111ab5b3d145b7e2da447ef1aaab5189c12
2023-05-04T16:33:23.182990345Z I0504 16:33:23.182949       1 request.go:533] Waited for 98.290771ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/image.openshift.io/v1/images/sha256:f876250993619037cbf206da00d0419c545269799f3b29848a9d1bc0e88aad30
2023-05-04T16:33:23.183922362Z E0504 16:33:23.183900       1 workloads_info.go:354] Unable to retrieve image sha256:f876250993619037cbf206da00d0419c545269799f3b29848a9d1bc0e88aad30
2023-05-04T16:33:23.284768072Z I0504 16:33:23.284718       1 request.go:533] Waited for 100.733469ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/image.openshift.io/v1/images/sha256:756f3f02d7592b100d5fcf2a8351a570102e79e02425d9b5d3d09a63ee21839d
2023-05-04T16:33:23.285955909Z E0504 16:33:23.285914       1 workloads_info.go:354] Unable to retrieve image sha256:756f3f02d7592b100d5fcf2a8351a570102e79e02425d9b5d3d09a63ee21839d
2023-05-04T16:33:23.383238169Z I0504 16:33:23.383203       1 request.go:533] Waited for 97.196119ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/image.openshift.io/v1/images/sha256:d4228c6e797ec6b2d37e599c19c715b02f6cb955b2a7fb493c56844f4c75e687
2023-05-04T16:33:23.384323083Z E0504 16:33:23.384304       1 workloads_info.go:354] Unable to retrieve image sha256:d4228c6e797ec6b2d37e599c19c715b02f6cb955b2a7fb493c56844f4c75e687
2023-05-04T16:33:23.485642430Z I0504 16:33:23.483388       1 request.go:533] Waited for 98.998607ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/image.openshift.io/v1/images/sha256:da1dec5c084b77969ed1b7995a292c7ac431cdd711a708bfbe1f40628515466c
2023-05-04T16:33:23.485642430Z E0504 16:33:23.485026       1 workloads_info.go:354] Unable to retrieve image sha256:da1dec5c084b77969ed1b7995a292c7ac431cdd711a708bfbe1f40628515466c
2023-05-04T16:33:23.599342595Z I0504 16:33:23.598995       1 request.go:533] Waited for 113.903106ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/image.openshift.io/v1/images/sha256:14794ac4b4b5e1bb2728d253b939578a03730cf26ba5cf795c8e2d26b9737dd6
2023-05-04T16:33:23.607108642Z E0504 16:33:23.605040       1 workloads_info.go:354] Unable to retrieve image sha256:14794ac4b4b5e1bb2728d253b939578a03730cf26ba5cf795c8e2d26b9737dd6
2023-05-04T16:33:23.683231350Z I0504 16:33:23.683186       1 request.go:533] Waited for 78.065459ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/image.openshift.io/v1/images/sha256:751044f29417b1a8db051c813e95316e489a73ccb4a8c7d18ab46a0f4d1c1a59
2023-05-04T16:33:23.685691371Z E0504 16:33:23.684729       1 workloads_info.go:354] Unable to retrieve image sha256:751044f29417b1a8db051c813e95316e489a73ccb4a8c7d18ab46a0f4d1c1a59
2023-05-04T16:33:23.784116354Z I0504 16:33:23.782899       1 request.go:533] Waited for 98.076459ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/image.openshift.io/v1/images/sha256:cad5a85f21da1d2e653f41f82db607ab6827da0468283f63694c509e39374f0d
2023-05-04T16:33:23.784116354Z E0504 16:33:23.783786       1 workloads_info.go:354] Unable to retrieve image sha256:cad5a85f21da1d2e653f41f82db607ab6827da0468283f63694c509e39374f0d
2023-05-04T16:33:23.883054528Z I0504 16:33:23.883010       1 request.go:533] Waited for 99.171191ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/image.openshift.io/v1/images/sha256:ec53f44c080dc784adb01a4e3b8257adffaf79a6e38f683d26bf1b384d6b7156
2023-05-04T16:33:23.884174928Z E0504 16:33:23.884156       1 workloads_info.go:354] Unable to retrieve image sha256:ec53f44c080dc784adb01a4e3b8257adffaf79a6e38f683d26bf1b384d6b7156
2023-05-04T16:33:23.884205796Z I0504 16:33:23.884188       1 tasks_processing.go:74] worker 0 stopped.
2023-05-04T16:33:23.884604633Z I0504 16:33:23.884591       1 recorder.go:70] Recording config/workload_info with fingerprint=f6171a25e80296733cf3565f33de02e4ba68c20536d5f22cd553e01ea31bfd4c
2023-05-04T16:33:23.884612909Z I0504 16:33:23.884603       1 gather.go:180] gatherer "workloads" function "workload_info" took 7.104509999s to process 1 records
2023-05-04T16:33:23.884618279Z I0504 16:33:23.884611       1 periodic.go:162] Periodic gather workloads completed in 7.104s
2023-05-04T16:33:23.884623399Z I0504 16:33:23.884617       1 controllerstatus.go:70] name=periodic-workloads healthy=true reason= message=
2023-05-04T16:33:23.884633898Z I0504 16:33:23.884624       1 periodic.go:150] Running conditional gatherer
2023-05-04T16:33:23.884633898Z I0504 16:33:23.884629       1 requests.go:214] Preparing a request to Insights Operator Gathering Conditions Service at the endpoint "https://console.redhat.com/api/gathering/gathering_rules"
2023-05-04T16:33:23.887873982Z I0504 16:33:23.887850       1 requests.go:233] Performing a request to Insights Operator Gathering Conditions Service
2023-05-04T16:33:24.986609071Z I0504 16:33:24.986563       1 conditional_gatherer.go:94] got 9 gathering rules for conditional gatherer with version 1.0.1
2023-05-04T16:33:25.017068155Z I0504 16:33:25.017011       1 conditional_gatherer.go:242] updating alerts cache for conditional gatherer
2023-05-04T16:33:25.044007802Z E0504 16:33:25.043647       1 conditional_gatherer.go:228] unable to update alerts cache: Get "https://prometheus-k8s.openshift-monitoring.svc:9091/api/v1/query?match%5B%5D=ALERTS%7Balertstate%3D%22firing%22%7D&query=ALERTS": dial tcp 172.30.65.195:9091: connect: connection refused
2023-05-04T16:33:25.044007802Z I0504 16:33:25.043765       1 conditional_gatherer.go:288] updating version cache for conditional gatherer
2023-05-04T16:33:25.212046562Z I0504 16:33:25.211093       1 conditional_gatherer.go:296] cluster version is '4.12.2'
2023-05-04T16:33:25.212046562Z E0504 16:33:25.211111       1 conditional_gatherer.go:140] error checking conditions for a gathering rule: alerts cache is missing
2023-05-04T16:33:25.212046562Z E0504 16:33:25.211117       1 conditional_gatherer.go:140] error checking conditions for a gathering rule: alerts cache is missing
2023-05-04T16:33:25.212969502Z E0504 16:33:25.212135       1 conditional_gatherer.go:140] error checking conditions for a gathering rule: alerts cache is missing
2023-05-04T16:33:25.212969502Z E0504 16:33:25.212149       1 conditional_gatherer.go:140] error checking conditions for a gathering rule: alerts cache is missing
2023-05-04T16:33:25.212969502Z E0504 16:33:25.212152       1 conditional_gatherer.go:140] error checking conditions for a gathering rule: alerts cache is missing
2023-05-04T16:33:25.212969502Z E0504 16:33:25.212156       1 conditional_gatherer.go:140] error checking conditions for a gathering rule: alerts cache is missing
2023-05-04T16:33:25.212969502Z E0504 16:33:25.212159       1 conditional_gatherer.go:140] error checking conditions for a gathering rule: alerts cache is missing
2023-05-04T16:33:25.212969502Z E0504 16:33:25.212162       1 conditional_gatherer.go:140] error checking conditions for a gathering rule: alerts cache is missing
2023-05-04T16:33:25.212969502Z E0504 16:33:25.212165       1 conditional_gatherer.go:140] error checking conditions for a gathering rule: alerts cache is missing
2023-05-04T16:33:25.212969502Z I0504 16:33:25.212186       1 tasks_processing.go:45] number of workers: 1
2023-05-04T16:33:25.212969502Z I0504 16:33:25.212192       1 tasks_processing.go:69] worker 0 listening for tasks.
2023-05-04T16:33:25.212969502Z I0504 16:33:25.212196       1 tasks_processing.go:71] worker 0 working on conditional_gatherer_rules task.
2023-05-04T16:33:25.212969502Z I0504 16:33:25.212941       1 tasks_processing.go:74] worker 0 stopped.
2023-05-04T16:33:25.214991401Z I0504 16:33:25.213074       1 recorder.go:70] Recording insights-operator/conditional-gatherer-rules with fingerprint=838df68beccab6de00ec0a565c6686682bfb892b8aca485249e7c888c6d6292c
2023-05-04T16:33:25.214991401Z I0504 16:33:25.213086       1 gather.go:180] gatherer "conditional" function "conditional_gatherer_rules" took 1.884s to process 1 records
2023-05-04T16:33:25.214991401Z I0504 16:33:25.213096       1 periodic.go:162] Periodic gather conditional completed in 1.328s
2023-05-04T16:33:25.214991401Z I0504 16:33:25.213101       1 controllerstatus.go:70] name=periodic-conditional healthy=true reason= message=
2023-05-04T16:33:25.297360157Z I0504 16:33:25.297305       1 recorder.go:70] Recording insights-operator/gathers with fingerprint=da316db89a98a3c07cc7e12398d3c294d4d5dba0617717979112b25dce8343c7
2023-05-04T16:33:25.297588345Z I0504 16:33:25.297532       1 diskrecorder.go:70] Writing 132 records to /var/lib/insights-operator/insights-2023-05-04-163325.tar.gz
2023-05-04T16:33:25.310425057Z I0504 16:33:25.310383       1 diskrecorder.go:51] Wrote 132 records to disk in 13ms
2023-05-04T16:33:25.310467376Z I0504 16:33:25.310432       1 periodic.go:192] Gathering cluster info every 2h0m0s
2023-05-04T16:33:34.824470319Z I0504 16:33:34.824431       1 diskrecorder.go:170] Found files to send: insights-2023-05-04-163325.tar.gz
2023-05-04T16:33:34.824533748Z I0504 16:33:34.824525       1 insightsuploader.go:130] Uploading latest report since 2023-05-04T16:13:56Z
2023-05-04T16:33:34.829782166Z I0504 16:33:34.829742       1 requests.go:42] Uploading application/vnd.redhat.openshift.periodic to https://console.redhat.com/api/ingress/v1/upload
2023-05-04T16:33:35.284811394Z I0504 16:33:35.284773       1 requests.go:83] Successfully reported id=2023-05-04T16:33:34Z x-rh-insights-request-id=d9513236ab4c45ab8b8e709e0d93ef16, wrote=78911
2023-05-04T16:33:35.285022820Z I0504 16:33:35.285009       1 insightsuploader.go:151] Uploaded report successfully in 460.486377ms
2023-05-04T16:33:35.285258472Z I0504 16:33:35.285247       1 insightsreport.go:251] Archive uploaded, starting pulling report...
2023-05-04T16:33:35.285283659Z I0504 16:33:35.285277       1 insightsreport.go:159] Starting retrieving report from Smart Proxy
2023-05-04T16:33:35.285304227Z I0504 16:33:35.285297       1 insightsreport.go:170] Initial delay for pulling: 1m0s
2023-05-04T16:33:35.288469441Z I0504 16:33:35.288439       1 controller.go:447] The operator is healthy
2023-05-04T16:33:46.889094184Z I0504 16:33:46.889056       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.327182ms" userAgent="Prometheus/2.39.1" audit-ID="b096e06d-d013-4c00-94f4-a58cebc18709" srcIP="10.128.0.90:54562" resp=200
2023-05-04T16:34:16.889112874Z I0504 16:34:16.889078       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.355224ms" userAgent="Prometheus/2.39.1" audit-ID="aeefb678-8ce4-4726-ab98-26576aa8f3c0" srcIP="10.128.0.90:54562" resp=200
2023-05-04T16:34:40.315299938Z I0504 16:34:40.315267       1 insightsreport.go:82] Pulling report from smart-proxy
2023-05-04T16:34:40.315361724Z I0504 16:34:40.315354       1 insightsreport.go:94] Retrieving report
2023-05-04T16:34:40.315399194Z I0504 16:34:40.315381       1 requests.go:100] Retrieving report for cluster: 91e347a3-3761-416f-abcc-9282fb097dea
2023-05-04T16:34:40.315417439Z I0504 16:34:40.315410       1 requests.go:101] Endpoint: https://console.redhat.com/api/insights-results-aggregator/v2/cluster/91e347a3-3761-416f-abcc-9282fb097dea/reports
2023-05-04T16:34:40.317952797Z I0504 16:34:40.317938       1 requests.go:111] Retrieving report from https://console.redhat.com/api/insights-results-aggregator/v2/cluster/91e347a3-3761-416f-abcc-9282fb097dea/reports
2023-05-04T16:34:41.764189475Z I0504 16:34:41.764155       1 insightsreport.go:129] Report retrieved
2023-05-04T16:34:41.764536095Z I0504 16:34:41.764522       1 insightsreport.go:137] Smart Proxy report correctly parsed
2023-05-04T16:34:41.764548148Z E0504 16:34:41.764535       1 insightsreport.go:317] Metric insightsclient_last_gather_time not updated. Failed to parse time: parsing time "" as "2006-01-02T15:04:05Z07:00": cannot parse "" as "2006"
2023-05-04T16:34:41.785017636Z I0504 16:34:41.784898       1 insightsreport.go:188] Report retrieved correctly
2023-05-04T16:34:46.889813038Z I0504 16:34:46.889766       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.299075ms" userAgent="Prometheus/2.39.1" audit-ID="bdedb5a8-6dca-4a3c-9367-a2397eccdabe" srcIP="10.128.0.90:54562" resp=200
2023-05-04T16:35:04.794180739Z I0504 16:35:04.794127       1 controller.go:447] The operator is healthy
2023-05-04T16:35:04.794180739Z I0504 16:35:04.794170       1 controller.go:325] No status update necessary, objects are identical
2023-05-04T16:35:16.889027904Z I0504 16:35:16.888980       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.130027ms" userAgent="Prometheus/2.39.1" audit-ID="9fac6df2-d029-4963-956c-2432379ea398" srcIP="10.128.0.90:54562" resp=200
2023-05-04T16:35:46.889740851Z I0504 16:35:46.889690       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.409004ms" userAgent="Prometheus/2.39.1" audit-ID="0c973cf2-49a3-4ad7-9d78-9dd968f73354" srcIP="10.128.0.90:54562" resp=200
2023-05-04T16:36:16.889685313Z I0504 16:36:16.889652       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.890465ms" userAgent="Prometheus/2.39.1" audit-ID="a3f0ffcf-67f7-4ef9-8df7-26a1e2ffc50f" srcIP="10.128.0.90:54562" resp=200
2023-05-04T16:36:46.890585724Z I0504 16:36:46.890191       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.745718ms" userAgent="Prometheus/2.39.1" audit-ID="dba42688-fa78-4ea3-ac1e-4620448b92bb" srcIP="10.128.0.90:54562" resp=200
2023-05-04T16:37:04.793636932Z I0504 16:37:04.793600       1 controller.go:447] The operator is healthy
2023-05-04T16:37:04.793676947Z I0504 16:37:04.793644       1 controller.go:325] No status update necessary, objects are identical
2023-05-04T16:37:16.889477192Z I0504 16:37:16.889411       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.104115ms" userAgent="Prometheus/2.39.1" audit-ID="61f60735-7991-46cc-af66-d1266bb35ee7" srcIP="10.128.0.90:54562" resp=200
2023-05-04T16:37:44.635815291Z I0504 16:37:44.635752       1 secretconfigobserver.go:136] Refreshing configuration from cluster pull secret
2023-05-04T16:37:44.638540664Z I0504 16:37:44.638448       1 secretconfigobserver.go:248] Found cloud.openshift.com token
2023-05-04T16:37:44.638540664Z I0504 16:37:44.638467       1 secretconfigobserver.go:162] Refreshing configuration from cluster secret
2023-05-04T16:37:44.640230353Z I0504 16:37:44.640196       1 secretconfigobserver.go:119] support secret does not exist
2023-05-04T16:37:46.888824889Z I0504 16:37:46.888788       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.085222ms" userAgent="Prometheus/2.39.1" audit-ID="e6207a4e-50cb-402b-aac0-1d93a202d07b" srcIP="10.128.0.90:54562" resp=200
2023-05-04T16:38:16.890703843Z I0504 16:38:16.890663       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="3.189513ms" userAgent="Prometheus/2.39.1" audit-ID="a9e6eecf-7e44-4bea-8e1d-5e62073b352c" srcIP="10.128.0.90:54562" resp=200
2023-05-04T16:38:46.559509897Z I0504 16:38:46.559464       1 reflector.go:559] k8s.io/apiserver/pkg/authentication/request/headerrequest/requestheader_controller.go:172: Watch close - *v1.ConfigMap total 7 items received
2023-05-04T16:38:46.889383673Z I0504 16:38:46.889344       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.452029ms" userAgent="Prometheus/2.39.1" audit-ID="6175a2ba-aaab-4af0-8d7a-8da40c090184" srcIP="10.128.0.90:54562" resp=200
2023-05-04T16:39:04.794415323Z I0504 16:39:04.794374       1 controller.go:447] The operator is healthy
2023-05-04T16:39:04.794451982Z I0504 16:39:04.794416       1 controller.go:325] No status update necessary, objects are identical
2023-05-04T16:39:16.889165856Z I0504 16:39:16.889130       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.459162ms" userAgent="Prometheus/2.39.1" audit-ID="0f0d2aa3-6b09-4bf8-9c80-3633950160d9" srcIP="10.128.0.90:54562" resp=200
2023-05-04T16:39:46.888801280Z I0504 16:39:46.888759       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.082404ms" userAgent="Prometheus/2.39.1" audit-ID="21a95e99-a04f-4e6c-8bdd-b1ce6620fa76" srcIP="10.128.0.90:54562" resp=200
2023-05-04T16:40:16.889242305Z I0504 16:40:16.889202       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.126988ms" userAgent="Prometheus/2.39.1" audit-ID="bf9f803f-81c0-40fa-b31b-b3bf55d86882" srcIP="10.128.0.90:54562" resp=200
2023-05-04T16:40:19.557937045Z I0504 16:40:19.557894       1 reflector.go:559] k8s.io/apiserver/pkg/server/dynamiccertificates/configmap_cafile_content.go:206: Watch close - *v1.ConfigMap total 9 items received
2023-05-04T16:40:33.558839819Z I0504 16:40:33.558806       1 reflector.go:559] k8s.io/apiserver/pkg/server/dynamiccertificates/configmap_cafile_content.go:206: Watch close - *v1.ConfigMap total 9 items received
2023-05-04T16:40:46.889502180Z I0504 16:40:46.889464       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="1.931122ms" userAgent="Prometheus/2.39.1" audit-ID="e04a6f25-a905-4113-b662-adf17d569056" srcIP="10.128.0.90:54562" resp=200
2023-05-04T16:41:04.793584075Z I0504 16:41:04.793548       1 controller.go:447] The operator is healthy
2023-05-04T16:41:04.793618971Z I0504 16:41:04.793590       1 controller.go:325] No status update necessary, objects are identical
2023-05-04T16:41:16.890180008Z I0504 16:41:16.890013       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="3.102719ms" userAgent="Prometheus/2.39.1" audit-ID="2ca02efa-01e3-4c00-a0af-0689f2a7c59e" srcIP="10.128.0.90:54562" resp=200
2023-05-04T16:41:46.889141024Z I0504 16:41:46.889109       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="1.929278ms" userAgent="Prometheus/2.39.1" audit-ID="9ae768f2-ee5c-4d61-a8cf-58d5f4211b76" srcIP="10.128.0.90:54562" resp=200
2023-05-04T16:42:16.889368840Z I0504 16:42:16.889327       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.434687ms" userAgent="Prometheus/2.39.1" audit-ID="fa46de54-22c4-4e05-b451-568f68b6eeda" srcIP="10.128.0.90:54562" resp=200
2023-05-04T16:42:44.640528237Z I0504 16:42:44.640488       1 secretconfigobserver.go:136] Refreshing configuration from cluster pull secret
2023-05-04T16:42:44.642714788Z I0504 16:42:44.642684       1 secretconfigobserver.go:248] Found cloud.openshift.com token
2023-05-04T16:42:44.642714788Z I0504 16:42:44.642705       1 secretconfigobserver.go:162] Refreshing configuration from cluster secret
2023-05-04T16:42:44.644166110Z I0504 16:42:44.644136       1 secretconfigobserver.go:119] support secret does not exist
2023-05-04T16:42:46.888911162Z I0504 16:42:46.888877       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.247736ms" userAgent="Prometheus/2.39.1" audit-ID="62b5e21b-0719-4783-a423-9ef93177c099" srcIP="10.128.0.90:54562" resp=200
2023-05-04T16:43:04.793370733Z I0504 16:43:04.793337       1 controller.go:447] The operator is healthy
2023-05-04T16:43:04.793451454Z I0504 16:43:04.793443       1 controller.go:325] No status update necessary, objects are identical
2023-05-04T16:43:16.888676614Z I0504 16:43:16.888640       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="1.863275ms" userAgent="Prometheus/2.39.1" audit-ID="098a3c1f-2c40-491a-9cc6-04b00072c112" srcIP="10.128.0.90:54562" resp=200
2023-05-04T16:43:46.888909434Z I0504 16:43:46.888872       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.281901ms" userAgent="Prometheus/2.39.1" audit-ID="63d6e6e9-255e-4528-aeca-f2b3f2e23e4c" srcIP="10.128.0.90:54562" resp=200
2023-05-04T16:44:16.891144627Z I0504 16:44:16.891111       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="4.057681ms" userAgent="Prometheus/2.39.1" audit-ID="223c61d1-3ebb-4da9-80fb-fd9c7adcae78" srcIP="10.128.0.90:54562" resp=200
2023-05-04T16:44:32.561766736Z I0504 16:44:32.561732       1 reflector.go:559] k8s.io/apiserver/pkg/authentication/request/headerrequest/requestheader_controller.go:172: Watch close - *v1.ConfigMap total 7 items received
2023-05-04T16:44:46.888896369Z I0504 16:44:46.888861       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="1.835543ms" userAgent="Prometheus/2.39.1" audit-ID="ca2ff2ce-97be-4f29-8bdd-8deda4cbd43b" srcIP="10.128.0.90:54562" resp=200
2023-05-04T16:45:04.796035328Z I0504 16:45:04.794133       1 controller.go:447] The operator is healthy
2023-05-04T16:45:04.796035328Z I0504 16:45:04.794178       1 controller.go:325] No status update necessary, objects are identical
2023-05-04T16:45:16.888673833Z I0504 16:45:16.888641       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.15374ms" userAgent="Prometheus/2.39.1" audit-ID="24d2d62c-4a46-413e-989a-cdcf7311dc5f" srcIP="10.128.0.90:54562" resp=200
2023-05-04T16:45:46.889449278Z I0504 16:45:46.889414       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.168337ms" userAgent="Prometheus/2.39.1" audit-ID="fbb1e803-51cf-4bcb-b421-c9bb4db691ef" srcIP="10.128.0.90:54562" resp=200
2023-05-04T16:46:04.561102925Z I0504 16:46:04.561069       1 reflector.go:559] k8s.io/apiserver/pkg/server/dynamiccertificates/configmap_cafile_content.go:206: Watch close - *v1.ConfigMap total 7 items received
2023-05-04T16:46:16.889104532Z I0504 16:46:16.889007       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="1.995664ms" userAgent="Prometheus/2.39.1" audit-ID="2cbceb5e-8895-4587-ba58-80779a0db969" srcIP="10.128.0.90:54562" resp=200
2023-05-04T16:46:46.888638014Z I0504 16:46:46.888602       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="1.957333ms" userAgent="Prometheus/2.39.1" audit-ID="4c643831-e8f9-4b9e-be21-5e90589abc4c" srcIP="10.128.0.90:54562" resp=200
2023-05-04T16:47:04.795086776Z I0504 16:47:04.794951       1 controller.go:447] The operator is healthy
2023-05-04T16:47:04.795086776Z I0504 16:47:04.795008       1 controller.go:325] No status update necessary, objects are identical
2023-05-04T16:47:16.889949606Z I0504 16:47:16.889810       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.495242ms" userAgent="Prometheus/2.39.1" audit-ID="a9b6a43c-9eb4-4e0b-ada7-e9df274ff4e9" srcIP="10.128.0.90:54562" resp=200
2023-05-04T16:47:44.645225550Z I0504 16:47:44.645182       1 secretconfigobserver.go:136] Refreshing configuration from cluster pull secret
2023-05-04T16:47:44.647535444Z I0504 16:47:44.647505       1 secretconfigobserver.go:248] Found cloud.openshift.com token
2023-05-04T16:47:44.647535444Z I0504 16:47:44.647524       1 secretconfigobserver.go:162] Refreshing configuration from cluster secret
2023-05-04T16:47:44.648771564Z I0504 16:47:44.648743       1 secretconfigobserver.go:119] support secret does not exist
2023-05-04T16:47:46.890044836Z I0504 16:47:46.889661       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.030119ms" userAgent="Prometheus/2.39.1" audit-ID="abc9fd16-837e-4122-865e-295e67bf8f0c" srcIP="10.128.0.90:54562" resp=200
2023-05-04T16:48:16.888631051Z I0504 16:48:16.888595       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="1.904624ms" userAgent="Prometheus/2.39.1" audit-ID="92331de6-e913-4cc6-9274-c23681c23d69" srcIP="10.128.0.90:54562" resp=200
2023-05-04T16:48:46.890362739Z I0504 16:48:46.889282       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.199096ms" userAgent="Prometheus/2.39.1" audit-ID="5073eb48-24f6-41aa-90f3-ced3f11ea583" srcIP="10.128.0.90:54562" resp=200
2023-05-04T16:49:04.793013523Z I0504 16:49:04.792975       1 controller.go:447] The operator is healthy
2023-05-04T16:49:04.793044461Z I0504 16:49:04.793037       1 controller.go:325] No status update necessary, objects are identical
2023-05-04T16:49:16.889311405Z I0504 16:49:16.889276       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.024819ms" userAgent="Prometheus/2.39.1" audit-ID="c9d89874-8cef-4636-9122-8e1ad6dbebb2" srcIP="10.128.0.90:54562" resp=200
2023-05-04T16:49:43.559852754Z I0504 16:49:43.559804       1 reflector.go:559] k8s.io/apiserver/pkg/server/dynamiccertificates/configmap_cafile_content.go:206: Watch close - *v1.ConfigMap total 11 items received
2023-05-04T16:49:46.889104798Z I0504 16:49:46.889074       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.104248ms" userAgent="Prometheus/2.39.1" audit-ID="34966420-7d4d-47e9-a9e1-478d74d84e08" srcIP="10.128.0.90:54562" resp=200
2023-05-04T16:50:16.890005818Z I0504 16:50:16.889373       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.411284ms" userAgent="Prometheus/2.39.1" audit-ID="613da831-8e29-469d-8380-df287b244a32" srcIP="10.128.0.90:54562" resp=200
2023-05-04T16:50:17.563596773Z I0504 16:50:17.563558       1 reflector.go:559] k8s.io/apiserver/pkg/authentication/request/headerrequest/requestheader_controller.go:172: Watch close - *v1.ConfigMap total 7 items received
2023-05-04T16:50:46.889587769Z I0504 16:50:46.889548       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.069433ms" userAgent="Prometheus/2.39.1" audit-ID="723442a3-48fb-4ff4-ad83-4a61764ba99c" srcIP="10.128.0.90:54562" resp=200
2023-05-04T16:51:04.793624787Z I0504 16:51:04.793581       1 controller.go:447] The operator is healthy
2023-05-04T16:51:04.793654853Z I0504 16:51:04.793620       1 controller.go:325] No status update necessary, objects are identical
2023-05-04T16:51:16.889391738Z I0504 16:51:16.889345       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="1.926585ms" userAgent="Prometheus/2.39.1" audit-ID="7714f6fa-c848-43aa-9571-5938a3f3bc57" srcIP="10.128.0.90:54562" resp=200
2023-05-04T16:51:46.889450847Z I0504 16:51:46.889418       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.171965ms" userAgent="Prometheus/2.39.1" audit-ID="16a7f970-4944-4ab5-a205-262ead766be0" srcIP="10.128.0.90:54562" resp=200
2023-05-04T16:52:14.563292670Z I0504 16:52:14.563260       1 reflector.go:559] k8s.io/apiserver/pkg/server/dynamiccertificates/configmap_cafile_content.go:206: Watch close - *v1.ConfigMap total 8 items received
2023-05-04T16:52:16.888846952Z I0504 16:52:16.888816       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.013988ms" userAgent="Prometheus/2.39.1" audit-ID="571f8343-bf16-44ee-9ee1-044a14fecd1b" srcIP="10.128.0.90:54562" resp=200
2023-05-04T16:52:44.648849981Z I0504 16:52:44.648809       1 secretconfigobserver.go:136] Refreshing configuration from cluster pull secret
2023-05-04T16:52:44.651112806Z I0504 16:52:44.651084       1 secretconfigobserver.go:248] Found cloud.openshift.com token
2023-05-04T16:52:44.651155737Z I0504 16:52:44.651148       1 secretconfigobserver.go:162] Refreshing configuration from cluster secret
2023-05-04T16:52:44.652749857Z I0504 16:52:44.652722       1 secretconfigobserver.go:119] support secret does not exist
2023-05-04T16:52:46.888915095Z I0504 16:52:46.888883       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="1.813873ms" userAgent="Prometheus/2.39.1" audit-ID="1e6b1a9c-0ed8-4213-838d-51664eaef36f" srcIP="10.128.0.90:54562" resp=200
2023-05-04T16:53:04.799495647Z I0504 16:53:04.799452       1 controller.go:447] The operator is healthy
2023-05-04T16:53:04.799580767Z I0504 16:53:04.799572       1 controller.go:325] No status update necessary, objects are identical
2023-05-04T16:53:16.889370872Z I0504 16:53:16.889336       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.36112ms" userAgent="Prometheus/2.39.1" audit-ID="f0854092-09c8-45df-a09e-7425ebc89131" srcIP="10.128.0.90:54562" resp=200
2023-05-04T16:53:46.889297036Z I0504 16:53:46.889264       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.039506ms" userAgent="Prometheus/2.39.1" audit-ID="13e0c6bf-7fb3-45f4-8801-8c8ac0711976" srcIP="10.128.0.90:54562" resp=200
2023-05-04T16:54:16.889695448Z I0504 16:54:16.889615       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.210787ms" userAgent="Prometheus/2.39.1" audit-ID="73d90247-5abd-4ce7-86c0-5f7bcfea8301" srcIP="10.128.0.90:54562" resp=200
2023-05-04T16:54:46.888777702Z I0504 16:54:46.888739       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.108085ms" userAgent="Prometheus/2.39.1" audit-ID="ab6e0a52-645c-4483-ac49-63eac4c00a99" srcIP="10.128.0.90:54562" resp=200
2023-05-04T16:55:04.794365868Z I0504 16:55:04.794328       1 controller.go:447] The operator is healthy
2023-05-04T16:55:04.794397698Z I0504 16:55:04.794370       1 controller.go:325] No status update necessary, objects are identical
2023-05-04T16:55:16.890577616Z I0504 16:55:16.890538       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="3.388036ms" userAgent="Prometheus/2.39.1" audit-ID="55dc7243-b067-473b-a34e-62dd3ef52983" srcIP="10.128.0.90:54562" resp=200
2023-05-04T16:55:46.888855364Z I0504 16:55:46.888816       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.232439ms" userAgent="Prometheus/2.39.1" audit-ID="1ebe1172-c089-409e-8bd5-b5cfe52f2c6d" srcIP="10.128.0.90:54562" resp=200
2023-05-04T16:56:16.888633768Z I0504 16:56:16.888575       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.08963ms" userAgent="Prometheus/2.39.1" audit-ID="1f56763e-9063-4df7-a12e-f6ddbd230e8b" srcIP="10.128.0.90:54562" resp=200
2023-05-04T16:56:42.561842034Z I0504 16:56:42.561799       1 reflector.go:559] k8s.io/apiserver/pkg/server/dynamiccertificates/configmap_cafile_content.go:206: Watch close - *v1.ConfigMap total 8 items received
2023-05-04T16:56:46.888896741Z I0504 16:56:46.888855       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="1.954266ms" userAgent="Prometheus/2.39.1" audit-ID="b3f7012d-0bac-4115-bd80-7782771d2416" srcIP="10.128.0.90:54562" resp=200
2023-05-04T16:57:04.793852391Z I0504 16:57:04.793813       1 controller.go:447] The operator is healthy
2023-05-04T16:57:04.793881466Z I0504 16:57:04.793854       1 controller.go:325] No status update necessary, objects are identical
2023-05-04T16:57:16.890067715Z I0504 16:57:16.890033       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.922484ms" userAgent="Prometheus/2.39.1" audit-ID="f4c820ca-aaf2-4ba4-8cb5-ce34c9ddd402" srcIP="10.128.0.90:54562" resp=200
2023-05-04T16:57:37.565297586Z I0504 16:57:37.565256       1 reflector.go:559] k8s.io/apiserver/pkg/server/dynamiccertificates/configmap_cafile_content.go:206: Watch close - *v1.ConfigMap total 7 items received
2023-05-04T16:57:44.653819117Z I0504 16:57:44.653789       1 secretconfigobserver.go:136] Refreshing configuration from cluster pull secret
2023-05-04T16:57:44.656201698Z I0504 16:57:44.656187       1 secretconfigobserver.go:248] Found cloud.openshift.com token
2023-05-04T16:57:44.656232044Z I0504 16:57:44.656224       1 secretconfigobserver.go:162] Refreshing configuration from cluster secret
2023-05-04T16:57:44.657332870Z I0504 16:57:44.657321       1 secretconfigobserver.go:119] support secret does not exist
2023-05-04T16:57:46.889900101Z I0504 16:57:46.888956       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.471487ms" userAgent="Prometheus/2.39.1" audit-ID="ae8970e2-901d-4ac6-9e84-67b3191e2d5a" srcIP="10.128.0.90:54562" resp=200
2023-05-04T16:58:16.889675931Z I0504 16:58:16.889643       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.071967ms" userAgent="Prometheus/2.39.1" audit-ID="10731cbc-74cd-4a46-a92d-9206008c2099" srcIP="10.128.0.90:54562" resp=200
2023-05-04T16:58:46.888816565Z I0504 16:58:46.888785       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.044806ms" userAgent="Prometheus/2.39.1" audit-ID="2574d2fc-6aa9-467a-a275-e96176edcc1e" srcIP="10.128.0.90:54562" resp=200
2023-05-04T16:58:56.565076305Z I0504 16:58:56.565039       1 reflector.go:559] k8s.io/apiserver/pkg/authentication/request/headerrequest/requestheader_controller.go:172: Watch close - *v1.ConfigMap total 10 items received
2023-05-04T16:59:04.793064310Z I0504 16:59:04.793025       1 controller.go:447] The operator is healthy
2023-05-04T16:59:04.793093565Z I0504 16:59:04.793069       1 controller.go:325] No status update necessary, objects are identical
2023-05-04T16:59:16.889715649Z I0504 16:59:16.889680       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.172746ms" userAgent="Prometheus/2.39.1" audit-ID="6c4527c7-8681-4eef-b72c-8968a291ad99" srcIP="10.128.0.90:54562" resp=200
2023-05-04T16:59:46.889280999Z I0504 16:59:46.889244       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.079762ms" userAgent="Prometheus/2.39.1" audit-ID="59c05b4d-6d71-46c3-b395-653090da93e9" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:00:16.891417514Z I0504 17:00:16.890957       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.981264ms" userAgent="Prometheus/2.39.1" audit-ID="73bfcd5e-fcbc-4713-9ffa-8c50c18814e4" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:00:46.889171245Z I0504 17:00:46.889140       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.219204ms" userAgent="Prometheus/2.39.1" audit-ID="eadce7a6-6cba-4550-982e-900f93bb2ec9" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:01:04.793808661Z I0504 17:01:04.793775       1 controller.go:447] The operator is healthy
2023-05-04T17:01:04.793887609Z I0504 17:01:04.793879       1 controller.go:325] No status update necessary, objects are identical
2023-05-04T17:01:16.907470985Z I0504 17:01:16.907425       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="18.426452ms" userAgent="Prometheus/2.39.1" audit-ID="a24dc885-881f-42dd-af5d-d07872941efa" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:01:46.902810818Z I0504 17:01:46.902769       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.105991ms" userAgent="Prometheus/2.39.1" audit-ID="fa0df607-e04b-4e32-b66e-79464a1008e9" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:02:16.889395844Z I0504 17:02:16.889352       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.134895ms" userAgent="Prometheus/2.39.1" audit-ID="8d8a1ae1-7d93-47e4-ac29-454c6a891815" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:02:40.567261183Z I0504 17:02:40.566825       1 reflector.go:559] k8s.io/apiserver/pkg/server/dynamiccertificates/configmap_cafile_content.go:206: Watch close - *v1.ConfigMap total 7 items received
2023-05-04T17:02:44.657751498Z I0504 17:02:44.657711       1 secretconfigobserver.go:136] Refreshing configuration from cluster pull secret
2023-05-04T17:02:44.660470910Z I0504 17:02:44.660430       1 secretconfigobserver.go:248] Found cloud.openshift.com token
2023-05-04T17:02:44.660470910Z I0504 17:02:44.660454       1 secretconfigobserver.go:162] Refreshing configuration from cluster secret
2023-05-04T17:02:44.663661006Z I0504 17:02:44.663610       1 secretconfigobserver.go:119] support secret does not exist
2023-05-04T17:02:46.889843811Z I0504 17:02:46.889807       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.157458ms" userAgent="Prometheus/2.39.1" audit-ID="11706e98-9a8b-4c77-a25d-0db3f2a09b50" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:03:04.795004200Z I0504 17:03:04.794012       1 controller.go:447] The operator is healthy
2023-05-04T17:03:04.795004200Z I0504 17:03:04.794051       1 controller.go:325] No status update necessary, objects are identical
2023-05-04T17:03:16.889125082Z I0504 17:03:16.889079       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.123073ms" userAgent="Prometheus/2.39.1" audit-ID="50a56676-86df-4cd5-afe4-4d1a26a4b2e3" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:03:46.889465044Z I0504 17:03:46.889427       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="1.863706ms" userAgent="Prometheus/2.39.1" audit-ID="b9439815-524d-4027-b3a3-9dacb8a99ec2" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:04:16.889210263Z I0504 17:04:16.889172       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.076546ms" userAgent="Prometheus/2.39.1" audit-ID="dd6102a0-de3f-4d14-830c-812a3c63422e" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:04:46.889413624Z I0504 17:04:46.889371       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="1.992879ms" userAgent="Prometheus/2.39.1" audit-ID="d87422db-6344-49ed-8c25-e5081b871feb" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:05:04.797056619Z I0504 17:05:04.796448       1 controller.go:447] The operator is healthy
2023-05-04T17:05:04.797056619Z I0504 17:05:04.796489       1 controller.go:325] No status update necessary, objects are identical
2023-05-04T17:05:16.899071884Z I0504 17:05:16.896798       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="3.609673ms" userAgent="Prometheus/2.39.1" audit-ID="ad0c08ea-826c-4c37-8614-742d5c6612fb" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:05:46.890630103Z I0504 17:05:46.889819       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.534686ms" userAgent="Prometheus/2.39.1" audit-ID="cf5606ba-5809-4dce-9b53-f29c8ad4d667" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:05:54.567492830Z I0504 17:05:54.567449       1 reflector.go:559] k8s.io/apiserver/pkg/server/dynamiccertificates/configmap_cafile_content.go:206: Watch close - *v1.ConfigMap total 10 items received
2023-05-04T17:06:16.889134444Z I0504 17:06:16.889069       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="1.877923ms" userAgent="Prometheus/2.39.1" audit-ID="939ecfe3-d3e6-4b3d-aac2-f2558163b322" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:06:46.889088977Z I0504 17:06:46.889044       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.3238ms" userAgent="Prometheus/2.39.1" audit-ID="238ac458-97e3-4f8a-bcaf-5eb81fbc21de" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:07:04.793673964Z I0504 17:07:04.793635       1 controller.go:447] The operator is healthy
2023-05-04T17:07:04.793702076Z I0504 17:07:04.793675       1 controller.go:325] No status update necessary, objects are identical
2023-05-04T17:07:16.891053360Z I0504 17:07:16.889733       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.348827ms" userAgent="Prometheus/2.39.1" audit-ID="9d3f7976-11d2-4b6e-bc6f-945679b7f9a8" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:07:44.664500381Z I0504 17:07:44.664461       1 secretconfigobserver.go:136] Refreshing configuration from cluster pull secret
2023-05-04T17:07:44.666683386Z I0504 17:07:44.666649       1 secretconfigobserver.go:248] Found cloud.openshift.com token
2023-05-04T17:07:44.666683386Z I0504 17:07:44.666668       1 secretconfigobserver.go:162] Refreshing configuration from cluster secret
2023-05-04T17:07:44.667912462Z I0504 17:07:44.667887       1 secretconfigobserver.go:119] support secret does not exist
2023-05-04T17:07:46.889179366Z I0504 17:07:46.889144       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.026862ms" userAgent="Prometheus/2.39.1" audit-ID="8f33ff48-7f23-4423-a5d7-fc4e57d26c89" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:08:05.567139528Z I0504 17:08:05.567104       1 reflector.go:559] k8s.io/apiserver/pkg/authentication/request/headerrequest/requestheader_controller.go:172: Watch close - *v1.ConfigMap total 10 items received
2023-05-04T17:08:16.889609432Z I0504 17:08:16.889571       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.191191ms" userAgent="Prometheus/2.39.1" audit-ID="7025fe55-b927-4e15-af8d-26b1725a7d6a" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:08:46.889162385Z I0504 17:08:46.888861       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.097135ms" userAgent="Prometheus/2.39.1" audit-ID="daaa5dea-ac2f-4e14-a326-b7904d9ec7d1" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:08:51.571892326Z I0504 17:08:51.571856       1 reflector.go:559] k8s.io/apiserver/pkg/server/dynamiccertificates/configmap_cafile_content.go:206: Watch close - *v1.ConfigMap total 8 items received
2023-05-04T17:09:04.792953862Z I0504 17:09:04.792914       1 controller.go:447] The operator is healthy
2023-05-04T17:09:04.792989208Z I0504 17:09:04.792957       1 controller.go:325] No status update necessary, objects are identical
2023-05-04T17:09:16.889522959Z I0504 17:09:16.889483       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.114206ms" userAgent="Prometheus/2.39.1" audit-ID="ee0d32eb-f092-45d4-9d72-587c01492f4e" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:09:46.888793088Z I0504 17:09:46.888757       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.063431ms" userAgent="Prometheus/2.39.1" audit-ID="ad561daf-fd43-45fc-948e-f9af3c8be93a" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:10:16.890008717Z I0504 17:10:16.889082       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.160764ms" userAgent="Prometheus/2.39.1" audit-ID="bf1ebd8e-4a72-4a9a-b4a3-b428ab213f0e" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:10:46.904899292Z I0504 17:10:46.904864       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="6.280573ms" userAgent="Prometheus/2.39.1" audit-ID="e1d8fdcf-d486-43cf-a7a6-afdee35a4c13" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:11:04.796085443Z I0504 17:11:04.795539       1 controller.go:447] The operator is healthy
2023-05-04T17:11:04.796085443Z I0504 17:11:04.795580       1 controller.go:325] No status update necessary, objects are identical
2023-05-04T17:11:16.908932963Z I0504 17:11:16.908027       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="4.32803ms" userAgent="Prometheus/2.39.1" audit-ID="7b58b2cb-bed5-4ca4-8db4-ae30e27167dc" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:11:46.891081254Z I0504 17:11:46.890973       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="3.533951ms" userAgent="Prometheus/2.39.1" audit-ID="91a8e74b-d947-4f5b-9d00-33981a7d3f66" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:11:50.570414808Z I0504 17:11:50.570248       1 reflector.go:559] k8s.io/apiserver/pkg/server/dynamiccertificates/configmap_cafile_content.go:206: Watch close - *v1.ConfigMap total 7 items received
2023-05-04T17:12:16.889379704Z I0504 17:12:16.889338       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="1.879637ms" userAgent="Prometheus/2.39.1" audit-ID="1677228e-8b00-48e2-b8f4-8ed7dad58101" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:12:44.668808486Z I0504 17:12:44.668740       1 secretconfigobserver.go:136] Refreshing configuration from cluster pull secret
2023-05-04T17:12:44.679696974Z I0504 17:12:44.679188       1 secretconfigobserver.go:248] Found cloud.openshift.com token
2023-05-04T17:12:44.679696974Z I0504 17:12:44.679209       1 secretconfigobserver.go:162] Refreshing configuration from cluster secret
2023-05-04T17:12:44.682298755Z I0504 17:12:44.682048       1 secretconfigobserver.go:119] support secret does not exist
2023-05-04T17:12:46.891039534Z I0504 17:12:46.889837       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.155274ms" userAgent="Prometheus/2.39.1" audit-ID="e23aba9b-9ef3-4085-a63b-620094c37645" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:13:04.793269074Z I0504 17:13:04.793231       1 controller.go:447] The operator is healthy
2023-05-04T17:13:04.793296635Z I0504 17:13:04.793271       1 controller.go:325] No status update necessary, objects are identical
2023-05-04T17:13:16.890133540Z I0504 17:13:16.890091       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.934476ms" userAgent="Prometheus/2.39.1" audit-ID="b3656ba5-99be-446a-97df-221a854cf3f2" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:13:46.889097711Z I0504 17:13:46.889039       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.117894ms" userAgent="Prometheus/2.39.1" audit-ID="3c397a9e-c009-4333-9c35-26c5ba9915c2" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:14:16.889310386Z I0504 17:14:16.889273       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.233871ms" userAgent="Prometheus/2.39.1" audit-ID="23828b64-5f75-47c6-804b-77d8ba09634f" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:14:46.888910622Z I0504 17:14:46.888862       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.198776ms" userAgent="Prometheus/2.39.1" audit-ID="16bdfbcb-0f7f-4980-af74-4a5e2b22ab53" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:15:04.799816950Z I0504 17:15:04.799771       1 controller.go:447] The operator is healthy
2023-05-04T17:15:04.799854401Z I0504 17:15:04.799811       1 controller.go:325] No status update necessary, objects are identical
2023-05-04T17:15:16.889384707Z I0504 17:15:16.889343       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="1.95613ms" userAgent="Prometheus/2.39.1" audit-ID="0bd77b23-212f-44a8-807d-64fbc870eba3" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:15:29.574147674Z I0504 17:15:29.574105       1 reflector.go:559] k8s.io/apiserver/pkg/server/dynamiccertificates/configmap_cafile_content.go:206: Watch close - *v1.ConfigMap total 8 items received
2023-05-04T17:15:46.888901398Z I0504 17:15:46.888865       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="1.983191ms" userAgent="Prometheus/2.39.1" audit-ID="1feb2b62-64e7-4ee7-b861-f8a7783592f6" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:16:16.889188624Z I0504 17:16:16.889156       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.147349ms" userAgent="Prometheus/2.39.1" audit-ID="c62c31c1-95a6-4609-a25a-12d4d0210f87" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:16:19.568967581Z I0504 17:16:19.568910       1 reflector.go:559] k8s.io/apiserver/pkg/authentication/request/headerrequest/requestheader_controller.go:172: Watch close - *v1.ConfigMap total 10 items received
2023-05-04T17:16:46.889693157Z I0504 17:16:46.889607       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.160213ms" userAgent="Prometheus/2.39.1" audit-ID="03a5344c-9aeb-4005-9136-5d4fc37f9887" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:17:04.794237470Z I0504 17:17:04.794197       1 controller.go:447] The operator is healthy
2023-05-04T17:17:04.794269961Z I0504 17:17:04.794237       1 controller.go:325] No status update necessary, objects are identical
2023-05-04T17:17:16.891486969Z I0504 17:17:16.891440       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="4.040671ms" userAgent="Prometheus/2.39.1" audit-ID="469b9eae-3ad2-4964-963b-e65e1ec101e2" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:17:19.572577586Z I0504 17:17:19.572533       1 reflector.go:559] k8s.io/apiserver/pkg/server/dynamiccertificates/configmap_cafile_content.go:206: Watch close - *v1.ConfigMap total 6 items received
2023-05-04T17:17:44.682475589Z I0504 17:17:44.682442       1 secretconfigobserver.go:136] Refreshing configuration from cluster pull secret
2023-05-04T17:17:44.685026555Z I0504 17:17:44.684948       1 secretconfigobserver.go:248] Found cloud.openshift.com token
2023-05-04T17:17:44.685082239Z I0504 17:17:44.685073       1 secretconfigobserver.go:162] Refreshing configuration from cluster secret
2023-05-04T17:17:44.687034893Z I0504 17:17:44.687000       1 secretconfigobserver.go:119] support secret does not exist
2023-05-04T17:17:46.888981015Z I0504 17:17:46.888914       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.314743ms" userAgent="Prometheus/2.39.1" audit-ID="97792196-51d8-4121-8f13-b1e51039e1ac" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:18:16.889200735Z I0504 17:18:16.889170       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.098407ms" userAgent="Prometheus/2.39.1" audit-ID="2951b089-e78f-4039-9426-ec38e02d5f9e" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:18:46.889761124Z I0504 17:18:46.889722       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.52637ms" userAgent="Prometheus/2.39.1" audit-ID="29c8491a-f9fd-42ad-9881-d0d8075a038b" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:19:04.819117778Z I0504 17:19:04.819073       1 controller.go:447] The operator is healthy
2023-05-04T17:19:04.819201284Z I0504 17:19:04.819192       1 controller.go:325] No status update necessary, objects are identical
2023-05-04T17:19:16.889170392Z I0504 17:19:16.889136       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.102174ms" userAgent="Prometheus/2.39.1" audit-ID="fb7e6e36-5c98-4dad-bc33-4f0d3c3610be" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:19:46.889011311Z I0504 17:19:46.888680       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.213433ms" userAgent="Prometheus/2.39.1" audit-ID="f2bd5910-c5a3-4e1b-88bc-2db98c189077" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:20:16.897110111Z I0504 17:20:16.896073       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="9.081709ms" userAgent="Prometheus/2.39.1" audit-ID="22a53f80-165f-4afe-b128-96d075ca0a40" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:20:46.889308842Z I0504 17:20:46.889266       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.471186ms" userAgent="Prometheus/2.39.1" audit-ID="1fc89887-3c17-46d4-9a72-6f1e1f2db93e" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:20:51.576226170Z I0504 17:20:51.576178       1 reflector.go:559] k8s.io/apiserver/pkg/server/dynamiccertificates/configmap_cafile_content.go:206: Watch close - *v1.ConfigMap total 7 items received
2023-05-04T17:21:04.793160315Z I0504 17:21:04.793116       1 controller.go:447] The operator is healthy
2023-05-04T17:21:04.793192325Z I0504 17:21:04.793158       1 controller.go:325] No status update necessary, objects are identical
2023-05-04T17:21:16.889958228Z I0504 17:21:16.889924       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.289625ms" userAgent="Prometheus/2.39.1" audit-ID="c623de5d-8f36-44d8-b375-6c9ff5f7d0b3" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:21:46.889236280Z I0504 17:21:46.889192       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.140376ms" userAgent="Prometheus/2.39.1" audit-ID="fe2c404d-a407-4e8b-9e27-0f017a20281b" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:21:53.571099346Z I0504 17:21:53.571067       1 reflector.go:559] k8s.io/apiserver/pkg/authentication/request/headerrequest/requestheader_controller.go:172: Watch close - *v1.ConfigMap total 7 items received
2023-05-04T17:22:16.891353082Z I0504 17:22:16.891305       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.179639ms" userAgent="Prometheus/2.39.1" audit-ID="b42e8277-ddb5-42c3-a2f5-8958b993c029" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:22:44.687889119Z I0504 17:22:44.687836       1 secretconfigobserver.go:136] Refreshing configuration from cluster pull secret
2023-05-04T17:22:44.690058850Z I0504 17:22:44.690017       1 secretconfigobserver.go:248] Found cloud.openshift.com token
2023-05-04T17:22:44.690058850Z I0504 17:22:44.690038       1 secretconfigobserver.go:162] Refreshing configuration from cluster secret
2023-05-04T17:22:44.691282856Z I0504 17:22:44.691256       1 secretconfigobserver.go:119] support secret does not exist
2023-05-04T17:22:46.890346069Z I0504 17:22:46.889273       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.065976ms" userAgent="Prometheus/2.39.1" audit-ID="5c9884b6-49e2-46d4-874d-60aa07095bca" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:22:57.574286942Z I0504 17:22:57.574243       1 reflector.go:559] k8s.io/apiserver/pkg/server/dynamiccertificates/configmap_cafile_content.go:206: Watch close - *v1.ConfigMap total 7 items received
2023-05-04T17:23:04.794067398Z I0504 17:23:04.794024       1 controller.go:447] The operator is healthy
2023-05-04T17:23:04.794104066Z I0504 17:23:04.794067       1 controller.go:325] No status update necessary, objects are identical
2023-05-04T17:23:16.889719790Z I0504 17:23:16.889676       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.082948ms" userAgent="Prometheus/2.39.1" audit-ID="9d560d29-d258-4b7f-bac4-4e15918576ce" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:23:46.891088725Z I0504 17:23:46.890745       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.576544ms" userAgent="Prometheus/2.39.1" audit-ID="f2523744-cfb2-47d3-807f-a798e1739e96" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:24:16.888784842Z I0504 17:24:16.888732       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.023777ms" userAgent="Prometheus/2.39.1" audit-ID="fd29c3eb-97b0-4eb5-aec7-07b3ec71bdbd" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:24:46.888814938Z I0504 17:24:46.888776       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="1.913891ms" userAgent="Prometheus/2.39.1" audit-ID="3ccc1c3e-298b-4e51-ac70-2b5ca049300d" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:25:04.794367975Z I0504 17:25:04.794323       1 controller.go:447] The operator is healthy
2023-05-04T17:25:04.794414853Z I0504 17:25:04.794377       1 controller.go:325] No status update necessary, objects are identical
2023-05-04T17:25:16.892039866Z I0504 17:25:16.890694       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.44126ms" userAgent="Prometheus/2.39.1" audit-ID="07acbc0a-4b50-40ac-9759-51184fed79c8" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:25:46.890028351Z I0504 17:25:46.889985       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.218482ms" userAgent="Prometheus/2.39.1" audit-ID="f8b8540c-1131-48d4-9cd9-ef0c6739a33d" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:26:16.891432471Z I0504 17:26:16.890330       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="3.390511ms" userAgent="Prometheus/2.39.1" audit-ID="897dcebe-b184-42f5-be02-e50a6f6f08c9" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:26:46.889151313Z I0504 17:26:46.889118       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.095672ms" userAgent="Prometheus/2.39.1" audit-ID="cbd141c2-3453-4fa1-9be9-7f2f295f55e5" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:27:04.793998599Z I0504 17:27:04.793710       1 controller.go:447] The operator is healthy
2023-05-04T17:27:04.793998599Z I0504 17:27:04.793753       1 controller.go:325] No status update necessary, objects are identical
2023-05-04T17:27:16.889218946Z I0504 17:27:16.889182       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.135186ms" userAgent="Prometheus/2.39.1" audit-ID="bd5b4f58-e3ef-42d4-a1de-971364240085" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:27:44.691373866Z I0504 17:27:44.691331       1 secretconfigobserver.go:136] Refreshing configuration from cluster pull secret
2023-05-04T17:27:44.693649195Z I0504 17:27:44.693612       1 secretconfigobserver.go:248] Found cloud.openshift.com token
2023-05-04T17:27:44.693649195Z I0504 17:27:44.693632       1 secretconfigobserver.go:162] Refreshing configuration from cluster secret
2023-05-04T17:27:44.695026970Z I0504 17:27:44.694933       1 secretconfigobserver.go:119] support secret does not exist
2023-05-04T17:27:46.894162168Z I0504 17:27:46.893063       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="1.886899ms" userAgent="Prometheus/2.39.1" audit-ID="3d6e85ca-6294-477b-82ef-276fe0295fdc" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:27:57.576870434Z I0504 17:27:57.576826       1 reflector.go:559] k8s.io/apiserver/pkg/server/dynamiccertificates/configmap_cafile_content.go:206: Watch close - *v1.ConfigMap total 6 items received
2023-05-04T17:28:16.889194337Z I0504 17:28:16.889081       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.178247ms" userAgent="Prometheus/2.39.1" audit-ID="892207eb-82b2-45ff-89ef-efe39c672734" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:28:46.889510307Z I0504 17:28:46.889468       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.601691ms" userAgent="Prometheus/2.39.1" audit-ID="eb27af82-415c-45ba-bc43-fe21b482ea6f" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:29:04.795760525Z I0504 17:29:04.795718       1 controller.go:447] The operator is healthy
2023-05-04T17:29:04.795804086Z I0504 17:29:04.795766       1 controller.go:325] No status update necessary, objects are identical
2023-05-04T17:29:15.573338048Z I0504 17:29:15.573300       1 reflector.go:559] k8s.io/apiserver/pkg/authentication/request/headerrequest/requestheader_controller.go:172: Watch close - *v1.ConfigMap total 8 items received
2023-05-04T17:29:16.893731922Z I0504 17:29:16.893691       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="5.658056ms" userAgent="Prometheus/2.39.1" audit-ID="2a2f9441-e25f-4e90-98fa-0c1844c250ab" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:29:46.889336813Z I0504 17:29:46.889304       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.274006ms" userAgent="Prometheus/2.39.1" audit-ID="691e0698-79dd-4a98-bbd0-c5c8cd269bef" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:30:10.578627683Z I0504 17:30:10.578585       1 reflector.go:559] k8s.io/apiserver/pkg/server/dynamiccertificates/configmap_cafile_content.go:206: Watch close - *v1.ConfigMap total 11 items received
2023-05-04T17:30:16.890147508Z I0504 17:30:16.889382       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.291129ms" userAgent="Prometheus/2.39.1" audit-ID="11558c99-0042-4d60-9d10-74a601a346b0" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:30:46.890459420Z I0504 17:30:46.890422       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.98969ms" userAgent="Prometheus/2.39.1" audit-ID="cdc2341d-f8bc-4055-89e1-f149e19b7c6e" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:31:04.793736453Z I0504 17:31:04.793690       1 controller.go:447] The operator is healthy
2023-05-04T17:31:04.793774003Z I0504 17:31:04.793735       1 controller.go:325] No status update necessary, objects are identical
2023-05-04T17:31:16.889656749Z I0504 17:31:16.889608       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.237728ms" userAgent="Prometheus/2.39.1" audit-ID="cc02eb02-4bca-438e-82ef-c019acd19489" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:31:46.891015334Z I0504 17:31:46.889957       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.338789ms" userAgent="Prometheus/2.39.1" audit-ID="85660175-520b-4bb7-9f62-8b992f64b511" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:32:16.889122575Z I0504 17:32:16.889077       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.16381ms" userAgent="Prometheus/2.39.1" audit-ID="f11d9453-740b-480c-bd7f-0aff6c49f50f" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:32:44.695741087Z I0504 17:32:44.695691       1 secretconfigobserver.go:136] Refreshing configuration from cluster pull secret
2023-05-04T17:32:44.698190964Z I0504 17:32:44.698158       1 secretconfigobserver.go:248] Found cloud.openshift.com token
2023-05-04T17:32:44.698208557Z I0504 17:32:44.698187       1 secretconfigobserver.go:162] Refreshing configuration from cluster secret
2023-05-04T17:32:44.699713931Z I0504 17:32:44.699692       1 secretconfigobserver.go:119] support secret does not exist
2023-05-04T17:32:46.889131163Z I0504 17:32:46.889098       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.188847ms" userAgent="Prometheus/2.39.1" audit-ID="2d525277-17d9-42cf-b42d-2ec73c3d1764" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:33:04.793657520Z I0504 17:33:04.793622       1 controller.go:447] The operator is healthy
2023-05-04T17:33:04.793748471Z I0504 17:33:04.793737       1 controller.go:325] No status update necessary, objects are identical
2023-05-04T17:33:16.889560825Z I0504 17:33:16.889525       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.236516ms" userAgent="Prometheus/2.39.1" audit-ID="8a19fa5f-434b-463f-85d9-430aeedb17a2" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:33:46.889410706Z I0504 17:33:46.889376       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.105631ms" userAgent="Prometheus/2.39.1" audit-ID="14a8fcf3-23a2-4695-aea2-99916e5abc46" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:34:16.889393124Z I0504 17:34:16.889354       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.066217ms" userAgent="Prometheus/2.39.1" audit-ID="4fb73d5a-22ef-4e94-a80a-0610b645b4a2" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:34:28.579357314Z I0504 17:34:28.579310       1 reflector.go:559] k8s.io/apiserver/pkg/server/dynamiccertificates/configmap_cafile_content.go:206: Watch close - *v1.ConfigMap total 8 items received
2023-05-04T17:34:46.889793146Z I0504 17:34:46.889734       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.227139ms" userAgent="Prometheus/2.39.1" audit-ID="e9903708-f378-4aa7-897b-50dbb19bc789" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:35:04.797052757Z I0504 17:35:04.793841       1 controller.go:447] The operator is healthy
2023-05-04T17:35:04.797052757Z I0504 17:35:04.793885       1 controller.go:325] No status update necessary, objects are identical
2023-05-04T17:35:16.889652492Z I0504 17:35:16.889608       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.491695ms" userAgent="Prometheus/2.39.1" audit-ID="2b527d62-9d6a-42a7-9f7b-936194cb44d4" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:35:33.575139261Z I0504 17:35:33.575095       1 reflector.go:559] k8s.io/apiserver/pkg/authentication/request/headerrequest/requestheader_controller.go:172: Watch close - *v1.ConfigMap total 8 items received
2023-05-04T17:35:46.889540883Z I0504 17:35:46.889462       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.409872ms" userAgent="Prometheus/2.39.1" audit-ID="638ee1f6-0abd-4711-965f-799a18bd8bf2" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:36:16.580547977Z I0504 17:36:16.580511       1 reflector.go:559] k8s.io/apiserver/pkg/server/dynamiccertificates/configmap_cafile_content.go:206: Watch close - *v1.ConfigMap total 8 items received
2023-05-04T17:36:16.892225210Z I0504 17:36:16.892183       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="5.369234ms" userAgent="Prometheus/2.39.1" audit-ID="5efc6410-b448-44e3-8124-d708674848ea" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:36:46.889037871Z I0504 17:36:46.888478       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="1.933007ms" userAgent="Prometheus/2.39.1" audit-ID="42642b5b-ca63-4839-90e0-d229076a8c61" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:37:04.794150306Z I0504 17:37:04.794117       1 controller.go:447] The operator is healthy
2023-05-04T17:37:04.794227060Z I0504 17:37:04.794218       1 controller.go:325] No status update necessary, objects are identical
2023-05-04T17:37:16.889549545Z I0504 17:37:16.889439       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.411284ms" userAgent="Prometheus/2.39.1" audit-ID="99a4e56e-30a5-48a6-be95-cf41430721ee" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:37:44.700112184Z I0504 17:37:44.700061       1 secretconfigobserver.go:136] Refreshing configuration from cluster pull secret
2023-05-04T17:37:44.702419594Z I0504 17:37:44.702389       1 secretconfigobserver.go:248] Found cloud.openshift.com token
2023-05-04T17:37:44.702419594Z I0504 17:37:44.702408       1 secretconfigobserver.go:162] Refreshing configuration from cluster secret
2023-05-04T17:37:44.703738799Z I0504 17:37:44.703713       1 secretconfigobserver.go:119] support secret does not exist
2023-05-04T17:37:46.889525875Z I0504 17:37:46.889488       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.176403ms" userAgent="Prometheus/2.39.1" audit-ID="f6e29230-6d06-48eb-970e-b2f31a5a42fa" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:38:16.889077117Z I0504 17:38:16.889040       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.216198ms" userAgent="Prometheus/2.39.1" audit-ID="90da4f21-3131-4306-a80a-e288a99049f3" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:38:46.889486292Z I0504 17:38:46.889450       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.104178ms" userAgent="Prometheus/2.39.1" audit-ID="c71f8e44-e87a-4510-80f2-a9630c0f3c12" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:39:04.806196444Z I0504 17:39:04.796668       1 controller.go:447] The operator is healthy
2023-05-04T17:39:04.806196444Z I0504 17:39:04.796709       1 controller.go:325] No status update necessary, objects are identical
2023-05-04T17:39:16.894180887Z I0504 17:39:16.894144       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="7.118146ms" userAgent="Prometheus/2.39.1" audit-ID="5c7af65b-6975-4d3e-af18-690ebda43fbe" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:39:41.581914260Z I0504 17:39:41.581868       1 reflector.go:559] k8s.io/apiserver/pkg/server/dynamiccertificates/configmap_cafile_content.go:206: Watch close - *v1.ConfigMap total 7 items received
2023-05-04T17:39:46.889128444Z I0504 17:39:46.889094       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.386257ms" userAgent="Prometheus/2.39.1" audit-ID="49436c47-167c-4174-9ddf-fbf1d8249aad" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:40:16.889827719Z I0504 17:40:16.889789       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.181242ms" userAgent="Prometheus/2.39.1" audit-ID="b27fd88a-27d8-4859-92d6-a488f4992cf7" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:40:37.577659834Z I0504 17:40:37.577612       1 reflector.go:559] k8s.io/apiserver/pkg/authentication/request/headerrequest/requestheader_controller.go:172: Watch close - *v1.ConfigMap total 7 items received
2023-05-04T17:40:46.888775429Z I0504 17:40:46.888736       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.040809ms" userAgent="Prometheus/2.39.1" audit-ID="2d43b365-acf3-4ed8-91e6-077d38cc2014" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:41:04.810058501Z I0504 17:41:04.809903       1 controller.go:447] The operator is healthy
2023-05-04T17:41:04.810169649Z I0504 17:41:04.810159       1 controller.go:325] No status update necessary, objects are identical
2023-05-04T17:41:16.889323622Z I0504 17:41:16.889284       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.223692ms" userAgent="Prometheus/2.39.1" audit-ID="5080ef62-9c88-4b8b-9e39-e9bbdc52a9d2" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:41:46.889245378Z I0504 17:41:46.889203       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.401105ms" userAgent="Prometheus/2.39.1" audit-ID="0a3282f7-61eb-452a-b845-40119713383f" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:42:16.889388388Z I0504 17:42:16.889351       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.415963ms" userAgent="Prometheus/2.39.1" audit-ID="09a2f646-a361-4c32-835d-86e9c790e287" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:42:42.582675605Z I0504 17:42:42.582637       1 reflector.go:559] k8s.io/apiserver/pkg/server/dynamiccertificates/configmap_cafile_content.go:206: Watch close - *v1.ConfigMap total 7 items received
2023-05-04T17:42:44.704116078Z I0504 17:42:44.704076       1 secretconfigobserver.go:136] Refreshing configuration from cluster pull secret
2023-05-04T17:42:44.706142180Z I0504 17:42:44.706105       1 secretconfigobserver.go:248] Found cloud.openshift.com token
2023-05-04T17:42:44.706142180Z I0504 17:42:44.706127       1 secretconfigobserver.go:162] Refreshing configuration from cluster secret
2023-05-04T17:42:44.707448701Z I0504 17:42:44.707427       1 secretconfigobserver.go:119] support secret does not exist
2023-05-04T17:42:46.888891016Z I0504 17:42:46.888852       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.156928ms" userAgent="Prometheus/2.39.1" audit-ID="b5b096c8-f73e-437e-8e2e-6b0a27fc45f3" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:43:04.805063290Z I0504 17:43:04.804624       1 controller.go:447] The operator is healthy
2023-05-04T17:43:04.805063290Z I0504 17:43:04.804666       1 controller.go:325] No status update necessary, objects are identical
2023-05-04T17:43:16.890212202Z I0504 17:43:16.890167       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.680199ms" userAgent="Prometheus/2.39.1" audit-ID="83423eb1-0094-4445-a28b-e45e16d2e263" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:43:46.889411500Z I0504 17:43:46.889359       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.265981ms" userAgent="Prometheus/2.39.1" audit-ID="f5b186f2-d82d-46e8-87da-8df4cce9b494" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:44:16.889450848Z I0504 17:44:16.889388       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.463132ms" userAgent="Prometheus/2.39.1" audit-ID="dbcad300-8b9a-439d-bce9-ee8cd29107ac" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:44:46.890021384Z I0504 17:44:46.888872       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.240764ms" userAgent="Prometheus/2.39.1" audit-ID="3c32ad4c-150f-4a81-b5a4-2d198e95ba7c" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:45:04.805566429Z I0504 17:45:04.805528       1 controller.go:447] The operator is healthy
2023-05-04T17:45:04.805658001Z I0504 17:45:04.805649       1 controller.go:325] No status update necessary, objects are identical
2023-05-04T17:45:16.888628254Z I0504 17:45:16.888585       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.086475ms" userAgent="Prometheus/2.39.1" audit-ID="637aecb8-a154-4b5b-9607-3d46a8206217" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:45:46.889216750Z I0504 17:45:46.889181       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.076185ms" userAgent="Prometheus/2.39.1" audit-ID="c92f8633-b8a8-4bdc-98bc-33e94cdf3e64" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:46:16.889367276Z I0504 17:46:16.889334       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="1.959457ms" userAgent="Prometheus/2.39.1" audit-ID="25972366-cdff-496e-8fa0-d1ab3cd4b96c" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:46:31.584441069Z I0504 17:46:31.584402       1 reflector.go:559] k8s.io/apiserver/pkg/server/dynamiccertificates/configmap_cafile_content.go:206: Watch close - *v1.ConfigMap total 8 items received
2023-05-04T17:46:46.889545689Z I0504 17:46:46.889506       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.175202ms" userAgent="Prometheus/2.39.1" audit-ID="3b33b408-4659-4af4-8fbf-1aef4364de28" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:47:04.798547236Z I0504 17:47:04.798505       1 controller.go:447] The operator is healthy
2023-05-04T17:47:04.798582933Z I0504 17:47:04.798549       1 controller.go:325] No status update necessary, objects are identical
2023-05-04T17:47:16.889781526Z I0504 17:47:16.889741       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.205789ms" userAgent="Prometheus/2.39.1" audit-ID="6e7306bc-e692-47b0-8151-0149dfb4bfba" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:47:44.707851617Z I0504 17:47:44.707810       1 secretconfigobserver.go:136] Refreshing configuration from cluster pull secret
2023-05-04T17:47:44.710275746Z I0504 17:47:44.710240       1 secretconfigobserver.go:248] Found cloud.openshift.com token
2023-05-04T17:47:44.710275746Z I0504 17:47:44.710261       1 secretconfigobserver.go:162] Refreshing configuration from cluster secret
2023-05-04T17:47:44.711652639Z I0504 17:47:44.711630       1 secretconfigobserver.go:119] support secret does not exist
2023-05-04T17:47:46.890034973Z I0504 17:47:46.889941       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.173228ms" userAgent="Prometheus/2.39.1" audit-ID="b7cb268e-93f3-4a6f-a37e-96a2cc47f617" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:48:16.889676998Z I0504 17:48:16.889640       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.828988ms" userAgent="Prometheus/2.39.1" audit-ID="8596ed16-3a2a-49a0-8dcb-c955ad9c7082" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:48:46.890954419Z I0504 17:48:46.889992       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.577125ms" userAgent="Prometheus/2.39.1" audit-ID="ecbf33a9-854f-4d43-bdc7-f679afdadf08" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:49:04.793882361Z I0504 17:49:04.793834       1 controller.go:447] The operator is healthy
2023-05-04T17:49:04.793974865Z I0504 17:49:04.793958       1 controller.go:325] No status update necessary, objects are identical
2023-05-04T17:49:14.579319270Z I0504 17:49:14.579284       1 reflector.go:559] k8s.io/apiserver/pkg/authentication/request/headerrequest/requestheader_controller.go:172: Watch close - *v1.ConfigMap total 10 items received
2023-05-04T17:49:16.889777757Z I0504 17:49:16.889738       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.191471ms" userAgent="Prometheus/2.39.1" audit-ID="57459ddc-d077-49de-bb81-8d7d0f33b8a7" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:49:40.584846354Z I0504 17:49:40.584800       1 reflector.go:559] k8s.io/apiserver/pkg/server/dynamiccertificates/configmap_cafile_content.go:206: Watch close - *v1.ConfigMap total 8 items received
2023-05-04T17:49:46.888930664Z I0504 17:49:46.888892       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="1.99875ms" userAgent="Prometheus/2.39.1" audit-ID="af125b0e-c338-4297-80bc-9999fd046a1b" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:50:16.890010229Z I0504 17:50:16.889215       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.342324ms" userAgent="Prometheus/2.39.1" audit-ID="08255180-83d2-4f2b-a7b8-af9ae885bf71" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:50:46.889056497Z I0504 17:50:46.889014       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.122572ms" userAgent="Prometheus/2.39.1" audit-ID="2ded9fb4-297e-4d3d-8e09-5fc75b90c868" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:51:04.795035387Z I0504 17:51:04.794691       1 controller.go:447] The operator is healthy
2023-05-04T17:51:04.795035387Z I0504 17:51:04.794731       1 controller.go:325] No status update necessary, objects are identical
2023-05-04T17:51:16.889965801Z I0504 17:51:16.889914       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.860828ms" userAgent="Prometheus/2.39.1" audit-ID="f7fac75c-b76c-424d-8806-cfdc28dd6d50" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:51:46.889017039Z I0504 17:51:46.888968       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="1.961701ms" userAgent="Prometheus/2.39.1" audit-ID="5b3735b4-430a-470d-8874-85e2fbacc92d" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:52:16.890024267Z I0504 17:52:16.889211       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.122191ms" userAgent="Prometheus/2.39.1" audit-ID="611f7b69-8921-4869-9e9d-ec1a97472f5b" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:52:44.711725214Z I0504 17:52:44.711671       1 secretconfigobserver.go:136] Refreshing configuration from cluster pull secret
2023-05-04T17:52:44.713995945Z I0504 17:52:44.713921       1 secretconfigobserver.go:248] Found cloud.openshift.com token
2023-05-04T17:52:44.713995945Z I0504 17:52:44.713943       1 secretconfigobserver.go:162] Refreshing configuration from cluster secret
2023-05-04T17:52:44.716416176Z I0504 17:52:44.716377       1 secretconfigobserver.go:119] support secret does not exist
2023-05-04T17:52:46.890166940Z I0504 17:52:46.890124       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.973929ms" userAgent="Prometheus/2.39.1" audit-ID="2a0f61ba-1df9-4fb7-98c2-2b6e166b7e0c" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:53:04.798223289Z I0504 17:53:04.798071       1 controller.go:447] The operator is healthy
2023-05-04T17:53:04.798330560Z I0504 17:53:04.798311       1 controller.go:325] No status update necessary, objects are identical
2023-05-04T17:53:05.586727033Z I0504 17:53:05.586683       1 reflector.go:559] k8s.io/apiserver/pkg/server/dynamiccertificates/configmap_cafile_content.go:206: Watch close - *v1.ConfigMap total 8 items received
2023-05-04T17:53:16.889267659Z I0504 17:53:16.889233       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="1.902801ms" userAgent="Prometheus/2.39.1" audit-ID="b5ddfd54-93bc-4480-bf8f-e183f2f312fd" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:53:46.890686440Z I0504 17:53:46.890643       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="3.376405ms" userAgent="Prometheus/2.39.1" audit-ID="49bbf725-a607-473b-8584-b1fc808206e7" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:54:16.890088445Z I0504 17:54:16.889152       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.061879ms" userAgent="Prometheus/2.39.1" audit-ID="14155614-7398-44f5-99ba-c59f9d796051" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:54:46.889411310Z I0504 17:54:46.889368       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.222409ms" userAgent="Prometheus/2.39.1" audit-ID="3c626940-601a-4e40-a79b-06a57d2946d7" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:55:04.793947052Z I0504 17:55:04.793905       1 controller.go:447] The operator is healthy
2023-05-04T17:55:04.794042621Z I0504 17:55:04.794033       1 controller.go:325] No status update necessary, objects are identical
2023-05-04T17:55:16.889578480Z I0504 17:55:16.889539       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.409641ms" userAgent="Prometheus/2.39.1" audit-ID="1cbf95c3-0a56-47e8-8faa-a6584a642084" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:55:46.889794028Z I0504 17:55:46.889758       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.228471ms" userAgent="Prometheus/2.39.1" audit-ID="9ed86ff7-83e0-4263-a12d-fccdd8e77edb" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:56:16.889769126Z I0504 17:56:16.889732       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.424189ms" userAgent="Prometheus/2.39.1" audit-ID="d7c462d7-9548-4dad-bd63-323c49920622" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:56:46.889933409Z I0504 17:56:46.889889       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.108255ms" userAgent="Prometheus/2.39.1" audit-ID="0a112be9-caac-4d5a-9fff-06481ef5f829" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:57:04.793852173Z I0504 17:57:04.793807       1 controller.go:447] The operator is healthy
2023-05-04T17:57:04.793931202Z I0504 17:57:04.793915       1 controller.go:325] No status update necessary, objects are identical
2023-05-04T17:57:16.889278765Z I0504 17:57:16.889240       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.220637ms" userAgent="Prometheus/2.39.1" audit-ID="e46b74e4-b687-4419-ab5e-f443bdc6583d" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:57:20.581130622Z I0504 17:57:20.581089       1 reflector.go:559] k8s.io/apiserver/pkg/authentication/request/headerrequest/requestheader_controller.go:172: Watch close - *v1.ConfigMap total 10 items received
2023-05-04T17:57:44.717225472Z I0504 17:57:44.717188       1 secretconfigobserver.go:136] Refreshing configuration from cluster pull secret
2023-05-04T17:57:44.719579529Z I0504 17:57:44.719542       1 secretconfigobserver.go:248] Found cloud.openshift.com token
2023-05-04T17:57:44.719579529Z I0504 17:57:44.719560       1 secretconfigobserver.go:162] Refreshing configuration from cluster secret
2023-05-04T17:57:44.720739365Z I0504 17:57:44.720718       1 secretconfigobserver.go:119] support secret does not exist
2023-05-04T17:57:46.889017289Z I0504 17:57:46.888593       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.134445ms" userAgent="Prometheus/2.39.1" audit-ID="1d437ceb-e756-405a-8676-7ca460afb441" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:58:16.890183502Z I0504 17:58:16.889102       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="1.922006ms" userAgent="Prometheus/2.39.1" audit-ID="246c9519-d36d-4a82-a244-b74db518aad2" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:58:37.586893810Z I0504 17:58:37.586853       1 reflector.go:559] k8s.io/apiserver/pkg/server/dynamiccertificates/configmap_cafile_content.go:206: Watch close - *v1.ConfigMap total 10 items received
2023-05-04T17:58:46.889226100Z I0504 17:58:46.889181       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.273876ms" userAgent="Prometheus/2.39.1" audit-ID="40d2ec4a-f680-47d8-96c3-27030b8e01d7" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:59:04.793735240Z I0504 17:59:04.793702       1 controller.go:447] The operator is healthy
2023-05-04T17:59:04.793823646Z I0504 17:59:04.793814       1 controller.go:325] No status update necessary, objects are identical
2023-05-04T17:59:07.588706494Z I0504 17:59:07.588665       1 reflector.go:559] k8s.io/apiserver/pkg/server/dynamiccertificates/configmap_cafile_content.go:206: Watch close - *v1.ConfigMap total 6 items received
2023-05-04T17:59:16.890706700Z I0504 17:59:16.889677       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.177416ms" userAgent="Prometheus/2.39.1" audit-ID="846dcac6-650d-4c1c-912e-1ec852264e21" srcIP="10.128.0.90:54562" resp=200
2023-05-04T17:59:46.890291828Z I0504 17:59:46.890252       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="3.139251ms" userAgent="Prometheus/2.39.1" audit-ID="3b54d940-bd0b-4f92-90ed-b515a1cd3167" srcIP="10.128.0.90:54562" resp=200
2023-05-04T18:00:16.890021453Z I0504 18:00:16.888860       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.250132ms" userAgent="Prometheus/2.39.1" audit-ID="54e9cb59-c540-40d0-a6d2-6c338788313d" srcIP="10.128.0.90:54562" resp=200
2023-05-04T18:00:46.888619475Z I0504 18:00:46.888581       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.027715ms" userAgent="Prometheus/2.39.1" audit-ID="00d9777c-5146-44cd-bf11-45e7a022c051" srcIP="10.128.0.90:54562" resp=200
2023-05-04T18:01:04.794551988Z I0504 18:01:04.794510       1 controller.go:447] The operator is healthy
2023-05-04T18:01:04.794644561Z I0504 18:01:04.794636       1 controller.go:325] No status update necessary, objects are identical
2023-05-04T18:01:16.889578539Z I0504 18:01:16.889525       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.431341ms" userAgent="Prometheus/2.39.1" audit-ID="2b400abb-3273-4ab4-b067-8136f88824a0" srcIP="10.128.0.90:54562" resp=200
2023-05-04T18:01:46.889633486Z I0504 18:01:46.889594       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.456129ms" userAgent="Prometheus/2.39.1" audit-ID="d2010d25-79ed-4488-b3bd-6a2f94e799db" srcIP="10.128.0.90:54562" resp=200
2023-05-04T18:02:16.888971467Z I0504 18:02:16.888925       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.213723ms" userAgent="Prometheus/2.39.1" audit-ID="4cda8580-be98-4edf-99e0-ce93fab6aba7" srcIP="10.128.0.90:54562" resp=200
2023-05-04T18:02:44.721652896Z I0504 18:02:44.721607       1 secretconfigobserver.go:136] Refreshing configuration from cluster pull secret
2023-05-04T18:02:44.723914359Z I0504 18:02:44.723885       1 secretconfigobserver.go:248] Found cloud.openshift.com token
2023-05-04T18:02:44.723914359Z I0504 18:02:44.723906       1 secretconfigobserver.go:162] Refreshing configuration from cluster secret
2023-05-04T18:02:44.725190063Z I0504 18:02:44.725166       1 secretconfigobserver.go:119] support secret does not exist
2023-05-04T18:02:46.889808140Z I0504 18:02:46.889335       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.338518ms" userAgent="Prometheus/2.39.1" audit-ID="4d77da45-2a03-4f6c-a7f2-05505f29c453" srcIP="10.128.0.90:54562" resp=200
2023-05-04T18:03:03.583126600Z I0504 18:03:03.583090       1 reflector.go:559] k8s.io/apiserver/pkg/authentication/request/headerrequest/requestheader_controller.go:172: Watch close - *v1.ConfigMap total 7 items received
2023-05-04T18:03:04.793859970Z I0504 18:03:04.793815       1 controller.go:447] The operator is healthy
2023-05-04T18:03:04.793896950Z I0504 18:03:04.793867       1 controller.go:325] No status update necessary, objects are identical
2023-05-04T18:03:16.889656105Z I0504 18:03:16.889606       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.33432ms" userAgent="Prometheus/2.39.1" audit-ID="feb24a77-40c6-43a1-8d12-bddbc5daa8f5" srcIP="10.128.0.90:54562" resp=200
2023-05-04T18:03:46.889357915Z I0504 18:03:46.888732       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.26546ms" userAgent="Prometheus/2.39.1" audit-ID="887e0670-a45e-4e58-bcfa-d5e4a1fae58b" srcIP="10.128.0.90:54562" resp=200
2023-05-04T18:04:15.588743496Z I0504 18:04:15.588699       1 reflector.go:559] k8s.io/apiserver/pkg/server/dynamiccertificates/configmap_cafile_content.go:206: Watch close - *v1.ConfigMap total 7 items received
2023-05-04T18:04:16.889406359Z I0504 18:04:16.889370       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.082808ms" userAgent="Prometheus/2.39.1" audit-ID="e08fa7e5-a62f-4b94-8116-5af92cdf9dde" srcIP="10.128.0.90:54562" resp=200
2023-05-04T18:04:46.888761846Z I0504 18:04:46.888722       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="1.870169ms" userAgent="Prometheus/2.39.1" audit-ID="910b9c0c-afdb-4109-a568-89601c94720c" srcIP="10.128.0.90:54562" resp=200
2023-05-04T18:05:04.796043814Z I0504 18:05:04.795551       1 controller.go:447] The operator is healthy
2023-05-04T18:05:04.796043814Z I0504 18:05:04.795617       1 controller.go:325] No status update necessary, objects are identical
2023-05-04T18:05:16.889867221Z I0504 18:05:16.889828       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.639052ms" userAgent="Prometheus/2.39.1" audit-ID="d974dbbd-a509-4b2c-a832-8dd431526b17" srcIP="10.128.0.90:54562" resp=200
2023-05-04T18:05:46.889868488Z I0504 18:05:46.889740       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.237658ms" userAgent="Prometheus/2.39.1" audit-ID="8d4f37db-1fd2-43ab-a47a-6527b6df6206" srcIP="10.128.0.90:54562" resp=200
2023-05-04T18:05:59.590526164Z I0504 18:05:59.590482       1 reflector.go:559] k8s.io/apiserver/pkg/server/dynamiccertificates/configmap_cafile_content.go:206: Watch close - *v1.ConfigMap total 8 items received
2023-05-04T18:06:16.889564432Z I0504 18:06:16.889523       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.322347ms" userAgent="Prometheus/2.39.1" audit-ID="537c0db5-75a0-4eba-98d2-6ee6d2aeae74" srcIP="10.128.0.90:54562" resp=200
2023-05-04T18:06:46.889533806Z I0504 18:06:46.889446       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.240704ms" userAgent="Prometheus/2.39.1" audit-ID="72f3ccd3-87ed-42e8-84bd-00525da27fdc" srcIP="10.128.0.90:54562" resp=200
2023-05-04T18:07:04.801549616Z I0504 18:07:04.801509       1 controller.go:447] The operator is healthy
2023-05-04T18:07:04.801658450Z I0504 18:07:04.801648       1 controller.go:325] No status update necessary, objects are identical
2023-05-04T18:07:16.901700948Z I0504 18:07:16.897801       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.63271ms" userAgent="Prometheus/2.39.1" audit-ID="152bed1a-27f2-47bb-af51-9a97b4f510a0" srcIP="10.128.0.90:54562" resp=200
2023-05-04T18:07:44.726049959Z I0504 18:07:44.726012       1 secretconfigobserver.go:136] Refreshing configuration from cluster pull secret
2023-05-04T18:07:44.728418643Z I0504 18:07:44.728390       1 secretconfigobserver.go:248] Found cloud.openshift.com token
2023-05-04T18:07:44.728418643Z I0504 18:07:44.728408       1 secretconfigobserver.go:162] Refreshing configuration from cluster secret
2023-05-04T18:07:44.729448726Z I0504 18:07:44.729430       1 secretconfigobserver.go:119] support secret does not exist
2023-05-04T18:07:46.899478112Z I0504 18:07:46.897941       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.256092ms" userAgent="Prometheus/2.39.1" audit-ID="7b815728-7e8c-4159-b15a-8dbcba2aa776" srcIP="10.128.0.90:54562" resp=200
2023-05-04T18:08:16.889651653Z I0504 18:08:16.889611       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.462451ms" userAgent="Prometheus/2.39.1" audit-ID="25ecd0a3-ccde-4a7d-b1ae-6dbccd111853" srcIP="10.128.0.90:54562" resp=200
2023-05-04T18:08:46.889715991Z I0504 18:08:46.889680       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.550445ms" userAgent="Prometheus/2.39.1" audit-ID="b3777109-2556-4b6d-9f64-ff7c3c06b842" srcIP="10.128.0.90:54562" resp=200
2023-05-04T18:09:04.793807020Z I0504 18:09:04.793772       1 controller.go:447] The operator is healthy
2023-05-04T18:09:04.793883163Z I0504 18:09:04.793875       1 controller.go:325] No status update necessary, objects are identical
2023-05-04T18:09:16.889704881Z I0504 18:09:16.889656       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.692992ms" userAgent="Prometheus/2.39.1" audit-ID="f74e934c-2d3d-47c4-99ee-d6c88508b459" srcIP="10.128.0.90:54562" resp=200
2023-05-04T18:09:46.890020532Z I0504 18:09:46.889188       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="1.861833ms" userAgent="Prometheus/2.39.1" audit-ID="acfac009-e96e-4054-9a35-031f7024d2b6" srcIP="10.128.0.90:54562" resp=200
2023-05-04T18:10:16.888720664Z I0504 18:10:16.888678       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="1.897139ms" userAgent="Prometheus/2.39.1" audit-ID="b46f7378-7f1f-48ac-801f-6f4dfd892323" srcIP="10.128.0.90:54562" resp=200
2023-05-04T18:10:46.889223077Z I0504 18:10:46.889184       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.082517ms" userAgent="Prometheus/2.39.1" audit-ID="fc253f90-888c-4e22-b09f-ba7bc12a4ca1" srcIP="10.128.0.90:54562" resp=200
2023-05-04T18:11:04.793727489Z I0504 18:11:04.793692       1 controller.go:447] The operator is healthy
2023-05-04T18:11:04.793801208Z I0504 18:11:04.793792       1 controller.go:325] No status update necessary, objects are identical
2023-05-04T18:11:16.889206795Z I0504 18:11:16.889172       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.149633ms" userAgent="Prometheus/2.39.1" audit-ID="ac65471c-bab5-469e-983b-82e5560b8502" srcIP="10.128.0.90:54562" resp=200
2023-05-04T18:11:39.595652939Z I0504 18:11:39.592937       1 reflector.go:559] k8s.io/apiserver/pkg/server/dynamiccertificates/configmap_cafile_content.go:206: Watch close - *v1.ConfigMap total 7 items received
2023-05-04T18:11:46.890188914Z I0504 18:11:46.890146       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="3.531746ms" userAgent="Prometheus/2.39.1" audit-ID="618eef85-5daa-4921-a168-2cb1fd6f5f33" srcIP="10.128.0.90:54562" resp=200
2023-05-04T18:12:16.892238631Z I0504 18:12:16.890714       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.849786ms" userAgent="Prometheus/2.39.1" audit-ID="82109bee-d2a6-4ab1-8209-114b5326bb0d" srcIP="10.128.0.90:54562" resp=200
2023-05-04T18:12:38.585357676Z I0504 18:12:38.585131       1 reflector.go:559] k8s.io/apiserver/pkg/authentication/request/headerrequest/requestheader_controller.go:172: Watch close - *v1.ConfigMap total 11 items received
2023-05-04T18:12:44.730522708Z I0504 18:12:44.730476       1 secretconfigobserver.go:136] Refreshing configuration from cluster pull secret
2023-05-04T18:12:44.732446678Z I0504 18:12:44.732412       1 secretconfigobserver.go:248] Found cloud.openshift.com token
2023-05-04T18:12:44.732446678Z I0504 18:12:44.732431       1 secretconfigobserver.go:162] Refreshing configuration from cluster secret
2023-05-04T18:12:44.733663521Z I0504 18:12:44.733636       1 secretconfigobserver.go:119] support secret does not exist
2023-05-04T18:12:46.889860414Z I0504 18:12:46.889827       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.255973ms" userAgent="Prometheus/2.39.1" audit-ID="a76ba608-49cb-4d3d-b7ce-f01355b95432" srcIP="10.128.0.90:54562" resp=200
2023-05-04T18:13:04.799995050Z I0504 18:13:04.797737       1 controller.go:447] The operator is healthy
2023-05-04T18:13:04.799995050Z I0504 18:13:04.797777       1 controller.go:325] No status update necessary, objects are identical
2023-05-04T18:13:08.591207288Z I0504 18:13:08.591160       1 reflector.go:559] k8s.io/apiserver/pkg/server/dynamiccertificates/configmap_cafile_content.go:206: Watch close - *v1.ConfigMap total 10 items received
2023-05-04T18:13:16.890896326Z I0504 18:13:16.890849       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="3.215964ms" userAgent="Prometheus/2.39.1" audit-ID="4e277fb0-ad7f-42eb-8ff9-a593fe918c2f" srcIP="10.128.0.90:54562" resp=200
2023-05-04T18:13:46.890100412Z I0504 18:13:46.889423       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.092025ms" userAgent="Prometheus/2.39.1" audit-ID="4d088839-b3df-405b-bb98-d061dacdf9b5" srcIP="10.128.0.90:54562" resp=200
2023-05-04T18:14:16.889985736Z I0504 18:14:16.889933       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.436631ms" userAgent="Prometheus/2.39.1" audit-ID="d947bd66-6984-43b1-abf0-b25f07ad4ed9" srcIP="10.128.0.90:54562" resp=200
2023-05-04T18:14:46.889150465Z I0504 18:14:46.889112       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.009931ms" userAgent="Prometheus/2.39.1" audit-ID="051a3b7c-bf71-4d0d-b947-234c46f156f1" srcIP="10.128.0.90:54562" resp=200
2023-05-04T18:15:04.793354443Z I0504 18:15:04.793298       1 controller.go:447] The operator is healthy
2023-05-04T18:15:04.793354443Z I0504 18:15:04.793344       1 controller.go:325] No status update necessary, objects are identical
2023-05-04T18:15:16.890206163Z I0504 18:15:16.889834       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.357854ms" userAgent="Prometheus/2.39.1" audit-ID="9a545b69-8f5b-4908-adda-044c47aa0c4f" srcIP="10.128.0.90:54562" resp=200
2023-05-04T18:15:46.889428489Z I0504 18:15:46.889395       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.489602ms" userAgent="Prometheus/2.39.1" audit-ID="1bfd0af2-c4f8-465c-94aa-209c59d33cc0" srcIP="10.128.0.90:54562" resp=200
2023-05-04T18:16:16.889574890Z I0504 18:16:16.888872       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.133183ms" userAgent="Prometheus/2.39.1" audit-ID="40269a64-ccaf-4cec-a9db-e7b75948dbd2" srcIP="10.128.0.90:54562" resp=200
2023-05-04T18:16:46.889111276Z I0504 18:16:46.889075       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.370698ms" userAgent="Prometheus/2.39.1" audit-ID="96647658-a384-4f54-ac92-6369ee756936" srcIP="10.128.0.90:54562" resp=200
2023-05-04T18:17:04.793994099Z I0504 18:17:04.793945       1 controller.go:447] The operator is healthy
2023-05-04T18:17:04.794070623Z I0504 18:17:04.794062       1 controller.go:325] No status update necessary, objects are identical
2023-05-04T18:17:16.890248055Z I0504 18:17:16.889227       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="1.988581ms" userAgent="Prometheus/2.39.1" audit-ID="82de24e4-e0f1-4f15-9813-77536ffe4da0" srcIP="10.128.0.90:54562" resp=200
2023-05-04T18:17:39.596567782Z I0504 18:17:39.596526       1 reflector.go:559] k8s.io/apiserver/pkg/server/dynamiccertificates/configmap_cafile_content.go:206: Watch close - *v1.ConfigMap total 7 items received
2023-05-04T18:17:44.734536278Z I0504 18:17:44.734500       1 secretconfigobserver.go:136] Refreshing configuration from cluster pull secret
2023-05-04T18:17:44.736524719Z I0504 18:17:44.736493       1 secretconfigobserver.go:248] Found cloud.openshift.com token
2023-05-04T18:17:44.736572188Z I0504 18:17:44.736564       1 secretconfigobserver.go:162] Refreshing configuration from cluster secret
2023-05-04T18:17:44.738926525Z I0504 18:17:44.738883       1 secretconfigobserver.go:119] support secret does not exist
2023-05-04T18:17:46.889024025Z I0504 18:17:46.888947       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.052922ms" userAgent="Prometheus/2.39.1" audit-ID="dea2b869-1b41-490b-b372-f5c4b1d8d6a3" srcIP="10.128.0.90:54562" resp=200
2023-05-04T18:18:16.889386889Z I0504 18:18:16.889340       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.191541ms" userAgent="Prometheus/2.39.1" audit-ID="9d4a19b5-818c-4eb3-aa98-d7711f368341" srcIP="10.128.0.90:54562" resp=200
2023-05-04T18:18:46.889388581Z I0504 18:18:46.889089       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.09477ms" userAgent="Prometheus/2.39.1" audit-ID="1e19bd08-1124-4573-8c42-59e4be151708" srcIP="10.128.0.90:54562" resp=200
2023-05-04T18:19:04.793286044Z I0504 18:19:04.793241       1 controller.go:447] The operator is healthy
2023-05-04T18:19:04.793323785Z I0504 18:19:04.793284       1 controller.go:325] No status update necessary, objects are identical
2023-05-04T18:19:16.889597628Z I0504 18:19:16.889461       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.242588ms" userAgent="Prometheus/2.39.1" audit-ID="f02a0472-cd34-4bb5-8dd1-779b12c570e5" srcIP="10.128.0.90:54562" resp=200
2023-05-04T18:19:46.889078387Z I0504 18:19:46.889042       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="1.911316ms" userAgent="Prometheus/2.39.1" audit-ID="bfb2a821-07f7-4fa2-a355-1464add81d99" srcIP="10.128.0.90:54562" resp=200
2023-05-04T18:20:14.592423134Z I0504 18:20:14.592374       1 reflector.go:559] k8s.io/apiserver/pkg/server/dynamiccertificates/configmap_cafile_content.go:206: Watch close - *v1.ConfigMap total 9 items received
2023-05-04T18:20:16.889748010Z I0504 18:20:16.889711       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.202162ms" userAgent="Prometheus/2.39.1" audit-ID="343c568e-dcdf-4c2a-a4ad-95f771e1fdf8" srcIP="10.128.0.90:54562" resp=200
2023-05-04T18:20:46.889859805Z I0504 18:20:46.888772       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.063682ms" userAgent="Prometheus/2.39.1" audit-ID="ede1b730-b45a-4801-9ec4-21c7a1316eff" srcIP="10.128.0.90:54562" resp=200
2023-05-04T18:20:52.586949023Z I0504 18:20:52.586912       1 reflector.go:559] k8s.io/apiserver/pkg/authentication/request/headerrequest/requestheader_controller.go:172: Watch close - *v1.ConfigMap total 10 items received
2023-05-04T18:21:04.793883289Z I0504 18:21:04.793839       1 controller.go:447] The operator is healthy
2023-05-04T18:21:04.793926590Z I0504 18:21:04.793881       1 controller.go:325] No status update necessary, objects are identical
2023-05-04T18:21:16.890046061Z I0504 18:21:16.889593       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.58525ms" userAgent="Prometheus/2.39.1" audit-ID="d63c74c9-7410-49ad-a364-7f909cb44e60" srcIP="10.128.0.90:54562" resp=200
2023-05-04T18:21:46.889449776Z I0504 18:21:46.889403       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.385265ms" userAgent="Prometheus/2.39.1" audit-ID="4a42fd1b-f614-444f-bd02-b49255b0f99b" srcIP="10.128.0.90:54562" resp=200
2023-05-04T18:22:16.888887786Z I0504 18:22:16.888847       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="1.986056ms" userAgent="Prometheus/2.39.1" audit-ID="40002d8e-84e4-4264-9e46-0e7ffcd9c708" srcIP="10.128.0.90:54562" resp=200
2023-05-04T18:22:44.741045946Z I0504 18:22:44.739762       1 secretconfigobserver.go:136] Refreshing configuration from cluster pull secret
2023-05-04T18:22:44.742527555Z I0504 18:22:44.742485       1 secretconfigobserver.go:248] Found cloud.openshift.com token
2023-05-04T18:22:44.742527555Z I0504 18:22:44.742507       1 secretconfigobserver.go:162] Refreshing configuration from cluster secret
2023-05-04T18:22:44.743937581Z I0504 18:22:44.743904       1 secretconfigobserver.go:119] support secret does not exist
2023-05-04T18:22:46.888695437Z I0504 18:22:46.888660       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="1.892009ms" userAgent="Prometheus/2.39.1" audit-ID="92d9dd61-ebfc-476c-ad49-6fda25dd8ae0" srcIP="10.128.0.90:54562" resp=200
2023-05-04T18:23:04.793655184Z I0504 18:23:04.793615       1 controller.go:447] The operator is healthy
2023-05-04T18:23:04.793697433Z I0504 18:23:04.793658       1 controller.go:325] No status update necessary, objects are identical
2023-05-04T18:23:16.890012611Z I0504 18:23:16.889510       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.342375ms" userAgent="Prometheus/2.39.1" audit-ID="20e6c64d-841a-4392-96ff-78766de3cf05" srcIP="10.128.0.90:54562" resp=200
2023-05-04T18:23:46.889520921Z I0504 18:23:46.889480       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.146687ms" userAgent="Prometheus/2.39.1" audit-ID="dceeb84c-a52c-444f-8b51-497dbdfe6dea" srcIP="10.128.0.90:54562" resp=200
2023-05-04T18:24:16.889135833Z I0504 18:24:16.889091       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.215006ms" userAgent="Prometheus/2.39.1" audit-ID="7567b6f7-ad06-4228-a0a8-7b4a7e02d322" srcIP="10.128.0.90:54562" resp=200
2023-05-04T18:24:20.599362636Z I0504 18:24:20.599321       1 reflector.go:559] k8s.io/apiserver/pkg/server/dynamiccertificates/configmap_cafile_content.go:206: Watch close - *v1.ConfigMap total 8 items received
2023-05-04T18:24:46.889752080Z I0504 18:24:46.889708       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.455618ms" userAgent="Prometheus/2.39.1" audit-ID="02d4b464-7422-4cf9-88fb-b8408c166404" srcIP="10.128.0.90:54562" resp=200
2023-05-04T18:25:04.799212471Z I0504 18:25:04.797164       1 controller.go:447] The operator is healthy
2023-05-04T18:25:04.799212471Z I0504 18:25:04.797208       1 controller.go:325] No status update necessary, objects are identical
2023-05-04T18:25:14.596299280Z I0504 18:25:14.596079       1 reflector.go:559] k8s.io/apiserver/pkg/server/dynamiccertificates/configmap_cafile_content.go:206: Watch close - *v1.ConfigMap total 5 items received
2023-05-04T18:25:16.890653173Z I0504 18:25:16.890070       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.177806ms" userAgent="Prometheus/2.39.1" audit-ID="64a736da-1d65-4f1d-9cb8-08821b6a54bc" srcIP="10.128.0.90:54562" resp=200
2023-05-04T18:25:46.888931144Z I0504 18:25:46.888884       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.036341ms" userAgent="Prometheus/2.39.1" audit-ID="0be84193-369b-4ba0-ae87-79f9eede3b3f" srcIP="10.128.0.90:54562" resp=200
2023-05-04T18:26:16.889765872Z I0504 18:26:16.889530       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.050347ms" userAgent="Prometheus/2.39.1" audit-ID="f02e0410-c6e3-4f78-9f2a-2e8114e7811a" srcIP="10.128.0.90:54562" resp=200
2023-05-04T18:26:46.890959000Z I0504 18:26:46.890924       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="3.503202ms" userAgent="Prometheus/2.39.1" audit-ID="e969d43b-2942-4873-9fac-4619affe23ad" srcIP="10.128.0.90:54562" resp=200
2023-05-04T18:27:04.794044840Z I0504 18:27:04.793929       1 controller.go:447] The operator is healthy
2023-05-04T18:27:04.794085687Z I0504 18:27:04.794071       1 controller.go:325] No status update necessary, objects are identical
2023-05-04T18:27:16.888661352Z I0504 18:27:16.888615       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.002016ms" userAgent="Prometheus/2.39.1" audit-ID="5b1f8d54-4760-4224-8343-5bc923d00337" srcIP="10.128.0.90:54562" resp=200
2023-05-04T18:27:44.745003529Z I0504 18:27:44.744946       1 secretconfigobserver.go:136] Refreshing configuration from cluster pull secret
2023-05-04T18:27:44.747366723Z I0504 18:27:44.747334       1 secretconfigobserver.go:248] Found cloud.openshift.com token
2023-05-04T18:27:44.747415966Z I0504 18:27:44.747407       1 secretconfigobserver.go:162] Refreshing configuration from cluster secret
2023-05-04T18:27:44.748750459Z I0504 18:27:44.748722       1 secretconfigobserver.go:119] support secret does not exist
2023-05-04T18:27:46.889279743Z I0504 18:27:46.889236       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.088539ms" userAgent="Prometheus/2.39.1" audit-ID="450d9c3a-6e7b-4804-8a9e-25c5cdd883e5" srcIP="10.128.0.90:54562" resp=200
2023-05-04T18:28:16.898265021Z I0504 18:28:16.895143       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="3.269555ms" userAgent="Prometheus/2.39.1" audit-ID="9ed01983-ea1a-4445-9500-adc1647871a8" srcIP="10.128.0.90:54562" resp=200
2023-05-04T18:28:46.890064807Z I0504 18:28:46.889015       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.176293ms" userAgent="Prometheus/2.39.1" audit-ID="39cef42c-4042-4d21-8b9a-4780cae5d78a" srcIP="10.128.0.90:54562" resp=200
2023-05-04T18:29:04.794180329Z I0504 18:29:04.794134       1 controller.go:447] The operator is healthy
2023-05-04T18:29:04.794212420Z I0504 18:29:04.794186       1 controller.go:325] No status update necessary, objects are identical
2023-05-04T18:29:16.891075696Z I0504 18:29:16.890980       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.228581ms" userAgent="Prometheus/2.39.1" audit-ID="ae6ca90d-26ee-4feb-8fa4-42a3059de824" srcIP="10.128.0.90:54562" resp=200
2023-05-04T18:29:46.889238171Z I0504 18:29:46.888226       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="1.903982ms" userAgent="Prometheus/2.39.1" audit-ID="ca15178d-6389-44e9-bd10-cca089fb11f2" srcIP="10.128.0.90:54562" resp=200
2023-05-04T18:30:16.890039246Z I0504 18:30:16.889968       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.077768ms" userAgent="Prometheus/2.39.1" audit-ID="ffa03900-3092-45e3-88fb-a25aecb9e9a7" srcIP="10.128.0.90:54562" resp=200
2023-05-04T18:30:33.588857071Z I0504 18:30:33.588805       1 reflector.go:559] k8s.io/apiserver/pkg/authentication/request/headerrequest/requestheader_controller.go:172: Watch close - *v1.ConfigMap total 11 items received
2023-05-04T18:30:46.890432293Z I0504 18:30:46.890394       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.352564ms" userAgent="Prometheus/2.39.1" audit-ID="a688c4a2-22d4-4ecf-8c2e-e9c81f79b81a" srcIP="10.128.0.90:54562" resp=200
2023-05-04T18:31:04.796696566Z I0504 18:31:04.796651       1 controller.go:447] The operator is healthy
2023-05-04T18:31:04.796731892Z I0504 18:31:04.796694       1 controller.go:325] No status update necessary, objects are identical
2023-05-04T18:31:16.889069207Z I0504 18:31:16.889026       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.311347ms" userAgent="Prometheus/2.39.1" audit-ID="20bf1d0e-823e-4678-80ed-017a0cbfe812" srcIP="10.128.0.90:54562" resp=200
2023-05-04T18:31:46.889105487Z I0504 18:31:46.889058       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.319081ms" userAgent="Prometheus/2.39.1" audit-ID="a927c86e-1550-46ec-b1a6-6dbc77b10698" srcIP="10.128.0.90:54562" resp=200
2023-05-04T18:31:47.597781028Z I0504 18:31:47.597736       1 reflector.go:559] k8s.io/apiserver/pkg/server/dynamiccertificates/configmap_cafile_content.go:206: Watch close - *v1.ConfigMap total 8 items received
2023-05-04T18:32:10.601537472Z I0504 18:32:10.601491       1 reflector.go:559] k8s.io/apiserver/pkg/server/dynamiccertificates/configmap_cafile_content.go:206: Watch close - *v1.ConfigMap total 8 items received
2023-05-04T18:32:16.890796722Z I0504 18:32:16.889790       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.11606ms" userAgent="Prometheus/2.39.1" audit-ID="d0ecd52b-0024-427b-b793-888fe83c2152" srcIP="10.128.0.90:54562" resp=200
2023-05-04T18:32:44.749664800Z I0504 18:32:44.749625       1 secretconfigobserver.go:136] Refreshing configuration from cluster pull secret
2023-05-04T18:32:44.752028595Z I0504 18:32:44.751993       1 secretconfigobserver.go:248] Found cloud.openshift.com token
2023-05-04T18:32:44.752076575Z I0504 18:32:44.752068       1 secretconfigobserver.go:162] Refreshing configuration from cluster secret
2023-05-04T18:32:44.753360193Z I0504 18:32:44.753328       1 secretconfigobserver.go:119] support secret does not exist
2023-05-04T18:32:46.889422667Z I0504 18:32:46.889387       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.700787ms" userAgent="Prometheus/2.39.1" audit-ID="2309026b-052e-4de0-b872-051e1b30c133" srcIP="10.128.0.90:54562" resp=200
2023-05-04T18:33:04.793626796Z I0504 18:33:04.793587       1 controller.go:447] The operator is healthy
2023-05-04T18:33:04.793673002Z I0504 18:33:04.793629       1 controller.go:325] No status update necessary, objects are identical
2023-05-04T18:33:16.889492179Z I0504 18:33:16.889452       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="1.957753ms" userAgent="Prometheus/2.39.1" audit-ID="4cee0425-97d0-48d1-ad75-bd57bee1606e" srcIP="10.128.0.90:54562" resp=200
2023-05-04T18:33:25.312047913Z I0504 18:33:25.310975       1 periodic.go:150] Running clusterconfig gatherer
2023-05-04T18:33:25.312047913Z I0504 18:33:25.311103       1 tasks_processing.go:45] number of workers: 16
2023-05-04T18:33:25.312047913Z I0504 18:33:25.311123       1 tasks_processing.go:69] worker 15 listening for tasks.
2023-05-04T18:33:25.312047913Z I0504 18:33:25.311126       1 tasks_processing.go:71] worker 15 working on feature_gates task.
2023-05-04T18:33:25.313996729Z I0504 18:33:25.312709       1 tasks_processing.go:69] worker 0 listening for tasks.
2023-05-04T18:33:25.313996729Z I0504 18:33:25.312721       1 tasks_processing.go:69] worker 1 listening for tasks.
2023-05-04T18:33:25.313996729Z I0504 18:33:25.312725       1 tasks_processing.go:69] worker 2 listening for tasks.
2023-05-04T18:33:25.313996729Z I0504 18:33:25.312730       1 tasks_processing.go:69] worker 3 listening for tasks.
2023-05-04T18:33:25.313996729Z I0504 18:33:25.312734       1 tasks_processing.go:69] worker 4 listening for tasks.
2023-05-04T18:33:25.313996729Z I0504 18:33:25.312738       1 tasks_processing.go:69] worker 5 listening for tasks.
2023-05-04T18:33:25.313996729Z I0504 18:33:25.312741       1 tasks_processing.go:69] worker 6 listening for tasks.
2023-05-04T18:33:25.313996729Z I0504 18:33:25.312744       1 tasks_processing.go:69] worker 7 listening for tasks.
2023-05-04T18:33:25.313996729Z I0504 18:33:25.312748       1 tasks_processing.go:69] worker 8 listening for tasks.
2023-05-04T18:33:25.313996729Z I0504 18:33:25.312754       1 tasks_processing.go:69] worker 9 listening for tasks.
2023-05-04T18:33:25.313996729Z I0504 18:33:25.312757       1 tasks_processing.go:69] worker 10 listening for tasks.
2023-05-04T18:33:25.313996729Z I0504 18:33:25.312761       1 tasks_processing.go:69] worker 11 listening for tasks.
2023-05-04T18:33:25.313996729Z I0504 18:33:25.312764       1 tasks_processing.go:69] worker 12 listening for tasks.
2023-05-04T18:33:25.313996729Z I0504 18:33:25.312767       1 tasks_processing.go:69] worker 13 listening for tasks.
2023-05-04T18:33:25.313996729Z I0504 18:33:25.312770       1 tasks_processing.go:69] worker 14 listening for tasks.
2023-05-04T18:33:25.313996729Z I0504 18:33:25.312775       1 tasks_processing.go:71] worker 14 working on operators task.
2023-05-04T18:33:25.313996729Z I0504 18:33:25.313088       1 tasks_processing.go:71] worker 0 working on mutating_webhook_configurations task.
2023-05-04T18:33:25.316012531Z I0504 18:33:25.314997       1 tasks_processing.go:71] worker 15 working on openshift_sdn_controller_logs task.
2023-05-04T18:33:25.316012531Z I0504 18:33:25.315525       1 recorder.go:70] Recording config/featuregate with fingerprint=e270958e75df290e33fd14e3a1f26ab3af7f7e06c8c4662c03d569da78e0de3a
2023-05-04T18:33:25.316012531Z I0504 18:33:25.315566       1 gather.go:180] gatherer "clusterconfig" function "feature_gates" took 3.860944ms to process 1 records
2023-05-04T18:33:25.316012531Z I0504 18:33:25.315586       1 tasks_processing.go:71] worker 7 working on storage_cluster task.
2023-05-04T18:33:25.316012531Z I0504 18:33:25.315755       1 tasks_processing.go:71] worker 1 working on machine_healthchecks task.
2023-05-04T18:33:25.316012531Z I0504 18:33:25.315862       1 tasks_processing.go:71] worker 2 working on nodes task.
2023-05-04T18:33:25.317990281Z I0504 18:33:25.316077       1 tasks_processing.go:71] worker 3 working on sap_pods task.
2023-05-04T18:33:25.317990281Z I0504 18:33:25.316319       1 tasks_processing.go:71] worker 4 working on authentication task.
2023-05-04T18:33:25.317990281Z I0504 18:33:25.316439       1 tasks_processing.go:71] worker 5 working on openshift_machine_api_events task.
2023-05-04T18:33:25.317990281Z I0504 18:33:25.316634       1 tasks_processing.go:71] worker 6 working on operators_pods_and_events task.
2023-05-04T18:33:25.317990281Z I0504 18:33:25.316864       1 tasks_processing.go:71] worker 10 working on pod_network_connectivity_checks task.
2023-05-04T18:33:25.317990281Z I0504 18:33:25.316999       1 tasks_processing.go:71] worker 8 working on silenced_alerts task.
2023-05-04T18:33:25.317990281Z I0504 18:33:25.317334       1 tasks_processing.go:71] worker 9 working on proxies task.
2023-05-04T18:33:25.317990281Z I0504 18:33:25.317608       1 tasks_processing.go:71] worker 12 working on infrastructures task.
2023-05-04T18:33:25.317990281Z I0504 18:33:25.317621       1 tasks_processing.go:71] worker 13 working on machine_configs task.
2023-05-04T18:33:25.317990281Z I0504 18:33:25.317725       1 tasks_processing.go:71] worker 11 working on overlapping_namespace_uids task.
2023-05-04T18:33:25.328077657Z I0504 18:33:25.324813       1 tasks_processing.go:71] worker 3 working on dvo_metrics task.
2023-05-04T18:33:25.328077657Z I0504 18:33:25.324906       1 gather.go:180] gatherer "clusterconfig" function "sap_pods" took 8.719329ms to process 0 records
2023-05-04T18:33:25.328077657Z I0504 18:33:25.327853       1 tasks_processing.go:71] worker 7 working on jaegers task.
2023-05-04T18:33:25.328180230Z I0504 18:33:25.328142       1 gather.go:180] gatherer "clusterconfig" function "storage_cluster" took 12.242619ms to process 0 records
2023-05-04T18:33:25.330016204Z I0504 18:33:25.328206       1 recorder.go:70] Recording config/machinehealthchecks/openshift-machine-api/machine-api-termination-handler with fingerprint=fa9d2812bc01b43f8bac647c12a6a4ef945698219c71eee0836ad01b2fb92aa6
2023-05-04T18:33:25.330016204Z I0504 18:33:25.328235       1 gather.go:180] gatherer "clusterconfig" function "machine_healthchecks" took 12.372784ms to process 1 records
2023-05-04T18:33:25.330016204Z I0504 18:33:25.328243       1 gather.go:180] gatherer "clusterconfig" function "mutating_webhook_configurations" took 15.065025ms to process 0 records
2023-05-04T18:33:25.330016204Z I0504 18:33:25.328249       1 tasks_processing.go:71] worker 0 working on openshift_sdn_logs task.
2023-05-04T18:33:25.330016204Z I0504 18:33:25.328584       1 tasks_processing.go:71] worker 1 working on machine_autoscalers task.
2023-05-04T18:33:25.346791557Z I0504 18:33:25.344573       1 tasks_processing.go:71] worker 7 working on netnamespaces task.
2023-05-04T18:33:25.346791557Z I0504 18:33:25.344910       1 gather_logs.go:132] no pods in openshift-sdn namespace were found
2023-05-04T18:33:25.346791557Z I0504 18:33:25.344921       1 gather.go:180] gatherer "clusterconfig" function "jaegers" took 16.69934ms to process 0 records
2023-05-04T18:33:25.346791557Z I0504 18:33:25.344927       1 gather.go:180] gatherer "clusterconfig" function "machine_autoscalers" took 16.307515ms to process 0 records
2023-05-04T18:33:25.346791557Z I0504 18:33:25.344931       1 gather.go:180] gatherer "clusterconfig" function "openshift_sdn_logs" took 16.664345ms to process 0 records
2023-05-04T18:33:25.346791557Z I0504 18:33:25.344936       1 tasks_processing.go:71] worker 0 working on ceph_cluster task.
2023-05-04T18:33:25.346791557Z I0504 18:33:25.345075       1 tasks_processing.go:71] worker 1 working on scheduler_logs task.
2023-05-04T18:33:25.346791557Z I0504 18:33:25.345482       1 tasks_processing.go:71] worker 8 working on node_logs task.
2023-05-04T18:33:25.346791557Z I0504 18:33:25.346030       1 gather_logs.go:132] no pods in openshift-sdn namespace were found
2023-05-04T18:33:25.346791557Z I0504 18:33:25.346058       1 recorder.go:70] Recording config/silenced_alerts.json with fingerprint=37517e5f3dc66819f61f5a7bb8ace1921282415f10551d2defa5c3eb0985b570
2023-05-04T18:33:25.346791557Z I0504 18:33:25.346066       1 gather.go:180] gatherer "clusterconfig" function "silenced_alerts" took 28.475164ms to process 1 records
2023-05-04T18:33:25.346791557Z I0504 18:33:25.346084       1 recorder.go:70] Recording config/namespaces_with_overlapping_uids with fingerprint=4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945
2023-05-04T18:33:25.346791557Z I0504 18:33:25.346090       1 gather.go:180] gatherer "clusterconfig" function "overlapping_namespace_uids" took 27.989923ms to process 1 records
2023-05-04T18:33:25.346791557Z I0504 18:33:25.346107       1 recorder.go:70] Recording config/proxy with fingerprint=1d43dfe530a46e7e4a398048c020301f58d72ef0d0e0f7a1ade4951756d2876a
2023-05-04T18:33:25.346791557Z I0504 18:33:25.346112       1 gather.go:180] gatherer "clusterconfig" function "proxies" took 28.500892ms to process 1 records
2023-05-04T18:33:25.346791557Z I0504 18:33:25.346129       1 recorder.go:70] Recording config/authentication with fingerprint=1345cd1911d860bbed605f3d6c2205288d79a10cc93e892beed48c40a61fc59d
2023-05-04T18:33:25.346791557Z I0504 18:33:25.346133       1 gather.go:180] gatherer "clusterconfig" function "authentication" took 29.531206ms to process 1 records
2023-05-04T18:33:25.346791557Z I0504 18:33:25.346137       1 gather.go:180] gatherer "clusterconfig" function "openshift_machine_api_events" took 29.561893ms to process 0 records
2023-05-04T18:33:25.346791557Z I0504 18:33:25.346141       1 gather.go:180] gatherer "clusterconfig" function "openshift_sdn_controller_logs" took 31.02632ms to process 0 records
2023-05-04T18:33:25.346791557Z I0504 18:33:25.346146       1 tasks_processing.go:71] worker 15 working on version task.
2023-05-04T18:33:25.346791557Z I0504 18:33:25.346470       1 tasks_processing.go:71] worker 5 working on sap_datahubs task.
2023-05-04T18:33:25.346791557Z I0504 18:33:25.346583       1 tasks_processing.go:71] worker 11 working on config_maps task.
2023-05-04T18:33:25.346844988Z I0504 18:33:25.346816       1 tasks_processing.go:71] worker 9 working on openshift_logging task.
2023-05-04T18:33:25.355067735Z I0504 18:33:25.353633       1 tasks_processing.go:71] worker 12 working on machine_config_pools task.
2023-05-04T18:33:25.357036178Z I0504 18:33:25.356584       1 recorder.go:70] Recording config/infrastructure with fingerprint=2d9683e273fbbc5188e978b3d62ea82188cb5acdef1d98809b1424c27b0ec63d
2023-05-04T18:33:25.357036178Z I0504 18:33:25.356610       1 gather.go:180] gatherer "clusterconfig" function "infrastructures" took 36.010992ms to process 1 records
2023-05-04T18:33:25.357036178Z I0504 18:33:25.356790       1 tasks_processing.go:71] worker 4 working on olm_operators task.
2023-05-04T18:33:25.358999812Z I0504 18:33:25.357244       1 tasks_processing.go:71] worker 7 working on kube_controller_manager_logs task.
2023-05-04T18:33:25.358999812Z I0504 18:33:25.358187       1 gather.go:180] gatherer "clusterconfig" function "netnamespaces" took 12.65337ms to process 0 records
2023-05-04T18:33:25.358999812Z I0504 18:33:25.358200       1 gather.go:180] gatherer "clusterconfig" function "ceph_cluster" took 12.397269ms to process 0 records
2023-05-04T18:33:25.358999812Z I0504 18:33:25.358211       1 gather.go:180] gatherer "clusterconfig" function "sap_datahubs" took 10.864484ms to process 0 records
2023-05-04T18:33:25.358999812Z I0504 18:33:25.358263       1 recorder.go:70] Recording config/podnetworkconnectivitychecks with fingerprint=fbee18ce7ead763bc4677fda5bb8fdbb348e7fbc56a160a070d85ef1ee2434a0
2023-05-04T18:33:25.358999812Z I0504 18:33:25.358273       1 gather.go:180] gatherer "clusterconfig" function "pod_network_connectivity_checks" took 41.227259ms to process 1 records
2023-05-04T18:33:25.358999812Z I0504 18:33:25.358358       1 recorder.go:70] Recording config/machineconfigpools/master with fingerprint=52fbaf0bc3c102c47b04aed7fb81bed1682dfdb716f6871a08cc48da179c0439
2023-05-04T18:33:25.358999812Z I0504 18:33:25.358434       1 recorder.go:70] Recording config/machineconfigpools/worker with fingerprint=9a0d6452846784a245788e8f86b5889853af50693428a6ad7192280f0563d6b6
2023-05-04T18:33:25.358999812Z I0504 18:33:25.358439       1 gather.go:180] gatherer "clusterconfig" function "machine_config_pools" took 4.460739ms to process 2 records
2023-05-04T18:33:25.358999812Z I0504 18:33:25.358551       1 recorder.go:70] Recording config/node/node with fingerprint=e3b4c97f4fc2e98136db81838214d870b9eb7a7b15a31cb0bf6f0cc7ab44d9eb
2023-05-04T18:33:25.358999812Z I0504 18:33:25.358560       1 gather.go:180] gatherer "clusterconfig" function "nodes" took 42.276267ms to process 1 records
2023-05-04T18:33:25.358999812Z I0504 18:33:25.358565       1 gather.go:180] gatherer "clusterconfig" function "openshift_logging" took 11.356757ms to process 0 records
2023-05-04T18:33:25.362008006Z I0504 18:33:25.361590       1 tasks_processing.go:71] worker 2 working on install_plans task.
2023-05-04T18:33:25.362008006Z W0504 18:33:25.361627       1 dvo_metrics.go:95] No DVO metrics gathered
2023-05-04T18:33:25.362008006Z I0504 18:33:25.361634       1 tasks_processing.go:71] worker 3 working on machine_sets task.
2023-05-04T18:33:25.362008006Z I0504 18:33:25.361880       1 tasks_processing.go:71] worker 9 working on active_alerts task.
2023-05-04T18:33:25.364253579Z I0504 18:33:25.362098       1 tasks_processing.go:71] worker 0 working on sap_config task.
2023-05-04T18:33:25.364253579Z I0504 18:33:25.362670       1 gather.go:180] gatherer "clusterconfig" function "dvo_metrics" took 36.807587ms to process 0 records
2023-05-04T18:33:25.364253579Z I0504 18:33:25.362747       1 tasks_processing.go:71] worker 10 working on image_pruners task.
2023-05-04T18:33:25.364253579Z I0504 18:33:25.362913       1 tasks_processing.go:71] worker 5 working on cost_management_metrics_configs task.
2023-05-04T18:33:25.366027247Z I0504 18:33:25.365167       1 tasks_processing.go:71] worker 12 working on container_images task.
2023-05-04T18:33:25.368034583Z I0504 18:33:25.366304       1 tasks_processing.go:71] worker 9 working on openshift_authentication_logs task.
2023-05-04T18:33:25.368034583Z I0504 18:33:25.366748       1 recorder.go:70] Recording config/alerts with fingerprint=294a7cfd71922fa8e5b8c3cafb851eb61223ae76405f3bfcf9859d1320cd49f6
2023-05-04T18:33:25.368034583Z I0504 18:33:25.366760       1 gather.go:180] gatherer "clusterconfig" function "active_alerts" took 4.412299ms to process 1 records
2023-05-04T18:33:25.383350798Z I0504 18:33:25.382202       1 tasks_processing.go:71] worker 13 working on image_registries task.
2023-05-04T18:33:25.383350798Z I0504 18:33:25.382458       1 recorder.go:70] Recording config/machineconfigs/00-master with fingerprint=acabf1fda5cc6909ce4f35367196635f3fae4fcd36b0ae1756c2623531914a5d
2023-05-04T18:33:25.383350798Z I0504 18:33:25.382668       1 recorder.go:70] Recording config/machineconfigs/00-worker with fingerprint=fb109d938c194334c7b432abe0fb7aad3e5e99ee7bcf45eb222daf28c288c91e
2023-05-04T18:33:25.383350798Z I0504 18:33:25.382705       1 recorder.go:70] Recording config/machineconfigs/01-master-container-runtime with fingerprint=80dd4bc6d57e9dc37f6fc9dcc79607ca3b34e6564a35aa5843fe56f49871ac97
2023-05-04T18:33:25.383350798Z I0504 18:33:25.382753       1 recorder.go:70] Recording config/machineconfigs/01-master-kubelet with fingerprint=927d5399cd7a3b8b15246e5c9d151d6e7ef0782f1998f66b0f7e92c7b7c2d789
2023-05-04T18:33:25.383350798Z I0504 18:33:25.382782       1 recorder.go:70] Recording config/machineconfigs/01-worker-container-runtime with fingerprint=3196a78f9ec1060681045e7f570ead88bbae0d1b135d6e48e7438713cb07148c
2023-05-04T18:33:25.383350798Z I0504 18:33:25.382836       1 recorder.go:70] Recording config/machineconfigs/01-worker-kubelet with fingerprint=99688bbcb30624daef4c88311c1b39273db871dd22392a551d3e4b4e03da0a83
2023-05-04T18:33:25.383350798Z I0504 18:33:25.382863       1 recorder.go:70] Recording config/machineconfigs/99-master-generated-registries with fingerprint=a24dcc4dc28d25513e10398975d7fca40c6f3e754e6857aa8a1741b30db75cf9
2023-05-04T18:33:25.383350798Z I0504 18:33:25.382883       1 recorder.go:70] Recording config/machineconfigs/99-master-ssh with fingerprint=247ee91099b8c8149129568c17bc87bf9b3058154cd58c4b3f2683b61db93799
2023-05-04T18:33:25.383350798Z I0504 18:33:25.382907       1 recorder.go:70] Recording config/machineconfigs/99-worker-generated-registries with fingerprint=f18e8d08689a82855560665aa586466ea29eb4f8aa8b0210613df54be7214ed5
2023-05-04T18:33:25.383350798Z I0504 18:33:25.382926       1 recorder.go:70] Recording config/machineconfigs/99-worker-ssh with fingerprint=4c1c3a062d5b75efd7fd5da072666dc939b284abb1bb6a384418a2563cce774e
2023-05-04T18:33:25.383350798Z I0504 18:33:25.383249       1 recorder.go:70] Recording config/machineconfigs/rendered-master-fa45321130bb3e39d5868f5cd1a6f593 with fingerprint=30cad36815f12749651ca1acec67fa254e18b6ef2098073ef5b8f8187ad9c021
2023-05-04T18:33:25.385015201Z I0504 18:33:25.383423       1 recorder.go:70] Recording config/machineconfigs/rendered-worker-2535121dc3ab02d4fb8debe0352afadb with fingerprint=33a2d56260cac23cefed38aceb0409f8cc7735d7a98596c676f23a1e02b399e6
2023-05-04T18:33:25.385015201Z I0504 18:33:25.383465       1 gather.go:180] gatherer "clusterconfig" function "machine_configs" took 64.540639ms to process 12 records
2023-05-04T18:33:25.471602403Z I0504 18:33:25.471550       1 tasks_processing.go:71] worker 4 working on pdbs task.
2023-05-04T18:33:25.471637298Z I0504 18:33:25.471627       1 recorder.go:70] Recording config/olm_operators with fingerprint=4a2bcbf1182046db759d24205cd970969f34ea6f85d0de66e1207e12dd7198d9
2023-05-04T18:33:25.471664169Z I0504 18:33:25.471644       1 gather.go:180] gatherer "clusterconfig" function "olm_operators" took 114.724923ms to process 1 records
2023-05-04T18:33:25.481304676Z I0504 18:33:25.481263       1 tasks_processing.go:71] worker 5 working on openshift_apiserver_operator_logs task.
2023-05-04T18:33:25.482186410Z I0504 18:33:25.482154       1 gather.go:180] gatherer "clusterconfig" function "cost_management_metrics_configs" took 118.338503ms to process 0 records
2023-05-04T18:33:25.482218060Z I0504 18:33:25.482208       1 recorder.go:70] Recording config/clusteroperator/imageregistry.operator.openshift.io/imagepruner/cluster with fingerprint=db32db6f703fae36c0a256cef5351fd88c275597fbc57b2840c23a8145809329
2023-05-04T18:33:25.482226315Z I0504 18:33:25.482218       1 gather.go:180] gatherer "clusterconfig" function "image_pruners" took 119.326165ms to process 1 records
2023-05-04T18:33:25.482234931Z I0504 18:33:25.482229       1 tasks_processing.go:71] worker 10 working on certificate_signing_requests task.
2023-05-04T18:33:25.482988505Z I0504 18:33:25.482954       1 tasks_processing.go:71] worker 0 working on networks task.
2023-05-04T18:33:25.483194792Z I0504 18:33:25.483170       1 gather.go:180] gatherer "clusterconfig" function "sap_config" took 120.845826ms to process 0 records
2023-05-04T18:33:25.484270781Z I0504 18:33:25.484240       1 tasks_processing.go:71] worker 3 working on schedulers task.
2023-05-04T18:33:25.484452402Z I0504 18:33:25.484435       1 gather.go:180] gatherer "clusterconfig" function "machine_sets" took 122.59619ms to process 0 records
2023-05-04T18:33:25.484710436Z I0504 18:33:25.484694       1 tasks_processing.go:71] worker 13 working on tsdb_status task.
2023-05-04T18:33:25.485424816Z I0504 18:33:25.485390       1 recorder.go:70] Recording config/clusteroperator/imageregistry.operator.openshift.io/config/cluster with fingerprint=1fb5e4b2ffa0e7a8e4ecfa010c0df207ade019de8c35d8e475c51752fca65f47
2023-05-04T18:33:25.485424816Z I0504 18:33:25.485405       1 gather.go:180] gatherer "clusterconfig" function "image_registries" took 102.473878ms to process 1 records
2023-05-04T18:33:25.485761177Z I0504 18:33:25.485747       1 version.go:101] Found 1 unhealthy pods in openshift-cluster-version
2023-05-04T18:33:25.490507502Z I0504 18:33:25.490456       1 operators_pods_and_events.go:98] Found 0 pods with 0 containers
2023-05-04T18:33:25.490507502Z I0504 18:33:25.490479       1 tasks_processing.go:71] worker 6 working on container_runtime_configs task.
2023-05-04T18:33:25.490640101Z I0504 18:33:25.490624       1 gather.go:180] gatherer "clusterconfig" function "operators_pods_and_events" took 173.837198ms to process 0 records
2023-05-04T18:33:25.497047352Z I0504 18:33:25.497005       1 tasks_processing.go:71] worker 15 working on oauths task.
2023-05-04T18:33:25.497504520Z I0504 18:33:25.497486       1 recorder.go:70] Recording config/version with fingerprint=e2baaf6dc82cf1dd4a1ac933f9da062ef732f7234d318110da6b8b0e6fac4fc0
2023-05-04T18:33:25.497504520Z I0504 18:33:25.497500       1 recorder.go:70] Recording config/id with fingerprint=ce9fe64408ec18c0573ef9be03fd4a143bc29898e33d0347cf715e07a6155496
2023-05-04T18:33:25.497662125Z I0504 18:33:25.497645       1 recorder.go:70] Recording config/pod/openshift-cluster-version/cluster-version-operator-7544974f8f-tjk7v with fingerprint=db72b1d08fea3e6e9bc3c01dd698d013d1b5a5e815b6d6746a398f07beb0fe6a
2023-05-04T18:33:25.497681622Z I0504 18:33:25.497671       1 recorder.go:70] Recording events/openshift-cluster-version with fingerprint=a9fa827edf77584edb8373fa4ecb8fc7252ace45a94e90f3e425d0cf320d022d
2023-05-04T18:33:25.497687743Z I0504 18:33:25.497679       1 gather.go:180] gatherer "clusterconfig" function "version" took 150.848176ms to process 4 records
2023-05-04T18:33:25.497706398Z I0504 18:33:25.497696       1 recorder.go:70] Recording config/network with fingerprint=af2cda9e5ed3e939a5ffd44d5a75116a02a299b30e84fb30087ab60b6075519e
2023-05-04T18:33:25.497706398Z I0504 18:33:25.497702       1 gather.go:180] gatherer "clusterconfig" function "networks" took 14.297986ms to process 1 records
2023-05-04T18:33:25.497723230Z E0504 18:33:25.497710       1 gather.go:143] gatherer "clusterconfig" function "config_maps" failed with the error: configmaps "cluster-monitoring-config" not found
2023-05-04T18:33:25.497733088Z I0504 18:33:25.497728       1 recorder.go:70] Recording config/configmaps/openshift-config/admin-kubeconfig-client-ca/ca-bundle.crt with fingerprint=34cdf5d36d45a9e3ee7c2be31546e3d937ae4ebf144ac07b0210c06a1610a94d
2023-05-04T18:33:25.497739811Z I0504 18:33:25.497736       1 recorder.go:70] Recording config/configmaps/openshift-config/etcd-ca-bundle/ca-bundle.crt with fingerprint=34cdf5d36d45a9e3ee7c2be31546e3d937ae4ebf144ac07b0210c06a1610a94d
2023-05-04T18:33:25.497756843Z W0504 18:33:25.497745       1 gather.go:158] issue recording gatherer "clusterconfig" function "config_maps" result "config/configmaps/openshift-config/etcd-ca-bundle/ca-bundle.crt" because of the warning: warning: the record with the same fingerprint "34cdf5d36d45a9e3ee7c2be31546e3d937ae4ebf144ac07b0210c06a1610a94d" was already recorded at path "config/configmaps/openshift-config/admin-kubeconfig-client-ca/ca-bundle.crt", recording another one with a different path "config/configmaps/openshift-config/etcd-ca-bundle/ca-bundle.crt"
2023-05-04T18:33:25.497770959Z I0504 18:33:25.497757       1 recorder.go:70] Recording config/configmaps/openshift-config/etcd-metric-serving-ca/ca-bundle.crt with fingerprint=34cdf5d36d45a9e3ee7c2be31546e3d937ae4ebf144ac07b0210c06a1610a94d
2023-05-04T18:33:25.497770959Z W0504 18:33:25.497764       1 gather.go:158] issue recording gatherer "clusterconfig" function "config_maps" result "config/configmaps/openshift-config/etcd-metric-serving-ca/ca-bundle.crt" because of the warning: warning: the record with the same fingerprint "34cdf5d36d45a9e3ee7c2be31546e3d937ae4ebf144ac07b0210c06a1610a94d" was already recorded at path "config/configmaps/openshift-config/etcd-ca-bundle/ca-bundle.crt", recording another one with a different path "config/configmaps/openshift-config/etcd-metric-serving-ca/ca-bundle.crt"
2023-05-04T18:33:25.497776470Z I0504 18:33:25.497773       1 recorder.go:70] Recording config/configmaps/openshift-config/etcd-serving-ca/ca-bundle.crt with fingerprint=34cdf5d36d45a9e3ee7c2be31546e3d937ae4ebf144ac07b0210c06a1610a94d
2023-05-04T18:33:25.497782491Z W0504 18:33:25.497779       1 gather.go:158] issue recording gatherer "clusterconfig" function "config_maps" result "config/configmaps/openshift-config/etcd-serving-ca/ca-bundle.crt" because of the warning: warning: the record with the same fingerprint "34cdf5d36d45a9e3ee7c2be31546e3d937ae4ebf144ac07b0210c06a1610a94d" was already recorded at path "config/configmaps/openshift-config/etcd-metric-serving-ca/ca-bundle.crt", recording another one with a different path "config/configmaps/openshift-config/etcd-serving-ca/ca-bundle.crt"
2023-05-04T18:33:25.497809552Z I0504 18:33:25.497798       1 recorder.go:70] Recording config/configmaps/openshift-config/initial-kube-apiserver-server-ca/ca-bundle.crt with fingerprint=b115cabb75d3a5abd871b8626a1e9e91f4b87698e6f540c0d58abddc29c34240
2023-05-04T18:33:25.497833286Z I0504 18:33:25.497824       1 recorder.go:70] Recording config/configmaps/openshift-config/kube-root-ca.crt/ca.crt with fingerprint=8f83ef1ecfe5c8bf1cdc6211109047b8218a3e3824396ed4c00cdb684c75b209
2023-05-04T18:33:25.497833286Z I0504 18:33:25.497830       1 recorder.go:70] Recording config/configmaps/openshift-config/openshift-install-manifests/invoker with fingerprint=04f8996da763b7a969b1028ee3007569eaf3a635486ddab211d512c85b9df8fb
2023-05-04T18:33:25.497839308Z I0504 18:33:25.497834       1 recorder.go:70] Recording config/configmaps/openshift-config/openshift-install-manifests/version with fingerprint=678bc2ab673ae8f811ba4e95eb34d4a0d62dcd07a2f4ed0b69b94af3193ce00d
2023-05-04T18:33:25.497844066Z I0504 18:33:25.497840       1 recorder.go:70] Recording config/configmaps/openshift-config/openshift-service-ca.crt/service-ca.crt with fingerprint=34cdf5d36d45a9e3ee7c2be31546e3d937ae4ebf144ac07b0210c06a1610a94d
2023-05-04T18:33:25.497849947Z W0504 18:33:25.497846       1 gather.go:158] issue recording gatherer "clusterconfig" function "config_maps" result "config/configmaps/openshift-config/openshift-service-ca.crt/service-ca.crt" because of the warning: warning: the record with the same fingerprint "34cdf5d36d45a9e3ee7c2be31546e3d937ae4ebf144ac07b0210c06a1610a94d" was already recorded at path "config/configmaps/openshift-config/etcd-serving-ca/ca-bundle.crt", recording another one with a different path "config/configmaps/openshift-config/openshift-service-ca.crt/service-ca.crt"
2023-05-04T18:33:25.497881206Z I0504 18:33:25.497870       1 recorder.go:70] Recording config/configmaps/kube-system/cluster-config-v1 with fingerprint=083de95c5f401dfd87a0f16d6fb12ae369eccd8a54654fb98afe933578a6e6b3
2023-05-04T18:33:25.497881206Z I0504 18:33:25.497877       1 gather.go:180] gatherer "clusterconfig" function "config_maps" took 150.734593ms to process 10 records
2023-05-04T18:33:25.497890153Z I0504 18:33:25.497885       1 gather.go:180] gatherer "clusterconfig" function "certificate_signing_requests" took 15.112794ms to process 0 records
2023-05-04T18:33:25.497905983Z I0504 18:33:25.497896       1 recorder.go:70] Recording config/schedulers/cluster with fingerprint=24909f0181771d02e9d889c59ad4037a27c08c3752b621530cfebebf2e665887
2023-05-04T18:33:25.497905983Z I0504 18:33:25.497902       1 gather.go:180] gatherer "clusterconfig" function "schedulers" took 13.240151ms to process 1 records
2023-05-04T18:33:25.497927052Z I0504 18:33:25.497917       1 recorder.go:70] Recording config/pdbs/openshift-console/console with fingerprint=bd14cc0f4beef600bd3573c05ed5671360abd348459619c08bc43a1c1af2df63
2023-05-04T18:33:25.497933825Z I0504 18:33:25.497930       1 recorder.go:70] Recording config/pdbs/openshift-console/downloads with fingerprint=eac0da871e5972c67234265fc3c36b220a0aa8267b56d218385923c9dabc283f
2023-05-04T18:33:25.497952941Z I0504 18:33:25.497943       1 recorder.go:70] Recording config/pdbs/openshift-operator-lifecycle-manager/packageserver-pdb with fingerprint=b6f54008e604e3894bd37ab71d1fe6c33f36e60f3fa9331848563287e78e5799
2023-05-04T18:33:25.497952941Z I0504 18:33:25.497949       1 gather.go:180] gatherer "clusterconfig" function "pdbs" took 26.091162ms to process 3 records
2023-05-04T18:33:25.498019586Z I0504 18:33:25.497955       1 tasks_processing.go:71] worker 4 working on support_secret task.
2023-05-04T18:33:25.498032540Z I0504 18:33:25.497960       1 tasks_processing.go:71] worker 4 working on validating_webhook_configurations task.
2023-05-04T18:33:25.498101730Z I0504 18:33:25.498086       1 gather.go:180] gatherer "clusterconfig" function "support_secret" took 692ns to process 0 records
2023-05-04T18:33:25.498101730Z I0504 18:33:25.498098       1 gather.go:180] gatherer "clusterconfig" function "container_runtime_configs" took 7.598556ms to process 0 records
2023-05-04T18:33:25.498204593Z I0504 18:33:25.498190       1 tasks_processing.go:71] worker 6 working on crds task.
2023-05-04T18:33:25.498327564Z I0504 18:33:25.498310       1 tasks_processing.go:71] worker 11 working on host_subnets task.
2023-05-04T18:33:25.498427461Z I0504 18:33:25.498415       1 tasks_processing.go:71] worker 0 working on service_accounts task.
2023-05-04T18:33:25.498605245Z I0504 18:33:25.498593       1 tasks_processing.go:71] worker 3 working on sap_license_management_logs task.
2023-05-04T18:33:25.498783709Z I0504 18:33:25.498772       1 tasks_processing.go:71] worker 10 working on image task.
2023-05-04T18:33:25.506586549Z I0504 18:33:25.506546       1 sap_vsystem_iptables_logs.go:51] SAP resources weren't found
2023-05-04T18:33:25.506586549Z I0504 18:33:25.506552       1 tasks_processing.go:71] worker 12 working on metrics task.
2023-05-04T18:33:25.506790802Z I0504 18:33:25.506769       1 recorder.go:70] Recording config/pod/openshift-cluster-machine-approver/machine-approver-879c4799-h65jk with fingerprint=c0e63feea6fdf5f9d9941f46d70b802481e8e0ef5054d7276fbe4418d303928b
2023-05-04T18:33:25.506941124Z I0504 18:33:25.506923       1 recorder.go:70] Recording config/pod/openshift-cluster-version/cluster-version-operator-7544974f8f-tjk7v with fingerprint=db72b1d08fea3e6e9bc3c01dd698d013d1b5a5e815b6d6746a398f07beb0fe6a
2023-05-04T18:33:25.506952045Z E0504 18:33:25.506944       1 gather.go:164] error recording gatherer "clusterconfig" function "container_images" result "config/pod/openshift-cluster-version/cluster-version-operator-7544974f8f-tjk7v.json" because of the error: the record with the same name "config/pod/openshift-cluster-version/cluster-version-operator-7544974f8f-tjk7v.json" was already recorded and had the fingerprint "db72b1d08fea3e6e9bc3c01dd698d013d1b5a5e815b6d6746a398f07beb0fe6a", overwriting with the record having fingerprint "db72b1d08fea3e6e9bc3c01dd698d013d1b5a5e815b6d6746a398f07beb0fe6a"
2023-05-04T18:33:25.507023348Z W0504 18:33:25.506957       1 gather.go:158] issue recording gatherer "clusterconfig" function "container_images" result "config/pod/openshift-cluster-version/cluster-version-operator-7544974f8f-tjk7v.json" because of the warning: warning: the record with the same fingerprint "db72b1d08fea3e6e9bc3c01dd698d013d1b5a5e815b6d6746a398f07beb0fe6a" was already recorded at path "config/pod/openshift-cluster-version/cluster-version-operator-7544974f8f-tjk7v.json", recording another one with a different path "config/pod/openshift-cluster-version/cluster-version-operator-7544974f8f-tjk7v.json"
2023-05-04T18:33:25.507257418Z I0504 18:33:25.507238       1 recorder.go:70] Recording config/pod/openshift-ingress-operator/ingress-operator-6dbf96bf9c-mchcp with fingerprint=614a6284ce6aca0d0df101cfaa03b056d1dae08f7d5a7b3c7fbf0328e825b9cc
2023-05-04T18:33:25.507355532Z I0504 18:33:25.507345       1 recorder.go:70] Recording config/pod/openshift-ingress/router-default-757b9d4d79-snzvp with fingerprint=6e00560774d268185e1a7506378e1c0df67c552fa216dc8b6f4a779e8721a1f1
2023-05-04T18:33:25.507722781Z I0504 18:33:25.507710       1 recorder.go:70] Recording config/running_containers with fingerprint=ebb66e484437a53ce0391730047bf45f028e3fa00c9bace24b91b0c0e1872b4c
2023-05-04T18:33:25.507730335Z I0504 18:33:25.507718       1 gather.go:180] gatherer "clusterconfig" function "container_images" took 141.368651ms to process 5 records
2023-05-04T18:33:25.507735244Z I0504 18:33:25.507731       1 gather.go:180] gatherer "clusterconfig" function "sap_license_management_logs" took 7.958ms to process 0 records
2023-05-04T18:33:25.507740073Z I0504 18:33:25.507736       1 gather.go:180] gatherer "clusterconfig" function "host_subnets" took 9.123578ms to process 0 records
2023-05-04T18:33:25.507774648Z I0504 18:33:25.507765       1 recorder.go:70] Recording config/oauth with fingerprint=9d910ae7f0dcb338bb7cc4e0ed40b9df5d0c7c8c794cdd32a78dbbfb150f2c47
2023-05-04T18:33:25.507774648Z I0504 18:33:25.507772       1 gather.go:180] gatherer "clusterconfig" function "oauths" took 10.635143ms to process 1 records
2023-05-04T18:33:25.507782232Z I0504 18:33:25.507778       1 tasks_processing.go:71] worker 15 working on ingress task.
2023-05-04T18:33:25.508163257Z I0504 18:33:25.508147       1 tasks_processing.go:74] worker 11 stopped.
2023-05-04T18:33:25.508181792Z I0504 18:33:25.508160       1 tasks_processing.go:74] worker 3 stopped.
2023-05-04T18:33:25.509041214Z I0504 18:33:25.508262       1 tasks_processing.go:74] worker 10 stopped.
2023-05-04T18:33:25.509041214Z I0504 18:33:25.508301       1 recorder.go:70] Recording config/image with fingerprint=40406a2d3048d25fb0167bcc2918af08fd6c87b76ee15bfdea90334a80de86f0
2023-05-04T18:33:25.509041214Z I0504 18:33:25.508309       1 gather.go:180] gatherer "clusterconfig" function "image" took 9.480387ms to process 1 records
2023-05-04T18:33:25.513822314Z I0504 18:33:25.512784       1 tasks_processing.go:74] worker 15 stopped.
2023-05-04T18:33:25.513822314Z I0504 18:33:25.512829       1 recorder.go:70] Recording config/ingress with fingerprint=781a0b8ee5796efd6fc80b9fff891a01af47b36baf9ea4f75188a913d17e7ac5
2023-05-04T18:33:25.513822314Z I0504 18:33:25.512838       1 gather.go:180] gatherer "clusterconfig" function "ingress" took 4.997847ms to process 1 records
2023-05-04T18:33:25.513822314Z I0504 18:33:25.513255       1 tasks_processing.go:74] worker 4 stopped.
2023-05-04T18:33:25.513822314Z I0504 18:33:25.513309       1 recorder.go:70] Recording config/validatingwebhookconfigurations/alertmanagerconfigs.openshift.io with fingerprint=fcf00b34b07141e143ba5b5fb1b59572f62343463c4d71416c3057e811be28d5
2023-05-04T18:33:25.513822314Z I0504 18:33:25.513339       1 recorder.go:70] Recording config/validatingwebhookconfigurations/autoscaling.openshift.io with fingerprint=909a0e29eb5d6c1e43ccbd2a9edf3c1cc04dc1e35e0117d840985b1195a8af99
2023-05-04T18:33:25.513822314Z I0504 18:33:25.513361       1 recorder.go:70] Recording config/validatingwebhookconfigurations/cluster-baremetal-validating-webhook-configuration with fingerprint=ce423529a9780f564c48c4de6c74f76cc65f86c5c44a4af5ca92781327ff98e8
2023-05-04T18:33:25.513822314Z I0504 18:33:25.513381       1 recorder.go:70] Recording config/validatingwebhookconfigurations/controlplanemachineset.machine.openshift.io with fingerprint=79f859beeaadf5f1eac94c9a61ba4489dd7efe0ff94dd655c924a29fd681d022
2023-05-04T18:33:25.513822314Z I0504 18:33:25.513400       1 recorder.go:70] Recording config/validatingwebhookconfigurations/multus.openshift.io with fingerprint=4bb2304c54026dab033e1a2a651b2ca8a8dfbeb14023a1e430dc992b1f0cdb17
2023-05-04T18:33:25.514674273Z I0504 18:33:25.514164       1 recorder.go:70] Recording config/validatingwebhookconfigurations/performance-addon-operator with fingerprint=7c0dc2f167a3b25da54137a57f6532605f7c74642721d50de9c65374b292f69d
2023-05-04T18:33:25.514674273Z I0504 18:33:25.514206       1 recorder.go:70] Recording config/validatingwebhookconfigurations/prometheusrules.openshift.io with fingerprint=b31c2bdf0f899481779a4149e2902ba299fe6873a663296253861d90be26b2ef
2023-05-04T18:33:25.514674273Z I0504 18:33:25.514232       1 recorder.go:70] Recording config/validatingwebhookconfigurations/snapshot.storage.k8s.io with fingerprint=84f30fd3c07eb1e7694fa2fe112539311495a9ae22612b849e5bc4afdae5b432
2023-05-04T18:33:25.514674273Z I0504 18:33:25.514256       1 recorder.go:70] Recording config/validatingwebhookconfigurations/vlvmcluster.kb.io-bwbz9 with fingerprint=b2ca9c2c4c8590efcd9e18e3a4b4e0499e8822edff27caa50c8193f3fc3ee13c
2023-05-04T18:33:25.514674273Z I0504 18:33:25.514265       1 gather.go:180] gatherer "clusterconfig" function "validating_webhook_configurations" took 15.278796ms to process 9 records
2023-05-04T18:33:25.520019572Z I0504 18:33:25.516148       1 tasks_processing.go:74] worker 6 stopped.
2023-05-04T18:33:25.520019572Z I0504 18:33:25.517712       1 recorder.go:70] Recording config/crd/volumesnapshots.snapshot.storage.k8s.io with fingerprint=06d23a6335a38edbc58c1974e35b9692361fd2cc7b6c26c9642895fa2b662db9
2023-05-04T18:33:25.521415050Z I0504 18:33:25.521350       1 recorder.go:70] Recording config/crd/volumesnapshotcontents.snapshot.storage.k8s.io with fingerprint=c14ae6f5b67ba3c88d768061277086a49870420126f1219955ba2635c8fd8251
2023-05-04T18:33:25.521415050Z I0504 18:33:25.521371       1 gather.go:180] gatherer "clusterconfig" function "crds" took 17.94071ms to process 2 records
2023-05-04T18:33:25.526508396Z I0504 18:33:25.526283       1 tasks_processing.go:74] worker 1 stopped.
2023-05-04T18:33:25.526508396Z I0504 18:33:25.526310       1 recorder.go:70] Recording config/pod/openshift-kube-scheduler/logs/openshift-kube-scheduler-node/messages.log with fingerprint=821f85f1aadec2bc7df1f04c88b4a1037a73e3057cccb27a7e28c66015436c12
2023-05-04T18:33:25.526508396Z I0504 18:33:25.526318       1 gather.go:180] gatherer "clusterconfig" function "scheduler_logs" took 181.195462ms to process 1 records
2023-05-04T18:33:25.526508396Z I0504 18:33:25.526341       1 tasks_processing.go:74] worker 9 stopped.
2023-05-04T18:33:25.526508396Z I0504 18:33:25.526349       1 gather.go:180] gatherer "clusterconfig" function "openshift_authentication_logs" took 160.02364ms to process 0 records
2023-05-04T18:33:25.532294621Z I0504 18:33:25.532245       1 tasks_processing.go:74] worker 5 stopped.
2023-05-04T18:33:25.532294621Z I0504 18:33:25.532267       1 gather.go:180] gatherer "clusterconfig" function "openshift_apiserver_operator_logs" took 50.938509ms to process 0 records
2023-05-04T18:33:25.555575981Z I0504 18:33:25.555534       1 tasks_processing.go:74] worker 8 stopped.
2023-05-04T18:33:25.555609654Z I0504 18:33:25.555590       1 recorder.go:70] Recording config/node/logs/node.log with fingerprint=d50ea89ba1d0cc1e0ef1ab124ad5814a87c4013cbeefe94860ee403c3e7a79d8
2023-05-04T18:33:25.555609654Z I0504 18:33:25.555599       1 gather.go:180] gatherer "clusterconfig" function "node_logs" took 210.038287ms to process 1 records
2023-05-04T18:33:25.579188312Z I0504 18:33:25.579151       1 tasks_processing.go:74] worker 7 stopped.
2023-05-04T18:33:25.579213479Z I0504 18:33:25.579203       1 recorder.go:70] Recording config/pod/openshift-kube-controller-manager/logs/kube-controller-manager-node/errors.log with fingerprint=27e9b56e823c238f649092b3c63728724c8eed85744e9cb81ba02f9017b3f939
2023-05-04T18:33:25.579219350Z I0504 18:33:25.579212       1 gather.go:180] gatherer "clusterconfig" function "kube_controller_manager_logs" took 221.890933ms to process 1 records
2023-05-04T18:33:25.690050898Z I0504 18:33:25.690018       1 request.go:533] Waited for 151.121198ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/ingress.operator.openshift.io/v1/namespaces/openshift-ingress-operator/dnsrecords/default
2023-05-04T18:33:25.690242348Z I0504 18:33:25.690182       1 request.go:533] Waited for 154.622297ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operators.coreos.com/v1alpha1/namespaces/openshift-cluster-machine-approver/installplans?limit=500
2023-05-04T18:33:25.691466123Z I0504 18:33:25.691438       1 operators.go:164] Unable to get dnsrecords.ingress.operator.openshift.io resource due to: dnsrecords.ingress.operator.openshift.io "default" is forbidden: User "system:serviceaccount:openshift-insights:gather" cannot get resource "dnsrecords" in API group "ingress.operator.openshift.io" in the namespace "openshift-ingress-operator"
2023-05-04T18:33:25.699247542Z I0504 18:33:25.699220       1 request.go:533] Waited for 158.074834ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-cloud-controller-manager-operator/serviceaccounts?limit=1000
2023-05-04T18:33:25.890429541Z I0504 18:33:25.890395       1 request.go:533] Waited for 198.851548ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operator.openshift.io/v1/insightsoperators/cluster
2023-05-04T18:33:25.890517045Z I0504 18:33:25.890396       1 request.go:533] Waited for 198.214623ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operators.coreos.com/v1alpha1/namespaces/openshift-cluster-node-tuning-operator/installplans?limit=500
2023-05-04T18:33:25.899628941Z I0504 18:33:25.899595       1 request.go:533] Waited for 198.375765ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-cloud-credential-operator/serviceaccounts?limit=1000
2023-05-04T18:33:26.089952389Z I0504 18:33:26.089918       1 request.go:533] Waited for 194.883844ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster
2023-05-04T18:33:26.091021935Z I0504 18:33:26.090982       1 request.go:533] Waited for 197.860719ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operators.coreos.com/v1alpha1/namespaces/openshift-cluster-samples-operator/installplans?limit=500
2023-05-04T18:33:26.093369911Z I0504 18:33:26.093331       1 operators.go:164] Unable to get podnetworkconnectivitychecks.controlplane.operator.openshift.io resource due to: name is required
2023-05-04T18:33:26.099164923Z I0504 18:33:26.099144       1 request.go:533] Waited for 197.651486ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-cloud-network-config-controller/serviceaccounts?limit=1000
2023-05-04T18:33:26.290285867Z I0504 18:33:26.290249       1 request.go:533] Waited for 196.86942ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster
2023-05-04T18:33:26.290285867Z I0504 18:33:26.290251       1 request.go:533] Waited for 197.427888ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operators.coreos.com/v1alpha1/namespaces/openshift-cluster-storage-operator/installplans?limit=500
2023-05-04T18:33:26.298908886Z I0504 18:33:26.298863       1 request.go:533] Waited for 197.855379ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-cluster-csi-drivers/serviceaccounts?limit=1000
2023-05-04T18:33:26.490322679Z I0504 18:33:26.490283       1 request.go:533] Waited for 198.045025ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operators.coreos.com/v1alpha1/namespaces/openshift-cluster-version/installplans?limit=500
2023-05-04T18:33:26.490365279Z I0504 18:33:26.490288       1 request.go:533] Waited for 197.367734ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeschedulers/cluster
2023-05-04T18:33:26.493062019Z I0504 18:33:26.493022       1 operators.go:164] Unable to get podnetworkconnectivitychecks.controlplane.operator.openshift.io resource due to: name is required
2023-05-04T18:33:26.498925750Z I0504 18:33:26.498912       1 request.go:533] Waited for 197.851091ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-cluster-machine-approver/serviceaccounts?limit=1000
2023-05-04T18:33:26.546878337Z I0504 18:33:26.546836       1 tasks_processing.go:74] worker 12 stopped.
2023-05-04T18:33:26.546919544Z I0504 18:33:26.546896       1 recorder.go:70] Recording config/metrics with fingerprint=3d9ae40fc3d490aa4647a7cecc1c5ff1562acafd947c9d3375994744a256be73
2023-05-04T18:33:26.546919544Z I0504 18:33:26.546909       1 gather.go:180] gatherer "clusterconfig" function "metrics" took 1.040265198s to process 1 records
2023-05-04T18:33:26.546925716Z I0504 18:33:26.546922       1 recorder.go:70] Recording config/tsdb.json with fingerprint=89f385113c4786a9b47e167bed55e6e2fa9132860743b26276a17997c115ed8b
2023-05-04T18:33:26.546930775Z I0504 18:33:26.546926       1 gather.go:180] gatherer "clusterconfig" function "tsdb_status" took 1.062133567s to process 1 records
2023-05-04T18:33:26.546935764Z I0504 18:33:26.546931       1 tasks_processing.go:74] worker 13 stopped.
2023-05-04T18:33:26.690293958Z I0504 18:33:26.690252       1 request.go:533] Waited for 197.3705ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operators.coreos.com/v1alpha1/namespaces/openshift-config/installplans?limit=500
2023-05-04T18:33:26.690419403Z I0504 18:33:26.690254       1 request.go:533] Waited for 197.159563ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operator.openshift.io/v1/kubestorageversionmigrators/cluster
2023-05-04T18:33:26.698844780Z I0504 18:33:26.698806       1 request.go:533] Waited for 197.847474ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-cluster-node-tuning-operator/serviceaccounts?limit=1000
2023-05-04T18:33:26.890139861Z I0504 18:33:26.890076       1 request.go:533] Waited for 197.331125ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/network.operator.openshift.io/v1/namespaces/openshift-ovn-kubernetes/operatorpkis/ovn
2023-05-04T18:33:26.890290324Z I0504 18:33:26.890189       1 request.go:533] Waited for 197.527213ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operators.coreos.com/v1alpha1/namespaces/openshift-config-managed/installplans?limit=500
2023-05-04T18:33:26.893280193Z I0504 18:33:26.892264       1 operators.go:164] Unable to get operatorpkis.network.operator.openshift.io resource due to: operatorpkis.network.operator.openshift.io "ovn" is forbidden: User "system:serviceaccount:openshift-insights:gather" cannot get resource "operatorpkis" in API group "network.operator.openshift.io" in the namespace "openshift-ovn-kubernetes"
2023-05-04T18:33:26.899534788Z I0504 18:33:26.899407       1 request.go:533] Waited for 198.72494ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-cluster-samples-operator/serviceaccounts?limit=1000
2023-05-04T18:33:27.089997006Z I0504 18:33:27.089949       1 request.go:533] Waited for 197.612012ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/network.operator.openshift.io/v1/namespaces/openshift-ovn-kubernetes/operatorpkis/signer
2023-05-04T18:33:27.091054039Z I0504 18:33:27.091029       1 request.go:533] Waited for 198.381226ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operators.coreos.com/v1alpha1/namespaces/openshift-config-operator/installplans?limit=500
2023-05-04T18:33:27.091753862Z I0504 18:33:27.091147       1 operators.go:164] Unable to get operatorpkis.network.operator.openshift.io resource due to: operatorpkis.network.operator.openshift.io "signer" is forbidden: User "system:serviceaccount:openshift-insights:gather" cannot get resource "operatorpkis" in API group "network.operator.openshift.io" in the namespace "openshift-ovn-kubernetes"
2023-05-04T18:33:27.099287897Z I0504 18:33:27.099262       1 request.go:533] Waited for 196.795711ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-cluster-storage-operator/serviceaccounts?limit=1000
2023-05-04T18:33:27.290522505Z I0504 18:33:27.290483       1 request.go:533] Waited for 199.280733ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operator.openshift.io/v1/networks/cluster
2023-05-04T18:33:27.290579592Z I0504 18:33:27.290488       1 request.go:533] Waited for 193.239218ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operators.coreos.com/v1alpha1/namespaces/openshift-console/installplans?limit=500
2023-05-04T18:33:27.299261881Z I0504 18:33:27.299223       1 request.go:533] Waited for 197.919339ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-cluster-version/serviceaccounts?limit=1000
2023-05-04T18:33:27.490246740Z I0504 18:33:27.490209       1 request.go:533] Waited for 196.982321ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operator.openshift.io/v1/openshiftapiservers/cluster
2023-05-04T18:33:27.490246740Z I0504 18:33:27.490209       1 request.go:533] Waited for 197.362364ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operators.coreos.com/v1alpha1/namespaces/openshift-console-operator/installplans?limit=500
2023-05-04T18:33:27.493884345Z I0504 18:33:27.493841       1 operators.go:164] Unable to get podnetworkconnectivitychecks.controlplane.operator.openshift.io resource due to: name is required
2023-05-04T18:33:27.498821748Z I0504 18:33:27.498798       1 request.go:533] Waited for 197.878513ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config/serviceaccounts?limit=1000
2023-05-04T18:33:27.690217408Z I0504 18:33:27.690010       1 request.go:533] Waited for 196.110475ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operator.openshift.io/v1/openshiftcontrollermanagers/cluster
2023-05-04T18:33:27.690217408Z I0504 18:33:27.690172       1 request.go:533] Waited for 196.939171ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operators.coreos.com/v1alpha1/namespaces/openshift-console-user-settings/installplans?limit=500
2023-05-04T18:33:27.699628154Z I0504 18:33:27.699586       1 request.go:533] Waited for 198.898195ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-managed/serviceaccounts?limit=1000
2023-05-04T18:33:27.890607011Z I0504 18:33:27.890557       1 request.go:533] Waited for 197.933245ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/samples.operator.openshift.io/v1/configs/cluster
2023-05-04T18:33:27.890607011Z I0504 18:33:27.890559       1 request.go:533] Waited for 198.464482ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operators.coreos.com/v1alpha1/namespaces/openshift-controller-manager/installplans?limit=500
2023-05-04T18:33:27.899595525Z I0504 18:33:27.899549       1 request.go:533] Waited for 197.998818ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config-operator/serviceaccounts?limit=1000
2023-05-04T18:33:28.090265634Z I0504 18:33:28.090227       1 request.go:533] Waited for 196.989905ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operator.openshift.io/v1/servicecas/cluster
2023-05-04T18:33:28.090394115Z I0504 18:33:28.090377       1 request.go:533] Waited for 196.849672ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operators.coreos.com/v1alpha1/namespaces/openshift-controller-manager-operator/installplans?limit=500
2023-05-04T18:33:28.099142138Z I0504 18:33:28.099087       1 request.go:533] Waited for 196.362568ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-console/serviceaccounts?limit=1000
2023-05-04T18:33:28.290266628Z I0504 18:33:28.290228       1 request.go:533] Waited for 197.255674ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operator.openshift.io/v1/storages/cluster
2023-05-04T18:33:28.290423533Z I0504 18:33:28.290408       1 request.go:533] Waited for 197.699336ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operators.coreos.com/v1alpha1/namespaces/openshift-dns/installplans?limit=500
2023-05-04T18:33:28.293254544Z I0504 18:33:28.293223       1 tasks_processing.go:74] worker 14 stopped.
2023-05-04T18:33:28.293310319Z I0504 18:33:28.293297       1 recorder.go:70] Recording config/clusteroperator/authentication with fingerprint=1efd3f21ee71b660a4ae53585f28e78ce7f8f2091d6db18979e30642cbf538c7
2023-05-04T18:33:28.293381713Z I0504 18:33:28.293370       1 recorder.go:70] Recording config/clusteroperator/operator.openshift.io/authentication/cluster with fingerprint=3f670869558fe32b0991a61b90f42d752d6718099796826c3a5d726e4c27f030
2023-05-04T18:33:28.293406209Z I0504 18:33:28.293396       1 recorder.go:70] Recording config/clusteroperator/baremetal with fingerprint=4bf59119c135fb1cdcdf2749d25518ad973dab155f25cbc9817b63927e401f3c
2023-05-04T18:33:28.293431166Z I0504 18:33:28.293422       1 recorder.go:70] Recording config/clusteroperator/cloud-controller-manager with fingerprint=0e8e6b710c1961eb8dd6e6acb614f23d31325bff863dd583b5562240674169a9
2023-05-04T18:33:28.293492270Z I0504 18:33:28.293481       1 recorder.go:70] Recording config/clusteroperator/cloud-credential with fingerprint=20b979683e2a805f92c744c887f1e9438f6843d0eff24039d727076fc0cc4e17
2023-05-04T18:33:28.293498943Z I0504 18:33:28.293493       1 recorder.go:70] Recording config/clusteroperator/operator.openshift.io/cloudcredential/cluster with fingerprint=46c3957079df4e4653a808e6f850abac72c8b1276aa6de05929cc8264f4a1d93
2023-05-04T18:33:28.293529650Z I0504 18:33:28.293511       1 recorder.go:70] Recording config/clusteroperator/cluster-autoscaler with fingerprint=e9b9d816a2c9b9340b12183cc1b6106f3c73d639880cc7805b065f0b6568ec1b
2023-05-04T18:33:28.293536413Z I0504 18:33:28.293531       1 recorder.go:70] Recording config/clusteroperator/config-operator with fingerprint=e19ab07be91edcff155450ff113ac630be3649e9991ab76407ad5e3ece794180
2023-05-04T18:33:28.293549678Z I0504 18:33:28.293539       1 recorder.go:70] Recording config/clusteroperator/operator.openshift.io/config/cluster with fingerprint=7196eb59efe1f5998354aed5372544e9c59c3c8135aea7e3914ebf8f3330364b
2023-05-04T18:33:28.293575907Z I0504 18:33:28.293565       1 recorder.go:70] Recording config/clusteroperator/console with fingerprint=b7ca78b6f98e68ec8231b337a3acc00e01dae3392351b7d5839f2bb2a39f04b0
2023-05-04T18:33:28.293582309Z I0504 18:33:28.293576       1 recorder.go:70] Recording config/clusteroperator/operator.openshift.io/console/cluster with fingerprint=010776c08cb0c6b348faa3bde210b48a9a86a68f069d7d9bd68c1694b6985857
2023-05-04T18:33:28.293610061Z I0504 18:33:28.293592       1 recorder.go:70] Recording config/clusteroperator/control-plane-machine-set with fingerprint=d4ea52e71465f005b4535efe64ff28f0cec1826997f78004f6cf0affb61b2059
2023-05-04T18:33:28.293631562Z I0504 18:33:28.293620       1 recorder.go:70] Recording config/clusteroperator/csi-snapshot-controller with fingerprint=dd61ebe3a6d70b181678e626324f098f1e7a92e65426d1e249dc4d44a9c6755c
2023-05-04T18:33:28.293637974Z I0504 18:33:28.293631       1 recorder.go:70] Recording config/clusteroperator/operator.openshift.io/csisnapshotcontroller/cluster with fingerprint=5adc514f4b63e2f1ecc68bf6f9c0af70c5eea04522a49524e102721b1c41f80e
2023-05-04T18:33:28.293659374Z I0504 18:33:28.293650       1 recorder.go:70] Recording config/clusteroperator/dns with fingerprint=b1fd2fcc5989be8689cec34fd094b4d293c8b82320fc23c7e480421f331ac43e
2023-05-04T18:33:28.293680574Z I0504 18:33:28.293667       1 recorder.go:70] Recording config/clusteroperator/operator.openshift.io/dns/default with fingerprint=66451672d1dca372e5db68be01305585d028c30ef39ff8cb8efc44abd8226380
2023-05-04T18:33:28.293699980Z I0504 18:33:28.293691       1 recorder.go:70] Recording config/clusteroperator/etcd with fingerprint=20546a0d8eb2697bfe6f29c3166d4f8ff5a31e55f3eb2cc878cc269104be99c8
2023-05-04T18:33:28.293715479Z I0504 18:33:28.293706       1 recorder.go:70] Recording config/clusteroperator/operator.openshift.io/etcd/cluster with fingerprint=b46d458f840405154372ea9decf8fe7c8c37b1ea8ceebe40d163166b33cf8188
2023-05-04T18:33:28.293736849Z I0504 18:33:28.293728       1 recorder.go:70] Recording config/clusteroperator/image-registry with fingerprint=43df41c72168dab50474066f8fa510b902f6e20c821ef40b6d9adecbc2eb4aa2
2023-05-04T18:33:28.293765864Z I0504 18:33:28.293752       1 recorder.go:70] Recording config/clusteroperator/ingress with fingerprint=773fab44c6fd9ec1e0115cce15ac30f12f6fea3e907f960ef503c779cad4a13e
2023-05-04T18:33:28.293772907Z I0504 18:33:28.293769       1 recorder.go:70] Recording config/clusteroperator/operator.openshift.io/ingresscontroller/openshift-ingress-operator/default with fingerprint=2674785ba6ac5c818ffc9e162b795cc0d60e0d06b4914beb29d581f9afe822c5
2023-05-04T18:33:28.293810257Z I0504 18:33:28.293799       1 recorder.go:70] Recording config/clusteroperator/insights with fingerprint=ba393366ca9282497df9723214d8699dae3267f4a11e899f12a52ea2a6eaba99
2023-05-04T18:33:28.293816879Z I0504 18:33:28.293809       1 recorder.go:70] Recording config/clusteroperator/operator.openshift.io/insightsoperator/cluster with fingerprint=e5ff11d57817f84a678f6fa9565af55bd1120227c16a21933637ab62675a6d70
2023-05-04T18:33:28.293843479Z I0504 18:33:28.293834       1 recorder.go:70] Recording config/clusteroperator/kube-apiserver with fingerprint=9e7100f4f1319f0c91a00de16e9b5eabe390f7b415fed86a4b7139f8d38cc9d1
2023-05-04T18:33:28.293890838Z I0504 18:33:28.293880       1 recorder.go:70] Recording config/clusteroperator/operator.openshift.io/kubeapiserver/cluster with fingerprint=92f16f696a5f7077e156ead7bddd8f161ff3bd255ccad0cd0973b94143558b52
2023-05-04T18:33:28.293911657Z I0504 18:33:28.293902       1 recorder.go:70] Recording config/clusteroperator/kube-controller-manager with fingerprint=6f30235e73973dec3728be37013e9da517ec62723333b426515b62f8ca63a557
2023-05-04T18:33:28.293940301Z I0504 18:33:28.293923       1 recorder.go:70] Recording config/clusteroperator/operator.openshift.io/kubecontrollermanager/cluster with fingerprint=4edbffffa56295e3d73e0d846827ca6b8f9c8729084f1aaea3a533c699f21877
2023-05-04T18:33:28.293947965Z I0504 18:33:28.293945       1 recorder.go:70] Recording config/clusteroperator/kube-scheduler with fingerprint=3b2c27af70587fcd5b7c297c767e046f525e4ecc5d8268e324a1e607983a6968
2023-05-04T18:33:28.293977230Z I0504 18:33:28.293958       1 recorder.go:70] Recording config/clusteroperator/operator.openshift.io/kubescheduler/cluster with fingerprint=4c19e5391383b10e290707cbddf1ea79a8359bfe7867869021d7e62d674cb34c
2023-05-04T18:33:28.293993461Z I0504 18:33:28.293985       1 recorder.go:70] Recording config/clusteroperator/kube-storage-version-migrator with fingerprint=ccfc84876c229c3c6045ca9f1b222124b85c2dac1cc752fb3176035277a7255c
2023-05-04T18:33:28.293998680Z I0504 18:33:28.293995       1 recorder.go:70] Recording config/clusteroperator/operator.openshift.io/kubestorageversionmigrator/cluster with fingerprint=9351181aa7e6ada41ef581ab31e13516c6b934cc95710154bafb2eb222cb58db
2023-05-04T18:33:28.294041200Z I0504 18:33:28.294015       1 recorder.go:70] Recording config/clusteroperator/machine-api with fingerprint=a8bee862f72e44e2668646fec5444489731624daf8a91570871ed01e37b8f2e6
2023-05-04T18:33:28.294041200Z I0504 18:33:28.294034       1 recorder.go:70] Recording config/clusteroperator/machine-approver with fingerprint=eebf2b65b9d350fa13d6687832f6025c629ac4e3f1253855ed23f79697b71a29
2023-05-04T18:33:28.294067399Z I0504 18:33:28.294056       1 recorder.go:70] Recording config/clusteroperator/machine-config with fingerprint=915af78d83cf1d1e5c458af02c481ade1b4afd11e6339d81a7ed17be09d05f21
2023-05-04T18:33:28.294137040Z I0504 18:33:28.294124       1 recorder.go:70] Recording config/clusteroperator/marketplace with fingerprint=4a0f21077f08643866287c5f8c816517c108220f6f54314f04273c393ac1c19d
2023-05-04T18:33:28.294164862Z I0504 18:33:28.294155       1 recorder.go:70] Recording config/clusteroperator/monitoring with fingerprint=3e0db66ece6258b200f1353748a8d3530a988c84f90eab8f8d8995a95e127f53
2023-05-04T18:33:28.294234302Z I0504 18:33:28.294223       1 recorder.go:70] Recording config/clusteroperator/network with fingerprint=9c42a14f1566641188656ea3fd4bc7fb7820d58a83b0223abb19e192f75e263a
2023-05-04T18:33:28.294305075Z I0504 18:33:28.294249       1 recorder.go:70] Recording config/clusteroperator/operator.openshift.io/network/cluster with fingerprint=0bb9461ab1d969a8286e829e42334a81e7de0f6f99f0faa0590d79049d741c2a
2023-05-04T18:33:28.294305075Z I0504 18:33:28.294277       1 recorder.go:70] Recording config/clusteroperator/node-tuning with fingerprint=0300bd5c456155c30dfddaaa74eb9d5be519f858a92fe77e9a755012ecd5754c
2023-05-04T18:33:28.294305075Z I0504 18:33:28.294301       1 recorder.go:70] Recording config/clusteroperator/openshift-apiserver with fingerprint=ba48d0afa4c3f70f93533747087859413a8a8e29a8dd95eb8936a9c120c66b3f
2023-05-04T18:33:28.294325203Z I0504 18:33:28.294316       1 recorder.go:70] Recording config/clusteroperator/operator.openshift.io/openshiftapiserver/cluster with fingerprint=eb788c8cf77ee4f3a2009ca5d4e6f860fb3d252dee050e5c81a4a37109b7d6ad
2023-05-04T18:33:28.294342826Z I0504 18:33:28.294335       1 recorder.go:70] Recording config/clusteroperator/openshift-controller-manager with fingerprint=89f3e2de4ed2d1c0132e5258ddf0fa7f346f7cac170a5db88adaeba1787c3d8e
2023-05-04T18:33:28.294366581Z I0504 18:33:28.294353       1 recorder.go:70] Recording config/clusteroperator/operator.openshift.io/openshiftcontrollermanager/cluster with fingerprint=ec797a5c6d0fe61357b271ea3de7f56f954ad847a63bbf9ede1194ac63f59b7b
2023-05-04T18:33:28.294387109Z I0504 18:33:28.294377       1 recorder.go:70] Recording config/clusteroperator/openshift-samples with fingerprint=6ef24af6838a62f114529e7a2b8e34385c8dc60c92e688cdc008561915c2d060
2023-05-04T18:33:28.294392750Z I0504 18:33:28.294387       1 recorder.go:70] Recording config/clusteroperator/samples.operator.openshift.io/config/cluster with fingerprint=439a4284281b8dcef0621bb14ba23e2175a28a50613f86b33a171c49689474fd
2023-05-04T18:33:28.294432174Z I0504 18:33:28.294404       1 recorder.go:70] Recording config/clusteroperator/operator-lifecycle-manager with fingerprint=462ad5bd6d9c13cc1b47ce253dae1d588fec32ed5a53d4d99f0a10deea23d0b5
2023-05-04T18:33:28.294432174Z I0504 18:33:28.294421       1 recorder.go:70] Recording config/clusteroperator/operator-lifecycle-manager-catalog with fingerprint=ebc9040ec802a9b1125d8f1f1904595278c0daaf5e332aeff907eebeea2a8939
2023-05-04T18:33:28.294446841Z I0504 18:33:28.294439       1 recorder.go:70] Recording config/clusteroperator/operator-lifecycle-manager-packageserver with fingerprint=1dcd5d8ea13840e60fd3d468a502003eaaa51af534516125dcfff214f1a27f46
2023-05-04T18:33:28.294469945Z I0504 18:33:28.294458       1 recorder.go:70] Recording config/clusteroperator/service-ca with fingerprint=e5b59a726b16c18a272f1680cacb6d6963ddc0009f183de59bf2467f19592d0a
2023-05-04T18:33:28.294476607Z I0504 18:33:28.294469       1 recorder.go:70] Recording config/clusteroperator/operator.openshift.io/serviceca/cluster with fingerprint=812f7edc2cdb30e61e7f2b29454357a40b1a507a4b0c2b7729193b67f0e3b4aa
2023-05-04T18:33:28.294498147Z I0504 18:33:28.294489       1 recorder.go:70] Recording config/clusteroperator/storage with fingerprint=9200f635b1cce268441cb1956f5af47e67b138fd39eb4108d24901435425b85f
2023-05-04T18:33:28.294503778Z I0504 18:33:28.294497       1 recorder.go:70] Recording config/clusteroperator/operator.openshift.io/storage/cluster with fingerprint=8e480f8c1ce1b39baac42d8ec780c57c2592929ae0c801b61ffad49ba13f33ad
2023-05-04T18:33:28.294508497Z I0504 18:33:28.294502       1 gather.go:180] gatherer "clusterconfig" function "operators" took 2.980437989s to process 52 records
2023-05-04T18:33:28.299275110Z I0504 18:33:28.299241       1 request.go:533] Waited for 197.472982ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-console-operator/serviceaccounts?limit=1000
2023-05-04T18:33:28.490912192Z I0504 18:33:28.490878       1 request.go:533] Waited for 197.607494ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operators.coreos.com/v1alpha1/namespaces/openshift-dns-operator/installplans?limit=500
2023-05-04T18:33:28.499566630Z I0504 18:33:28.499519       1 request.go:533] Waited for 197.940328ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-console-user-settings/serviceaccounts?limit=1000
2023-05-04T18:33:28.691734147Z I0504 18:33:28.691703       1 request.go:533] Waited for 198.684064ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operators.coreos.com/v1alpha1/namespaces/openshift-etcd/installplans?limit=500
2023-05-04T18:33:28.699532117Z I0504 18:33:28.699496       1 request.go:533] Waited for 198.083888ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-controller-manager/serviceaccounts?limit=1000
2023-05-04T18:33:28.890888173Z I0504 18:33:28.890851       1 request.go:533] Waited for 194.494804ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operators.coreos.com/v1alpha1/namespaces/openshift-etcd-operator/installplans?limit=500
2023-05-04T18:33:28.898644795Z I0504 18:33:28.898619       1 request.go:533] Waited for 196.959298ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-controller-manager-operator/serviceaccounts?limit=1000
2023-05-04T18:33:29.090379411Z I0504 18:33:29.090333       1 request.go:533] Waited for 197.672456ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operators.coreos.com/v1alpha1/namespaces/openshift-host-network/installplans?limit=500
2023-05-04T18:33:29.099192416Z I0504 18:33:29.099155       1 request.go:533] Waited for 198.658856ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-dns/serviceaccounts?limit=1000
2023-05-04T18:33:29.290248057Z I0504 18:33:29.290209       1 request.go:533] Waited for 198.048151ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operators.coreos.com/v1alpha1/namespaces/openshift-image-registry/installplans?limit=500
2023-05-04T18:33:29.299019033Z I0504 18:33:29.298993       1 request.go:533] Waited for 198.113263ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-dns-operator/serviceaccounts?limit=1000
2023-05-04T18:33:29.491029366Z I0504 18:33:29.490955       1 request.go:533] Waited for 198.940184ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operators.coreos.com/v1alpha1/namespaces/openshift-infra/installplans?limit=500
2023-05-04T18:33:29.498829110Z I0504 18:33:29.498792       1 request.go:533] Waited for 198.157045ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts?limit=1000
2023-05-04T18:33:29.690843460Z I0504 18:33:29.690804       1 request.go:533] Waited for 194.999691ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operators.coreos.com/v1alpha1/namespaces/openshift-ingress/installplans?limit=500
2023-05-04T18:33:29.698818473Z I0504 18:33:29.698779       1 request.go:533] Waited for 198.069761ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/serviceaccounts?limit=1000
2023-05-04T18:33:29.891122476Z I0504 18:33:29.891084       1 request.go:533] Waited for 198.320762ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operators.coreos.com/v1alpha1/namespaces/openshift-ingress-canary/installplans?limit=500
2023-05-04T18:33:29.899226400Z I0504 18:33:29.899147       1 request.go:533] Waited for 198.273393ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-host-network/serviceaccounts?limit=1000
2023-05-04T18:33:30.090561416Z I0504 18:33:30.090515       1 request.go:533] Waited for 197.37095ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operators.coreos.com/v1alpha1/namespaces/openshift-ingress-operator/installplans?limit=500
2023-05-04T18:33:30.099527879Z I0504 18:33:30.099491       1 request.go:533] Waited for 198.444184ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-image-registry/serviceaccounts?limit=1000
2023-05-04T18:33:30.290779999Z I0504 18:33:30.290742       1 request.go:533] Waited for 198.25545ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operators.coreos.com/v1alpha1/namespaces/openshift-insights/installplans?limit=500
2023-05-04T18:33:30.298617724Z I0504 18:33:30.298583       1 request.go:533] Waited for 197.087188ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts?limit=1000
2023-05-04T18:33:30.492007665Z I0504 18:33:30.491886       1 request.go:533] Waited for 199.383115ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operators.coreos.com/v1alpha1/namespaces/openshift-kni-infra/installplans?limit=500
2023-05-04T18:33:30.499224986Z I0504 18:33:30.499182       1 request.go:533] Waited for 198.581382ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-ingress/serviceaccounts?limit=1000
2023-05-04T18:33:30.690791196Z I0504 18:33:30.690752       1 request.go:533] Waited for 195.624564ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operators.coreos.com/v1alpha1/namespaces/openshift-kube-apiserver/installplans?limit=500
2023-05-04T18:33:30.698608572Z I0504 18:33:30.698562       1 request.go:533] Waited for 197.000776ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-ingress-canary/serviceaccounts?limit=1000
2023-05-04T18:33:30.890432285Z I0504 18:33:30.890392       1 request.go:533] Waited for 197.645406ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operators.coreos.com/v1alpha1/namespaces/openshift-kube-apiserver-operator/installplans?limit=500
2023-05-04T18:33:30.899413345Z I0504 18:33:30.899382       1 request.go:533] Waited for 199.168001ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-ingress-operator/serviceaccounts?limit=1000
2023-05-04T18:33:31.090511076Z I0504 18:33:31.090471       1 request.go:533] Waited for 198.088626ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operators.coreos.com/v1alpha1/namespaces/openshift-kube-controller-manager/installplans?limit=500
2023-05-04T18:33:31.098638043Z I0504 18:33:31.098607       1 request.go:533] Waited for 197.524678ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-insights/serviceaccounts?limit=1000
2023-05-04T18:33:31.290671489Z I0504 18:33:31.290631       1 request.go:533] Waited for 195.972517ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operators.coreos.com/v1alpha1/namespaces/openshift-kube-controller-manager-operator/installplans?limit=500
2023-05-04T18:33:31.299554746Z I0504 18:33:31.299519       1 request.go:533] Waited for 199.138416ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kni-infra/serviceaccounts?limit=1000
2023-05-04T18:33:31.490660461Z I0504 18:33:31.490622       1 request.go:533] Waited for 198.146826ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operators.coreos.com/v1alpha1/namespaces/openshift-kube-scheduler/installplans?limit=500
2023-05-04T18:33:31.499469739Z I0504 18:33:31.499442       1 request.go:533] Waited for 198.157215ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts?limit=1000
2023-05-04T18:33:31.690610120Z I0504 18:33:31.690570       1 request.go:533] Waited for 198.078918ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operators.coreos.com/v1alpha1/namespaces/openshift-kube-scheduler-operator/installplans?limit=500
2023-05-04T18:33:31.699167986Z I0504 18:33:31.699141       1 request.go:533] Waited for 197.965877ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver-operator/serviceaccounts?limit=1000
2023-05-04T18:33:31.891135418Z I0504 18:33:31.891098       1 request.go:533] Waited for 197.965326ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operators.coreos.com/v1alpha1/namespaces/openshift-kube-storage-version-migrator/installplans?limit=500
2023-05-04T18:33:31.899022305Z I0504 18:33:31.898992       1 request.go:533] Waited for 198.043422ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts?limit=1000
2023-05-04T18:33:32.091243654Z I0504 18:33:32.091202       1 request.go:533] Waited for 198.240352ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operators.coreos.com/v1alpha1/namespaces/openshift-kube-storage-version-migrator-operator/installplans?limit=500
2023-05-04T18:33:32.099105023Z I0504 18:33:32.099075       1 request.go:533] Waited for 198.280165ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager-operator/serviceaccounts?limit=1000
2023-05-04T18:33:32.291122369Z I0504 18:33:32.291081       1 request.go:533] Waited for 197.985804ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operators.coreos.com/v1alpha1/namespaces/openshift-machine-api/installplans?limit=500
2023-05-04T18:33:32.298875455Z I0504 18:33:32.298844       1 request.go:533] Waited for 198.043152ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler/serviceaccounts?limit=1000
2023-05-04T18:33:32.491032573Z I0504 18:33:32.490987       1 request.go:533] Waited for 197.258249ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operators.coreos.com/v1alpha1/namespaces/openshift-machine-config-operator/installplans?limit=500
2023-05-04T18:33:32.499003438Z I0504 18:33:32.498976       1 request.go:533] Waited for 198.320151ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-scheduler-operator/serviceaccounts?limit=1000
2023-05-04T18:33:32.691054206Z I0504 18:33:32.691011       1 request.go:533] Waited for 198.161573ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operators.coreos.com/v1alpha1/namespaces/openshift-marketplace/installplans?limit=500
2023-05-04T18:33:32.698900978Z I0504 18:33:32.698864       1 request.go:533] Waited for 198.149702ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-storage-version-migrator/serviceaccounts?limit=1000
2023-05-04T18:33:32.891056504Z I0504 18:33:32.891010       1 request.go:533] Waited for 197.1576ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operators.coreos.com/v1alpha1/namespaces/openshift-monitoring/installplans?limit=500
2023-05-04T18:33:32.898928062Z I0504 18:33:32.898899       1 request.go:533] Waited for 198.321834ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-storage-version-migrator-operator/serviceaccounts?limit=1000
2023-05-04T18:33:33.090660564Z I0504 18:33:33.090618       1 request.go:533] Waited for 197.744772ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operators.coreos.com/v1alpha1/namespaces/openshift-multus/installplans?limit=500
2023-05-04T18:33:33.099634921Z I0504 18:33:33.099584       1 request.go:533] Waited for 198.816842ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-machine-api/serviceaccounts?limit=1000
2023-05-04T18:33:33.290501698Z I0504 18:33:33.290463       1 request.go:533] Waited for 197.914209ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operators.coreos.com/v1alpha1/namespaces/openshift-network-diagnostics/installplans?limit=500
2023-05-04T18:33:33.299630956Z I0504 18:33:33.299383       1 request.go:533] Waited for 197.754911ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-machine-config-operator/serviceaccounts?limit=1000
2023-05-04T18:33:33.490704391Z I0504 18:33:33.490665       1 request.go:533] Waited for 198.34662ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operators.coreos.com/v1alpha1/namespaces/openshift-network-operator/installplans?limit=500
2023-05-04T18:33:33.498765886Z I0504 18:33:33.498724       1 request.go:533] Waited for 197.373015ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-marketplace/serviceaccounts?limit=1000
2023-05-04T18:33:33.690310054Z I0504 18:33:33.690215       1 request.go:533] Waited for 197.714204ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operators.coreos.com/v1alpha1/namespaces/openshift-node/installplans?limit=500
2023-05-04T18:33:33.698740942Z I0504 18:33:33.698689       1 request.go:533] Waited for 197.75495ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-monitoring/serviceaccounts?limit=1000
2023-05-04T18:33:33.891132740Z I0504 18:33:33.891091       1 request.go:533] Waited for 197.553443ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operators.coreos.com/v1alpha1/namespaces/openshift-nutanix-infra/installplans?limit=500
2023-05-04T18:33:33.898990884Z I0504 18:33:33.898931       1 request.go:533] Waited for 196.094926ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-multus/serviceaccounts?limit=1000
2023-05-04T18:33:34.090876082Z I0504 18:33:34.090832       1 request.go:533] Waited for 198.028254ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operators.coreos.com/v1alpha1/namespaces/openshift-oauth-apiserver/installplans?limit=500
2023-05-04T18:33:34.098955079Z I0504 18:33:34.098924       1 request.go:533] Waited for 198.032892ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-network-diagnostics/serviceaccounts?limit=1000
2023-05-04T18:33:34.290398188Z I0504 18:33:34.290348       1 request.go:533] Waited for 197.539867ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operators.coreos.com/v1alpha1/namespaces/openshift-openstack-infra/installplans?limit=500
2023-05-04T18:33:34.298673233Z I0504 18:33:34.298630       1 request.go:533] Waited for 197.78674ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-network-operator/serviceaccounts?limit=1000
2023-05-04T18:33:34.492178350Z I0504 18:33:34.491457       1 request.go:533] Waited for 198.903815ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operators.coreos.com/v1alpha1/namespaces/openshift-operator-lifecycle-manager/installplans?limit=500
2023-05-04T18:33:34.500637030Z I0504 18:33:34.499111       1 request.go:533] Waited for 198.347482ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-node/serviceaccounts?limit=1000
2023-05-04T18:33:34.691232118Z I0504 18:33:34.691192       1 request.go:533] Waited for 192.721688ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operators.coreos.com/v1alpha1/namespaces/openshift-operators/installplans?limit=500
2023-05-04T18:33:34.699595128Z I0504 18:33:34.699546       1 request.go:533] Waited for 195.742855ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-nutanix-infra/serviceaccounts?limit=1000
2023-05-04T18:33:34.900174839Z I0504 18:33:34.890506       1 request.go:533] Waited for 193.977484ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operators.coreos.com/v1alpha1/namespaces/openshift-ovirt-infra/installplans?limit=500
2023-05-04T18:33:34.900219853Z I0504 18:33:34.900190       1 request.go:533] Waited for 198.472617ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-oauth-apiserver/serviceaccounts?limit=1000
2023-05-04T18:33:35.091976310Z I0504 18:33:35.091239       1 request.go:533] Waited for 187.155735ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operators.coreos.com/v1alpha1/namespaces/openshift-ovn-kubernetes/installplans?limit=500
2023-05-04T18:33:35.099771304Z I0504 18:33:35.099183       1 request.go:533] Waited for 186.126154ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-openstack-infra/serviceaccounts?limit=1000
2023-05-04T18:33:35.290715497Z I0504 18:33:35.290677       1 request.go:533] Waited for 194.54578ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operators.coreos.com/v1alpha1/namespaces/openshift-route-controller-manager/installplans?limit=500
2023-05-04T18:33:35.300173511Z I0504 18:33:35.300133       1 request.go:533] Waited for 198.955002ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-operator-lifecycle-manager/serviceaccounts?limit=1000
2023-05-04T18:33:35.492419516Z I0504 18:33:35.491680       1 request.go:533] Waited for 199.08201ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operators.coreos.com/v1alpha1/namespaces/openshift-service-ca/installplans?limit=500
2023-05-04T18:33:35.500579416Z I0504 18:33:35.500549       1 request.go:533] Waited for 198.600948ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-operators/serviceaccounts?limit=1000
2023-05-04T18:33:35.690801413Z I0504 18:33:35.690760       1 request.go:533] Waited for 195.830219ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operators.coreos.com/v1alpha1/namespaces/openshift-service-ca-operator/installplans?limit=500
2023-05-04T18:33:35.699567881Z I0504 18:33:35.699537       1 request.go:533] Waited for 196.981951ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-ovirt-infra/serviceaccounts?limit=1000
2023-05-04T18:33:35.890548081Z I0504 18:33:35.890512       1 request.go:533] Waited for 197.950147ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operators.coreos.com/v1alpha1/namespaces/openshift-storage/installplans?limit=500
2023-05-04T18:33:35.899356056Z I0504 18:33:35.899317       1 request.go:533] Waited for 197.890234ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-ovn-kubernetes/serviceaccounts?limit=1000
2023-05-04T18:33:36.090493551Z I0504 18:33:36.090462       1 request.go:533] Waited for 180.30443ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operators.coreos.com/v1alpha1/namespaces/openshift-user-workload-monitoring/installplans?limit=500
2023-05-04T18:33:36.099442010Z I0504 18:33:36.099402       1 request.go:533] Waited for 197.418319ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-route-controller-manager/serviceaccounts?limit=1000
2023-05-04T18:33:36.290484958Z I0504 18:33:36.290447       1 request.go:533] Waited for 198.068859ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/apis/operators.coreos.com/v1alpha1/namespaces/openshift-vsphere-infra/installplans?limit=500
2023-05-04T18:33:36.292251342Z I0504 18:33:36.292225       1 tasks_processing.go:74] worker 2 stopped.
2023-05-04T18:33:36.292275127Z I0504 18:33:36.292260       1 recorder.go:70] Recording config/installplans with fingerprint=407ce712345f2115a7c38f87c7485486737709175477b7849e2f832ffdb015f8
2023-05-04T18:33:36.292275127Z I0504 18:33:36.292268       1 gather.go:180] gatherer "clusterconfig" function "install_plans" took 10.93061304s to process 1 records
2023-05-04T18:33:36.299239703Z I0504 18:33:36.299224       1 request.go:533] Waited for 198.101611ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-service-ca/serviceaccounts?limit=1000
2023-05-04T18:33:36.499472643Z I0504 18:33:36.499435       1 request.go:533] Waited for 198.407776ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-service-ca-operator/serviceaccounts?limit=1000
2023-05-04T18:33:36.698646887Z I0504 18:33:36.698611       1 request.go:533] Waited for 197.27475ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-storage/serviceaccounts?limit=1000
2023-05-04T18:33:36.898804184Z I0504 18:33:36.898767       1 request.go:533] Waited for 198.12759ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-user-workload-monitoring/serviceaccounts?limit=1000
2023-05-04T18:33:37.099132974Z I0504 18:33:37.099084       1 request.go:533] Waited for 198.41524ms due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-vsphere-infra/serviceaccounts?limit=1000
2023-05-04T18:33:37.102515821Z I0504 18:33:37.102476       1 tasks_processing.go:74] worker 0 stopped.
2023-05-04T18:33:37.102727739Z I0504 18:33:37.102715       1 recorder.go:70] Recording config/serviceaccounts with fingerprint=89f7c8ae1ed7c4c37ef10949d33e8e1a6f75092ed2426ef7617ac28d05b4fe8e
2023-05-04T18:33:37.102736385Z I0504 18:33:37.102727       1 gather.go:180] gatherer "clusterconfig" function "service_accounts" took 11.604041351s to process 1 records
2023-05-04T18:33:37.102783924Z E0504 18:33:37.102774       1 periodic.go:167] clusterconfig failed after 11.791s with: function "config_maps" failed with an error, unable to record function "container_images" record "config/pod/openshift-cluster-version/cluster-version-operator-7544974f8f-tjk7v.json"
2023-05-04T18:33:37.102790827Z I0504 18:33:37.102783       1 controllerstatus.go:79] name=periodic-clusterconfig healthy=false reason=PeriodicGatherFailed message=Source clusterconfig could not be retrieved: function "config_maps" failed with an error, unable to record function "container_images" record "config/pod/openshift-cluster-version/cluster-version-operator-7544974f8f-tjk7v.json"
2023-05-04T18:33:37.102795716Z I0504 18:33:37.102792       1 periodic.go:150] Running conditional gatherer
2023-05-04T18:33:37.102811315Z I0504 18:33:37.102800       1 requests.go:214] Preparing a request to Insights Operator Gathering Conditions Service at the endpoint "https://console.redhat.com/api/gathering/gathering_rules"
2023-05-04T18:33:37.116256961Z I0504 18:33:37.116209       1 requests.go:233] Performing a request to Insights Operator Gathering Conditions Service
2023-05-04T18:33:38.291512032Z I0504 18:33:38.291477       1 conditional_gatherer.go:94] got 9 gathering rules for conditional gatherer with version 1.0.1
2023-05-04T18:33:38.294297458Z I0504 18:33:38.294276       1 conditional_gatherer.go:242] updating alerts cache for conditional gatherer
2023-05-04T18:33:38.296121881Z I0504 18:33:38.296082       1 conditional_gatherer.go:278] alert "AlertmanagerReceiversNotConfigured" has state "firing"
2023-05-04T18:33:38.296121881Z I0504 18:33:38.296099       1 conditional_gatherer.go:278] alert "InsightsRecommendationActive" has state "firing"
2023-05-04T18:33:38.296121881Z I0504 18:33:38.296103       1 conditional_gatherer.go:278] alert "PodSecurityViolation" has state "firing"
2023-05-04T18:33:38.296121881Z I0504 18:33:38.296107       1 conditional_gatherer.go:278] alert "SimpleContentAccessNotAvailable" has state "firing"
2023-05-04T18:33:38.296121881Z I0504 18:33:38.296110       1 conditional_gatherer.go:278] alert "UpdateAvailable" has state "firing"
2023-05-04T18:33:38.296121881Z I0504 18:33:38.296114       1 conditional_gatherer.go:278] alert "Watchdog" has state "firing"
2023-05-04T18:33:38.296198826Z I0504 18:33:38.296181       1 conditional_gatherer.go:288] updating version cache for conditional gatherer
2023-05-04T18:33:38.299204435Z I0504 18:33:38.299167       1 conditional_gatherer.go:296] cluster version is '4.12.2'
2023-05-04T18:33:38.299204435Z I0504 18:33:38.299195       1 tasks_processing.go:45] number of workers: 1
2023-05-04T18:33:38.299233559Z I0504 18:33:38.299202       1 tasks_processing.go:69] worker 0 listening for tasks.
2023-05-04T18:33:38.299233559Z I0504 18:33:38.299205       1 tasks_processing.go:71] worker 0 working on conditional_gatherer_rules task.
2023-05-04T18:33:38.299290837Z I0504 18:33:38.299275       1 recorder.go:70] Recording insights-operator/conditional-gatherer-rules with fingerprint=8dbbbde181184600277bd0c8401374b23c24c4f4b08634e52ed045ff5aa12179
2023-05-04T18:33:38.299298662Z I0504 18:33:38.299289       1 gather.go:180] gatherer "conditional" function "conditional_gatherer_rules" took 832ns to process 1 records
2023-05-04T18:33:38.299298662Z I0504 18:33:38.299297       1 tasks_processing.go:74] worker 0 stopped.
2023-05-04T18:33:38.299315273Z I0504 18:33:38.299304       1 periodic.go:162] Periodic gather conditional completed in 1.196s
2023-05-04T18:33:38.313657130Z I0504 18:33:38.313617       1 recorder.go:70] Recording insights-operator/gathers with fingerprint=8599b2756c2c3e23ebc0ada13f0bc3d00be7d49453b5b5e26dd096bf88aae9f4
2023-05-04T18:33:38.313785351Z I0504 18:33:38.313771       1 diskrecorder.go:70] Writing 125 records to /var/lib/insights-operator/insights-2023-05-04-183338.tar.gz
2023-05-04T18:33:38.319358747Z I0504 18:33:38.319332       1 diskrecorder.go:51] Wrote 125 records to disk in 5ms
2023-05-04T18:33:46.890256104Z I0504 18:33:46.890217       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.61694ms" userAgent="Prometheus/2.39.1" audit-ID="20ef9063-707d-4bb4-9be1-122a9ccae0f4" srcIP="10.128.0.90:54562" resp=200
2023-05-04T18:34:16.898126463Z I0504 18:34:16.898086       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="11.230209ms" userAgent="Prometheus/2.39.1" audit-ID="27b1f6cd-649b-4470-9520-c57d24f416a1" srcIP="10.128.0.90:54562" resp=200
2023-05-04T18:34:46.889615628Z I0504 18:34:46.889575       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.509658ms" userAgent="Prometheus/2.39.1" audit-ID="2cee9228-8e73-4ad7-99f1-bfd718ff7742" srcIP="10.128.0.90:54562" resp=200
2023-05-04T18:35:04.801054279Z I0504 18:35:04.797641       1 controller.go:447] The operator is healthy
2023-05-04T18:35:04.801054279Z I0504 18:35:04.797683       1 controller.go:325] No status update necessary, objects are identical
2023-05-04T18:35:16.889192556Z I0504 18:35:16.889152       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.38269ms" userAgent="Prometheus/2.39.1" audit-ID="f112aeee-9599-40fc-bb05-4f0b06bdf7e3" srcIP="10.128.0.90:54562" resp=200
2023-05-04T18:35:38.591227006Z I0504 18:35:38.591177       1 reflector.go:559] k8s.io/apiserver/pkg/authentication/request/headerrequest/requestheader_controller.go:172: Watch close - *v1.ConfigMap total 7 items received
2023-05-04T18:35:46.894986559Z I0504 18:35:46.894912       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="7.426233ms" userAgent="Prometheus/2.39.1" audit-ID="388edb22-8331-4281-bec5-98f7551a0c9b" srcIP="10.128.0.90:54562" resp=200
2023-05-04T18:36:16.888877290Z I0504 18:36:16.888834       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.161926ms" userAgent="Prometheus/2.39.1" audit-ID="01583593-8bb8-4d93-857f-347d76f834e0" srcIP="10.128.0.90:54562" resp=200
2023-05-04T18:36:46.888716551Z I0504 18:36:46.888673       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.022926ms" userAgent="Prometheus/2.39.1" audit-ID="4aad3d05-422d-40ed-b1db-53aede717e5b" srcIP="10.128.0.90:54562" resp=200
2023-05-04T18:37:04.793653074Z I0504 18:37:04.793613       1 controller.go:447] The operator is healthy
2023-05-04T18:37:04.793685956Z I0504 18:37:04.793654       1 controller.go:325] No status update necessary, objects are identical
2023-05-04T18:37:16.893031569Z I0504 18:37:16.892958       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.65468ms" userAgent="Prometheus/2.39.1" audit-ID="f21580ba-9cb5-47e7-8b9b-a11e6d7fc4e7" srcIP="10.128.0.90:54562" resp=200
2023-05-04T18:37:44.753610999Z I0504 18:37:44.753571       1 secretconfigobserver.go:136] Refreshing configuration from cluster pull secret
2023-05-04T18:37:44.756252735Z I0504 18:37:44.756213       1 secretconfigobserver.go:248] Found cloud.openshift.com token
2023-05-04T18:37:44.756252735Z I0504 18:37:44.756238       1 secretconfigobserver.go:162] Refreshing configuration from cluster secret
2023-05-04T18:37:44.757643123Z I0504 18:37:44.757612       1 secretconfigobserver.go:119] support secret does not exist
2023-05-04T18:37:46.930421612Z I0504 18:37:46.922279       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="27.833199ms" userAgent="Prometheus/2.39.1" audit-ID="b9e4b5fd-bee3-4fa6-a57b-bd3c0cf16699" srcIP="10.128.0.90:54562" resp=200
2023-05-04T18:38:16.890025184Z I0504 18:38:16.889044       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.17417ms" userAgent="Prometheus/2.39.1" audit-ID="fec713bf-8236-4b92-bfcd-6614bb7ddd94" srcIP="10.128.0.90:54562" resp=200
2023-05-04T18:38:46.893444701Z I0504 18:38:46.893403       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="5.553279ms" userAgent="Prometheus/2.39.1" audit-ID="72510eca-5763-4fa3-904a-3fdda324e9fd" srcIP="10.128.0.90:54562" resp=200
2023-05-04T18:38:48.600428352Z I0504 18:38:48.600384       1 reflector.go:559] k8s.io/apiserver/pkg/server/dynamiccertificates/configmap_cafile_content.go:206: Watch close - *v1.ConfigMap total 8 items received
2023-05-04T18:39:04.794124628Z I0504 18:39:04.794082       1 controller.go:447] The operator is healthy
2023-05-04T18:39:04.794168330Z I0504 18:39:04.794123       1 controller.go:325] No status update necessary, objects are identical
2023-05-04T18:39:16.890025218Z I0504 18:39:16.889803       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.203183ms" userAgent="Prometheus/2.39.1" audit-ID="e19482bd-f5d4-4e96-bf05-fbec9d79f825" srcIP="10.128.0.90:54562" resp=200
2023-05-04T18:39:46.891040275Z I0504 18:39:46.890437       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.906173ms" userAgent="Prometheus/2.39.1" audit-ID="23737d7e-4375-43d2-a435-b7c0691d8fb5" srcIP="10.128.0.90:54562" resp=200
2023-05-04T18:40:16.890483403Z I0504 18:40:16.890438       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.86249ms" userAgent="Prometheus/2.39.1" audit-ID="7a57728a-e4b4-40c7-80da-4e856ac76667" srcIP="10.128.0.90:54562" resp=200
2023-05-04T18:40:46.889705026Z I0504 18:40:46.889622       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.688414ms" userAgent="Prometheus/2.39.1" audit-ID="44e70935-5c77-48ed-9b15-2aafea26f895" srcIP="10.128.0.90:54562" resp=200
2023-05-04T18:41:04.795078647Z I0504 18:41:04.793945       1 controller.go:447] The operator is healthy
2023-05-04T18:41:04.795078647Z I0504 18:41:04.794069       1 controller.go:325] No status update necessary, objects are identical
2023-05-04T18:41:16.890972666Z I0504 18:41:16.890024       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.560764ms" userAgent="Prometheus/2.39.1" audit-ID="15d99ec4-d9ab-4785-b83e-ed242b60a849" srcIP="10.128.0.90:54562" resp=200
2023-05-04T18:41:46.892835945Z I0504 18:41:46.892558       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="3.400009ms" userAgent="Prometheus/2.39.1" audit-ID="20acbf9b-07b6-4fb2-95d3-fb51c5151da2" srcIP="10.128.0.90:54562" resp=200
2023-05-04T18:41:51.603648260Z I0504 18:41:51.603606       1 reflector.go:559] k8s.io/apiserver/pkg/server/dynamiccertificates/configmap_cafile_content.go:206: Watch close - *v1.ConfigMap total 10 items received
2023-05-04T18:42:16.888799144Z I0504 18:42:16.888755       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.094399ms" userAgent="Prometheus/2.39.1" audit-ID="5e1b15a4-7a2b-4ecd-9094-84f948f9d76c" srcIP="10.128.0.90:54562" resp=200
2023-05-04T18:42:44.758111941Z I0504 18:42:44.758071       1 secretconfigobserver.go:136] Refreshing configuration from cluster pull secret
2023-05-04T18:42:44.761305362Z I0504 18:42:44.761258       1 secretconfigobserver.go:248] Found cloud.openshift.com token
2023-05-04T18:42:44.761305362Z I0504 18:42:44.761283       1 secretconfigobserver.go:162] Refreshing configuration from cluster secret
2023-05-04T18:42:44.765504380Z I0504 18:42:44.764670       1 secretconfigobserver.go:119] support secret does not exist
2023-05-04T18:42:46.896280606Z I0504 18:42:46.896242       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="8.083076ms" userAgent="Prometheus/2.39.1" audit-ID="9a47a353-c67d-4ac8-99cf-0ea2bfc022a9" srcIP="10.128.0.90:54562" resp=200
2023-05-04T18:42:59.593194265Z I0504 18:42:59.593144       1 reflector.go:559] k8s.io/apiserver/pkg/authentication/request/headerrequest/requestheader_controller.go:172: Watch close - *v1.ConfigMap total 9 items received
2023-05-04T18:43:04.793472519Z I0504 18:43:04.793422       1 controller.go:447] The operator is healthy
2023-05-04T18:43:04.793557067Z I0504 18:43:04.793548       1 controller.go:325] No status update necessary, objects are identical
2023-05-04T18:43:16.890243562Z I0504 18:43:16.889881       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.526991ms" userAgent="Prometheus/2.39.1" audit-ID="4244a8cc-a620-49f2-9de8-9d4d18e0f799" srcIP="10.128.0.90:54562" resp=200
2023-05-04T18:43:46.890367217Z I0504 18:43:46.890325       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.441581ms" userAgent="Prometheus/2.39.1" audit-ID="37f7dc11-42ec-4d2f-b09b-26ba08e6dd6c" srcIP="10.128.0.90:54562" resp=200
2023-05-04T18:44:16.891127064Z I0504 18:44:16.891082       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.513555ms" userAgent="Prometheus/2.39.1" audit-ID="963299cd-1c39-4262-8511-b9a119355cb2" srcIP="10.128.0.90:54562" resp=200
2023-05-04T18:44:46.890032832Z I0504 18:44:46.889952       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.656133ms" userAgent="Prometheus/2.39.1" audit-ID="732c2619-1fd4-4ef1-8d05-c7641561b0ba" srcIP="10.128.0.90:54562" resp=200
2023-05-04T18:44:59.602731597Z I0504 18:44:59.602688       1 reflector.go:559] k8s.io/apiserver/pkg/server/dynamiccertificates/configmap_cafile_content.go:206: Watch close - *v1.ConfigMap total 8 items received
2023-05-04T18:45:04.793798739Z I0504 18:45:04.793740       1 controller.go:447] The operator is healthy
2023-05-04T18:45:04.793873209Z I0504 18:45:04.793864       1 controller.go:325] No status update necessary, objects are identical
2023-05-04T18:45:16.890042524Z I0504 18:45:16.889487       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.392919ms" userAgent="Prometheus/2.39.1" audit-ID="2e87c6aa-979d-41f1-b6ed-62fb9bacc526" srcIP="10.128.0.90:54562" resp=200
2023-05-04T18:45:46.890876583Z I0504 18:45:46.890834       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.729922ms" userAgent="Prometheus/2.39.1" audit-ID="a633a708-6890-4045-9ac6-ffa7112e1aef" srcIP="10.128.0.90:54562" resp=200
2023-05-04T18:46:16.890162016Z I0504 18:46:16.890124       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="2.642287ms" userAgent="Prometheus/2.39.1" audit-ID="4edb90b5-3348-4b9e-9472-5a76ccccaefb" srcIP="10.128.0.90:54562" resp=200
2023-05-04T18:46:46.892201221Z I0504 18:46:46.892161       1 httplog.go:131] "HTTP" verb="GET" URI="/metrics" latency="4.065748ms" userAgent="Prometheus/2.39.1" audit-ID="dabff04d-2a13-4cb8-9664-f10f188e1e70" srcIP="10.128.0.90:54562" resp=200
