---
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  annotations:
    include.release.openshift.io/ibm-cloud-managed: "true"
    include.release.openshift.io/self-managed-high-availability: "true"
    include.release.openshift.io/single-node-developer: "true"
  creationTimestamp: "2023-05-02T12:18:31Z"
  generation: 1
  labels:
    k8s-app: machine-config-daemon
  managedFields:
  - apiVersion: monitoring.coreos.com/v1
    fieldsType: FieldsV1
    fieldsV1:
      f:metadata:
        f:annotations:
          .: {}
          f:include.release.openshift.io/ibm-cloud-managed: {}
          f:include.release.openshift.io/self-managed-high-availability: {}
          f:include.release.openshift.io/single-node-developer: {}
        f:labels:
          .: {}
          f:k8s-app: {}
        f:ownerReferences:
          .: {}
          k:{"uid":"77d6ad13-e1ab-45f9-a3c3-540f5d841b6f"}: {}
      f:spec:
        .: {}
        f:groups: {}
    manager: cluster-version-operator
    operation: Update
    time: "2023-05-02T12:18:31Z"
  name: machine-config-daemon
  namespace: openshift-machine-config-operator
  ownerReferences:
  - apiVersion: config.openshift.io/v1
    kind: ClusterVersion
    name: version
    uid: 77d6ad13-e1ab-45f9-a3c3-540f5d841b6f
  resourceVersion: "1707"
  uid: 034f1078-6166-45f2-aae6-a6e2ebddb2ca
spec:
  groups:
  - name: mcd-reboot-error
    rules:
    - alert: MCDRebootError
      annotations:
        message: Reboot failed on {{ $labels.node }} , update may be blocked
      expr: |
        mcd_reboot_err > 0
      labels:
        severity: critical
  - name: mcd-drain-error
    rules:
    - alert: MCDDrainError
      annotations:
        message: 'Drain failed on {{ $labels.node }} , updates may be blocked. For
          more details check MachineConfigController pod logs: oc logs -f -n {{ $labels.namespace
          }} machine-config-controller-xxxxx -c machine-config-controller'
      expr: |
        mcd_drain_err > 0
      labels:
        severity: warning
  - name: mcd-pivot-error
    rules:
    - alert: MCDPivotError
      annotations:
        message: 'Error detected in pivot logs on {{ $labels.node }} '
      expr: |
        mcd_pivot_err > 0
      labels:
        severity: warning
  - name: mcd-kubelet-health-state-error
    rules:
    - alert: KubeletHealthState
      annotations:
        message: Kubelet health failure threshold reached
      expr: |
        mcd_kubelet_state > 2
      labels:
        severity: warning
  - name: system-memory-exceeds-reservation
    rules:
    - alert: SystemMemoryExceedsReservation
      annotations:
        message: System memory usage of {{ $value | humanize }} on {{ $labels.node
          }} exceeds 95% of the reservation. Reserved memory ensures system processes
          can function even when the node is fully allocated and protects against
          workload out of memory events impacting the proper functioning of the node.
          The default reservation is expected to be sufficient for most configurations
          and should be increased (https://docs.openshift.com/container-platform/latest/nodes/nodes/nodes-nodes-managing.html)
          when running nodes with high numbers of pods (either due to rate of change
          or at steady state).
      expr: |
        sum by (node) (container_memory_rss{id="/system.slice"}) > ((sum by (node) (kube_node_status_capacity{resource="memory"} - kube_node_status_allocatable{resource="memory"})) * 0.95)
      for: 15m
      labels:
        severity: warning
  - name: high-overall-control-plane-memory
    rules:
    - alert: HighOverallControlPlaneMemory
      annotations:
        description: Given three control plane nodes, the overall memory utilization
          may only be about 2/3 of all available capacity. This is because if a single
          control plane node fails, the kube-apiserver and etcd my be slow to respond.
          To fix this, increase memory of the control plane nodes.
        summary: Memory utilization across all control plane nodes is high, and could
          impact responsiveness and stability.
      expr: |
        (
          1
          -
          sum (
            node_memory_MemFree_bytes
            + node_memory_Buffers_bytes
            + node_memory_Cached_bytes
            AND on (instance)
            label_replace( kube_node_role{role="master"}, "instance", "$1", "node", "(.+)" )
          ) / sum (
            node_memory_MemTotal_bytes
            AND on (instance)
            label_replace( kube_node_role{role="master"}, "instance", "$1", "node", "(.+)" )
          )
        ) * 100 > 60
      for: 1h
      labels:
        severity: warning
  - name: extremely-high-individual-control-plane-memory
    rules:
    - alert: ExtremelyHighIndividualControlPlaneMemory
      annotations:
        description: The memory utilization per instance within control plane nodes
          influence the stability, and responsiveness of the cluster. This can lead
          to cluster instability and slow responses from kube-apiserver or failing
          requests specially on etcd. Moreover, OOM kill is expected which negatively
          influences the pod scheduling. If this happens on container level, the descheduler
          will not be able to detect it, as it works on the pod level. To fix this,
          increase memory of the affected node of control plane nodes.
        summary: Extreme memory utilization per node within control plane nodes is
          extremely high, and could impact responsiveness and stability.
      expr: |
        (
          1
          -
          sum by (instance) (
            node_memory_MemFree_bytes
            + node_memory_Buffers_bytes
            + node_memory_Cached_bytes
            AND on (instance)
            label_replace( kube_node_role{role="master"}, "instance", "$1", "node", "(.+)" )
          ) / sum by (instance) (
            node_memory_MemTotal_bytes
            AND on (instance)
            label_replace( kube_node_role{role="master"}, "instance", "$1", "node", "(.+)" )
          )
        ) * 100 > 90
      for: 45m
      labels:
        severity: critical
